{"totalQueries": 86, "1": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85175004991"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85175004991?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85175004991&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85175004991&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0031320323007495"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85175004991", "dc:identifier": "SCOPUS_ID:85175004991", "eid": "2-s2.0-85175004991", "dc:title": "Neural architecture search: A contemporary literature review for computer vision applications", "dc:creator": "Poyser M.", "prism:publicationName": "Pattern Recognition", "prism:issn": "00313203", "prism:volume": "147", "prism:pageRange": null, "prism:coverDate": "2024-03-01", "prism:coverDisplayDate": "March 2024", "prism:doi": "10.1016/j.patcog.2023.110052", "pii": "S0031320323007495", "dc:description": "Deep Neural Networks have received considerable attention in recent years. As the complexity of network architecture increases in relation to the task complexity, it becomes harder to manually craft an optimal neural network architecture and train it to convergence. As such, Neural Architecture Search (NAS) is becoming far more prevalent within computer vision research, especially when the construction of efficient, smaller network architectures is becoming an increasingly important area of research, for which NAS is well suited. However, despite their promise, contemporary and end-to-end NAS pipeline require vast computational training resources. In this paper, we present a comprehensive overview of contemporary NAS approaches with respect to image classification, object detection, and image segmentation. We adopt consistent terminology to overcome contradictions common within existing NAS literature. Furthermore, we identify and compare current performance limitations in addition to highlighting directions for future NAS research.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60022175", "afid": "60022175", "affilname": "Durham University", "affiliation-city": "Durham", "affiliation-country": "United Kingdom"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57219792943", "authid": "57219792943", "authname": "Poyser M.", "surname": "Poyser", "given-name": "Matt", "initials": "M.", "afid": [{"@_fa": "true", "$": "60022175"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/8661055600", "authid": "8661055600", "authname": "Breckon T.P.", "surname": "Breckon", "given-name": "Toby P.", "initials": "T.P.", "afid": [{"@_fa": "true", "$": "60022175"}]}], "authkeywords": "Classification | Detection | Neural architecture search | Segmentation", "article-number": "110052", "source-id": "24823", "fund-acr": "ERDF", "fund-no": "25R17P01847", "fund-sponsor": "Durham University", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherhybridgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Hybrid Gold"}]}}, "2": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85163706519"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85163706519?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85163706519&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85163706519&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580523002406"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85163706519", "dc:identifier": "SCOPUS_ID:85163706519", "eid": "2-s2.0-85163706519", "dc:title": "Computer vision applications in offsite construction", "dc:creator": "Alsakka F.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "154", "prism:pageRange": null, "prism:coverDate": "2023-10-01", "prism:coverDisplayDate": "October 2023", "prism:doi": "10.1016/j.autcon.2023.104980", "pii": "S0926580523002406", "dc:description": "The field of computer vision has undergone rapid growth in recent years, yet the use of computer vision in offsite construction remains an under-researched area of study. Given the current momentum around the adoption of this technology, this article presents a scoping review of computer vision applications in offsite construction. It provides (1) summaries of and discussions on the research areas in which computer vision is used in offsite construction, the computer vision tasks undertaken, the algorithms used, and related performance evaluation results and limitations, (2) a tabulated summary of performance-related terms commonly used in computer vision applications (to facilitate understanding of the performance evaluation results reported in the review), and (3) potential avenues of future research. The review provides a useful point of reference for practitioners and researchers in the offsite construction industry, aiding their understanding of current practice, limitations, research gaps, and potential opportunities to apply computer vision.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60030835", "afid": "60030835", "affilname": "University of Alberta", "affiliation-city": "Edmonton", "affiliation-country": "Canada"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60010365", "afid": "60010365", "affilname": "The University of British Columbia", "affiliation-city": "Vancouver", "affiliation-country": "Canada"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57216990608", "authid": "57216990608", "authname": "Alsakka F.", "surname": "Alsakka", "given-name": "Fatima", "initials": "F.", "afid": [{"@_fa": "true", "$": "60030835"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57215305751", "authid": "57215305751", "authname": "Assaf S.", "surname": "Assaf", "given-name": "Sena", "initials": "S.", "afid": [{"@_fa": "true", "$": "60030835"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57188813869", "authid": "57188813869", "authname": "El-Chami I.", "surname": "El-Chami", "given-name": "Ibrahim", "initials": "I.", "afid": [{"@_fa": "true", "$": "60010365"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/6603541102", "authid": "6603541102", "authname": "Al-Hussein M.", "surname": "Al-Hussein", "given-name": "Mohamed", "initials": "M.", "afid": [{"@_fa": "true", "$": "60030835"}]}], "authkeywords": "3D reconstruction | Artificial intelligence | Computer vision | Custom vision | Edge detection | Feature extraction | Object detection | Object tracking | Offsite construction | Scoping review | Segmentation", "article-number": "104980", "source-id": "24931", "fund-acr": "AI", "fund-no": "undefined", "fund-sponsor": "Alberta Innovates", "openaccess": "0", "openaccessFlag": false}, "3": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85160810683"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85160810683?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85160810683&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85160810683&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580523001966"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85160810683", "dc:identifier": "SCOPUS_ID:85160810683", "eid": "2-s2.0-85160810683", "dc:title": "From 3D point clouds to HBIM: Application of Artificial Intelligence in Cultural Heritage", "dc:creator": "Cotella V.A.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "152", "prism:pageRange": null, "prism:coverDate": "2023-08-01", "prism:coverDisplayDate": "August 2023", "prism:doi": "10.1016/j.autcon.2023.104936", "pii": "S0926580523001966", "dc:description": "Interest in semantic segmentation of 3D point clouds using ML and DL has grown due to their key role in scene insight across a wide range of computer vision, robotics and remote sensing applications. In the domain of Cultural Heritage, 3D point clouds are increasingly used as the backbone for as-built BIM models becoming a conventional approach to design in the AEC industry. However, there's a research gap in this field regarding the interface between point cloud segmentation and the HBIM workflow: there are no consistent studies demonstrating the possibility of automating the construction of parametric historical features from the segmentation process results in terms of geometry and semantic labels. The current research intends to perform a systematic review of the current bibliography with the aim of offering a constructive synthesis that will provide as a springboard for the advancement of innovative strategies in the field of BIM and AI.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60017293", "afid": "60017293", "affilname": "Universit\u00e0 degli Studi di Napoli Federico II", "affiliation-city": "Naples", "affiliation-country": "Italy"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57226342818", "authid": "57226342818", "authname": "Cotella V.A.", "surname": "Cotella", "given-name": "Victoria Andrea", "initials": "V.A.", "afid": [{"@_fa": "true", "$": "60017293"}]}], "authkeywords": "3D point cloud | Artificial Intelligence | Automatization | Cultural Heritage | Digitalisation | HBIM", "article-number": "104936", "source-id": "24931", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "4": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85164846648"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85164846648?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85164846648&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85164846648&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85164846648", "dc:identifier": "SCOPUS_ID:85164846648", "eid": "2-s2.0-85164846648", "dc:title": "Computer Vision Technology for Monitoring of Indoor and Outdoor Environments and HVAC Equipment: A Review", "dc:creator": "Yang B.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "23", "prism:issueIdentifier": "13", "prism:pageRange": null, "prism:coverDate": "2023-07-01", "prism:coverDisplayDate": "July 2023", "prism:doi": "10.3390/s23136186", "dc:description": "Artificial intelligence technologies such as computer vision (CV), machine learning, Internet of Things (IoT), and robotics have advanced rapidly in recent years. The new technologies provide non-contact measurements in three areas: indoor environmental monitoring, outdoor environ-mental monitoring, and equipment monitoring. This paper summarizes the specific applications of non-contact measurement based on infrared images and visible images in the areas of personnel skin temperature, position posture, the urban physical environment, building construction safety, and equipment operation status. At the same time, the challenges and opportunities associated with the application of CV technology are anticipated.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60138441", "afid": "60138441", "affilname": "Tianjin Chengjian University", "affiliation-city": "Tianjin", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025063", "afid": "60025063", "affilname": "KU Leuven", "affiliation-city": "3000 Leuven", "affiliation-country": "Belgium"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60009400", "afid": "60009400", "affilname": "Nanjing University of Post and TeleCommunications", "affiliation-city": "Nanjing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60003858", "afid": "60003858", "affilname": "Uppsala Universitet", "affiliation-city": "Uppsala", "affiliation-country": "Sweden"}], "pubmed-id": "37448035", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "8", "$": "8"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57220789589", "authid": "57220789589", "orcid": "0000-0003-4015-199X", "authname": "Yang B.", "surname": "Yang", "given-name": "Bin", "initials": "B.", "afid": [{"@_fa": "true", "$": "60138441"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/58001670800", "authid": "58001670800", "authname": "Yang S.", "surname": "Yang", "given-name": "Shuang", "initials": "S.", "afid": [{"@_fa": "true", "$": "60138441"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57903866900", "authid": "57903866900", "orcid": "0000-0002-7671-323X", "authname": "Zhu X.", "surname": "Zhu", "given-name": "Xin", "initials": "X.", "afid": [{"@_fa": "true", "$": "60138441"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/58488502100", "authid": "58488502100", "authname": "Qi M.", "surname": "Qi", "given-name": "Min", "initials": "M.", "afid": [{"@_fa": "true", "$": "60138441"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/58488267600", "authid": "58488267600", "authname": "Li H.", "surname": "Li", "given-name": "He", "initials": "H.", "afid": [{"@_fa": "true", "$": "60138441"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/55925162500", "authid": "55925162500", "authname": "Lv Z.", "surname": "Lv", "given-name": "Zhihan", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60003858"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/57192908357", "authid": "57192908357", "authname": "Cheng X.", "surname": "Cheng", "given-name": "Xiaogang", "initials": "X.", "afid": [{"@_fa": "true", "$": "60009400"}]}, {"@_fa": "true", "@seq": "8", "author-url": "https://api.elsevier.com/content/author/author_id/57204857191", "authid": "57204857191", "orcid": "0000-0002-2945-4685", "authname": "Wang F.", "surname": "Wang", "given-name": "Faming", "initials": "F.", "afid": [{"@_fa": "true", "$": "60025063"}]}], "authkeywords": "behavior patterns | computer vision | equipment health monitoring | fault diagnosis and detection | non-contact measurement | remote sensing", "article-number": "6186", "source-id": "130124", "fund-acr": "NSFC", "fund-no": "52278119", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "5": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85151418084"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85151418084?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151418084&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85151418084&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85151418084", "dc:identifier": "SCOPUS_ID:85151418084", "eid": "2-s2.0-85151418084", "dc:title": "Towards Diagnosis of Autoimmune Blistering Skin Diseases Using Deep Neural Network", "dc:creator": "Singh M.", "prism:publicationName": "Archives of Computational Methods in Engineering", "prism:issn": "11343060", "prism:eIssn": "18861784", "prism:volume": "30", "prism:issueIdentifier": "6", "prism:pageRange": "3529-3557", "prism:coverDate": "2023-07-01", "prism:coverDisplayDate": "July 2023", "prism:doi": "10.1007/s11831-023-09910-3", "dc:description": "There are many skin disorders that affect human beings and symptoms of many skin diseases are common. Therefore, understanding the real differences between them is important for the correct diagnosis of dermatitis. Autoimmune blister skin diseases are uncommon skin diseases which come under heterogeneous group of disorders and happen when our immune system, which usually protects, attacks one\u2019s own skin and mucous membrane mistakenly and cause blister (bulla) formation. The diagnosis of autoimmune blistering skin diseases is based on lesions examination and requires extensive, algorithmic array of immunologic investigations that are available in a few selected centers only and are cost intensive. Thus, a computerized system is needed to diagnose the diseases without such constraints. Computer-aided systems for detection are more precise, objective and reliable as opposed to diagnosis by expert. Deep neural networks, specifically convolutional neural networks, have been used for computer vision problems in several domains, have achieved the dermatologist-level accuracy in the classification of skin diseases. This paper provides the review on AIBD and its clinical features, existing tests for diagnosis, and need for early diagnosis of AIBD. Next, the techniques, challenges and shortcomings of traditional machine learning are highlighted. Then, the terminology and techniques used in the construction of convolutional neural network (CNN) and the existing use of deep neural networks, especially CNN, and transfer learning techniques for skin diseases are reviewed. Various approaches for segmentation using deep neural network are also pointed. At last, future works and conclusions about the classification of AIBD using deep learning techniques is discussed.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60000690", "afid": "60000690", "affilname": "Punjabi University", "affiliation-city": "Patiala", "affiliation-country": "India"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60000137", "afid": "60000137", "affilname": "Postgraduate Institute of Medical Education &amp; Research, Chandigarh", "affiliation-city": "Chandigarh", "affiliation-country": "India"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/58168206600", "authid": "58168206600", "orcid": "0000-0002-5108-1280", "authname": "Singh M.", "surname": "Singh", "given-name": "Manbir", "initials": "M.", "afid": [{"@_fa": "true", "$": "60000690"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/58599639800", "authid": "58599639800", "authname": "Singh M.", "surname": "Singh", "given-name": "Maninder", "initials": "M.", "afid": [{"@_fa": "true", "$": "60000690"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/14119526100", "authid": "14119526100", "authname": "De D.", "surname": "De", "given-name": "Dipankar", "initials": "D.", "afid": [{"@_fa": "true", "$": "60000137"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/55366103000", "authid": "55366103000", "authname": "Handa S.", "surname": "Handa", "given-name": "Sanjeev", "initials": "S.", "afid": [{"@_fa": "true", "$": "60000137"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/36546423300", "authid": "36546423300", "authname": "Mahajan R.", "surname": "Mahajan", "given-name": "Rahul", "initials": "R.", "afid": [{"@_fa": "true", "$": "60000137"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57202219548", "authid": "57202219548", "authname": "Chatterjee D.", "surname": "Chatterjee", "given-name": "Debajyoti", "initials": "D.", "afid": [{"@_fa": "true", "$": "60000137"}]}], "source-id": "18093", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "6": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85159279930"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85159279930?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85159279930&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85159279930&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159279930", "dc:identifier": "SCOPUS_ID:85159279930", "eid": "2-s2.0-85159279930", "dc:title": "A Survey on Datasets for Emotion Recognition from Vision: Limitations and In-the-Wild Applicability", "dc:creator": "Costa W.", "prism:publicationName": "Applied Sciences (Switzerland)", "prism:eIssn": "20763417", "prism:volume": "13", "prism:issueIdentifier": "9", "prism:pageRange": null, "prism:coverDate": "2023-05-01", "prism:coverDisplayDate": "May 2023", "prism:doi": "10.3390/app13095697", "dc:description": "Emotion recognition is the task of identifying and understanding human emotions from data. In the field of computer vision, there is a growing interest due to the wide range of possible applications in smart cities, health, marketing, and surveillance, among others. To date, several datasets have been proposed to allow techniques to be trained, validated, and finally deployed to production. However, these techniques have several limitations related to the construction of these datasets. In this work, we survey the datasets currently employed in state-of-the-art emotion recognition, to list and discuss their applicability and limitations in real-world scenarios. We propose experiments on the data to extract essential insights related to the provided visual information in each dataset and discuss how they impact the training and validation of techniques. We also investigate the presence of nonverbal cues in the datasets and propose experiments regarding their representativeness, visibility, and data quality. Among other discussions, we show that EMOTIC has more diverse context representations than CAER, however, with conflicting annotations. Finally, we discuss application scenarios and how techniques to approach them could leverage these datasets, suggesting approaches based on findings from these datasets to help guide future research and deployment. With this work we expect to provide a roadmap for upcoming research and experimentation in emotion recognition under real-world conditions.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60031482", "afid": "60031482", "affilname": "Universidade Federal de Pernambuco", "affiliation-city": "Recife", "affiliation-country": "Brazil"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020599", "afid": "60020599", "affilname": "Universiteit Twente", "affiliation-city": "Enschede", "affiliation-country": "Netherlands"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60000958", "afid": "60000958", "affilname": "Universidade Federal Rural de Pernambuco", "affiliation-city": "Recife", "affiliation-country": "Brazil"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "7", "$": "7"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57212622304", "authid": "57212622304", "orcid": "0000-0002-7493-4880", "authname": "Costa W.", "surname": "Costa", "given-name": "Willams", "initials": "W.", "afid": [{"@_fa": "true", "$": "60031482"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56728092700", "authid": "56728092700", "orcid": "0000-0001-5918-8990", "authname": "Talavera E.", "surname": "Talavera", "given-name": "Estefan\u00eda", "initials": "E.", "afid": [{"@_fa": "true", "$": "60020599"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/58248700600", "authid": "58248700600", "authname": "Oliveira R.", "surname": "Oliveira", "given-name": "Renato", "initials": "R.", "afid": [{"@_fa": "true", "$": "60031482"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/36162738100", "authid": "36162738100", "orcid": "0000-0001-9848-5883", "authname": "Figueiredo L.", "surname": "Figueiredo", "given-name": "Lucas", "initials": "L.", "afid": [{"@_fa": "true", "$": "60031482"}, {"@_fa": "true", "$": "60000958"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/20035706400", "authid": "20035706400", "orcid": "0000-0001-7180-512X", "authname": "Teixeira J.M.", "surname": "Teixeira", "given-name": "Jo\u00e3o Marcelo", "initials": "J.M.", "afid": [{"@_fa": "true", "$": "60031482"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57204039677", "authid": "57204039677", "orcid": "0000-0002-1834-5221", "authname": "Lima J.P.", "surname": "Lima", "given-name": "Jo\u00e3o Paulo", "initials": "J.P.", "afid": [{"@_fa": "true", "$": "60031482"}, {"@_fa": "true", "$": "60000958"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/6506442332", "authid": "6506442332", "authname": "Teichrieb V.", "surname": "Teichrieb", "given-name": "Veronica", "initials": "V.", "afid": [{"@_fa": "true", "$": "60031482"}]}], "authkeywords": "affective computing | computer vision | emotion perception | emotion recognition | emotion recognition datasets | human behavior recognition | in-the-wild emotion recognition | multi-cue emotion recognition | nonverbal emotion communication | survey", "article-number": "5697", "source-id": "21100829268", "fund-acr": "CAPES", "fund-no": "422728/2021-7", "fund-sponsor": "Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel Superior", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "7": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85159226405"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85159226405?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85159226405&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85159226405&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159226405", "dc:identifier": "SCOPUS_ID:85159226405", "eid": "2-s2.0-85159226405", "dc:title": "Review of Artificial Intelligence Applications for Virtual Sensing of Underground Utilities", "dc:creator": "Oguntoye K.S.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "23", "prism:issueIdentifier": "9", "prism:pageRange": null, "prism:coverDate": "2023-05-01", "prism:coverDisplayDate": "May 2023", "prism:doi": "10.3390/s23094367", "dc:description": "Accurately identifying the location and depth of buried utility assets became a considerable challenge in the construction industry, for which accidental strikes can cause important economic losses and safety concerns. While the collection of as-built utility locations is becoming more accurate, there still exists an important need to be capable of accurately detecting buried utilities in order to eliminate risks associated with digging. Current practices typically involve the use of trained agents to survey and detect underground utilities at locations of interest, which is a costly and time-consuming process. With advances in artificial intelligence (AI), an opportunity arose in conducting virtual sensing of buried utilities by combining robotics (e.g., drones), knowledge, and logic. This paper reviewed methods that are based on AI in mapping underground infrastructure. In particular, the use of AI in aerial and terrestrial mapping of utility assets was reviewed, followed by a summary of AI techniques used in fusing multi-source data in creating underground infrastructure maps. Key observations from the consolidated literature were that (1) when leveraging computer vision methods, automatic mapping techniques vastly focus on manholes localized from aerial imagery; (2) when applied to non-intrusive sensing, AI methods vastly focus on empowering ground-penetrating radar (GPR)-produced data; and (3) data fusion techniques to produce utility maps should be extended to any utility assets/types. Based on these observations, a universal utility mapping model was proposed, one that could enable mapping of underground utilities using limited information available in the form of different sources of data and knowledge.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60004354", "afid": "60004354", "affilname": "Iowa State University", "affiliation-city": "Ames", "affiliation-country": "United States"}], "pubmed-id": "37177570", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/58247815600", "authid": "58247815600", "orcid": "0009-0002-9993-3304", "authname": "Oguntoye K.S.", "surname": "Oguntoye", "given-name": "Kunle S.", "initials": "K.S.", "afid": [{"@_fa": "true", "$": "60004354"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/34168028300", "authid": "34168028300", "orcid": "0000-0002-0601-9664", "authname": "Laflamme S.", "surname": "Laflamme", "given-name": "Simon", "initials": "S.", "afid": [{"@_fa": "true", "$": "60004354"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/14831843800", "authid": "14831843800", "orcid": "0000-0002-0702-8351", "authname": "Sturgill R.", "surname": "Sturgill", "given-name": "Roy", "initials": "R.", "afid": [{"@_fa": "true", "$": "60004354"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/15135673800", "authid": "15135673800", "authname": "Eisenmann D.J.", "surname": "Eisenmann", "given-name": "David J.", "initials": "D.J.", "afid": [{"@_fa": "true", "$": "60004354"}]}], "authkeywords": "artificial intelligence | buried utilities | data fusion | knowledge database | underground utilities | virtual sensing", "article-number": "4367", "source-id": "130124", "fund-acr": "IEC", "fund-no": "21-IEC-006", "fund-sponsor": "Iowa Energy Center", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "8": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85159166796"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85159166796?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85159166796&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85159166796&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85159166796", "dc:identifier": "SCOPUS_ID:85159166796", "eid": "2-s2.0-85159166796", "dc:title": "Deep Learning for Visual SLAM: The State-of-the-Art and Future Trends", "dc:creator": "Favorskaya M.N.", "prism:publicationName": "Electronics (Switzerland)", "prism:eIssn": "20799292", "prism:volume": "12", "prism:issueIdentifier": "9", "prism:pageRange": null, "prism:coverDate": "2023-05-01", "prism:coverDisplayDate": "May 2023", "prism:doi": "10.3390/electronics12092006", "dc:description": "Visual Simultaneous Localization and Mapping (VSLAM) has been a hot topic of research since the 1990s, first based on traditional computer vision and recognition techniques and later on deep learning models. Although the implementation of VSLAM methods is far from perfect and complete, recent research in deep learning has yielded promising results for applications such as autonomous driving and navigation, service robots, virtual and augmented reality, and pose estimation. The pipeline of traditional VSLAM methods based on classical image processing algorithms consists of six main steps, including initialization (data acquisition), feature extraction, feature matching, pose estimation, map construction, and loop closure. Since 2017, deep learning has changed this approach from individual steps to implementation as a whole. Currently, three ways are developing with varying degrees of integration of deep learning into traditional VSLAM systems: (1) adding auxiliary modules based on deep learning, (2) replacing the original modules of traditional VSLAM with deep learning modules, and (3) replacing the traditional VSLAM system with end-to-end deep neural networks. The first way is the most elaborate and includes multiple algorithms. The other two are in the early stages of development due to complex requirements and criteria. The available datasets with multi-modal data are also of interest. The discussed challenges, advantages, and disadvantages underlie future VSLAM trends, guiding subsequent directions of research.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60075528", "afid": "60075528", "affilname": "Reshetnev Siberian State University of Science and Technology", "affiliation-city": "Krasnoyarsk", "affiliation-country": "Russian Federation"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/36598108700", "authid": "36598108700", "orcid": "0000-0002-2181-0454", "authname": "Favorskaya M.N.", "surname": "Favorskaya", "given-name": "Margarita N.", "initials": "M.N.", "afid": [{"@_fa": "true", "$": "60075528"}]}], "authkeywords": "deep learning | map construction | pose estimation | robotics | visual odometry | visual SLAM", "article-number": "2006", "source-id": "21100829272", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "9": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85151357121"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85151357121?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151357121&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85151357121&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85151357121", "dc:identifier": "SCOPUS_ID:85151357121", "eid": "2-s2.0-85151357121", "dc:title": "Concrete 3D Printing: Process Parameters for Process Control, Monitoring and Diagnosis in Automation and Construction", "dc:creator": "Quah T.K.N.", "prism:publicationName": "Mathematics", "prism:eIssn": "22277390", "prism:volume": "11", "prism:issueIdentifier": "6", "prism:pageRange": null, "prism:coverDate": "2023-03-01", "prism:coverDisplayDate": "March 2023", "prism:doi": "10.3390/math11061499", "dc:description": "In Singapore, there is an increasing need for independence from manpower within the Building and Construction (B&C) Industry. Prefabricated Prefinished Volumetric Construction (PPVC) production is mainly driven by benefits in environmental pollution reduction, improved productivity, quality control, and customizability. However, overall cost savings have been counterbalanced by new cost drivers like modular precast moulds, transportation, hoisting, manufacturing & holding yards, and supervision costs. The highly modular requirements for PPVC places additive manufacturing in an advantageous position, due to its high customizability, low volume manufacturing capabilities for a faster manufacturing response time, faster production changeovers, and lower inventory requirements. However, C3DP has only just begun to move away from its early-stage development, where there is a need to closely evaluate the process parameters across buildability, extrudability, and pumpability aspects. As many parameters have been identified as having considerable influence on C3DP processes, monitoring systems for feedback applications seem to be an inevitable step forward to automation in construction. This paper has presented a broad analysis of the challenges posed to C3DP and feedback systems, stressing the admission of process parameters to correct multiple modes of failure.", "citedby-count": "3", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60119025", "afid": "60119025", "affilname": "Singapore Centre for 3D Printing", "affiliation-city": "Singapore City", "affiliation-country": "Singapore"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/58165696900", "authid": "58165696900", "authname": "Quah T.K.N.", "surname": "Quah", "given-name": "Tan Kai Noel", "initials": "T.K.N.", "afid": [{"@_fa": "true", "$": "60119025"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57191844467", "authid": "57191844467", "orcid": "0000-0002-7369-2138", "authname": "Tay Y.W.D.", "surname": "Tay", "given-name": "Yi Wei Daniel", "initials": "Y.W.D.", "afid": [{"@_fa": "true", "$": "60119025"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57196248157", "authid": "57196248157", "authname": "Lim J.H.", "surname": "Lim", "given-name": "Jian Hui", "initials": "J.H.", "afid": [{"@_fa": "true", "$": "60119025"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/7401465058", "authid": "7401465058", "authname": "Tan M.J.", "surname": "Tan", "given-name": "Ming Jen", "initials": "M.J.", "afid": [{"@_fa": "true", "$": "60119025"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57772586300", "authid": "57772586300", "authname": "Wong T.N.", "surname": "Wong", "given-name": "Teck Neng", "initials": "T.N.", "afid": [{"@_fa": "true", "$": "60119025"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57204943460", "authid": "57204943460", "orcid": "0000-0001-6187-6434", "authname": "Li K.H.H.", "surname": "Li", "given-name": "King Ho Holden", "initials": "K.H.H.", "afid": [{"@_fa": "true", "$": "60119025"}]}], "authkeywords": "computer vision | Concrete 3D Printing | diagnosis systems | ex-situ monitoring | feedback control | feedback systems | in-situ monitoring | monitoring systems | process control | sustainability", "article-number": "1499", "source-id": "21100830702", "fund-acr": "NRF", "fund-no": "undefined", "fund-sponsor": "National Research Foundation Singapore", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "10": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85175027824"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85175027824?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85175027824&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85175027824&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85175027824", "dc:identifier": "SCOPUS_ID:85175027824", "eid": "2-s2.0-85175027824", "dc:title": "Recent Advances in Robot Visual SLAM", "dc:creator": "Zhang H.", "prism:publicationName": "Recent Advances in Computer Science and Communications", "prism:issn": "26662558", "prism:eIssn": "26662566", "prism:volume": "16", "prism:issueIdentifier": "8", "prism:pageRange": "19-37", "prism:coverDate": "2023-01-01", "prism:coverDisplayDate": "2023", "prism:doi": "10.2174/2666255816666230509153317", "dc:description": "Background: SLAM plays an important role in the navigation of robots, unmanned aeri-al vehicles, and unmanned vehicles. The positioning accuracy will affect the accuracy of obstacle avoidance. The quality of map construction directly affects the performance of subsequent path planning and other algorithms. It is the core algorithm of the intelligent mobile application. There-fore, robot vision SLAM has great research value and will be an important research direction in the future. Objective: By reviewing the latest development and patent of Computer Vision SLAM, this paper provides references to researchers in related fields. Methods: Computer Vision SLAM patents and literature were analyzed from the aspects of the algorithm, innovation, and application. Among them, there are more than 30 patents and nearly 30 pieces of literature in the past ten years. Results: This paper reviews the research progress of robot visual SLAM in the last 10 years, sum-marizes its typical features, especially describes the front part of the visual SLAM system in detail, describes the main advantages and disadvantages of each method, analyses the main problems in the development of robot visual SLAM, prospects its development trend, and finally discusses the related products and patents research status and future of robot visual SLAM technology. Conclusion: The Robot Vision SLAM can compare the texture information of the environment and identify the difference between the two environments, thus improving accuracy. However, the cur-rent SLAM algorithm is easy to fail in fast motion and highly dynamic environments, most SLAM action plans are inefficient, and the image features of VSLAM are too distinguishable. Furthermore, more patents on the Robot Vision SLAM should also be invented.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60024758", "afid": "60024758", "affilname": "Harbin University of Science and Technology", "affiliation-city": "Harbin", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55685526100", "authid": "55685526100", "authname": "Zhang H.", "surname": "Zhang", "given-name": "Hongxin", "initials": "H.", "afid": [{"@_fa": "true", "$": "60024758"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/58667888200", "authid": "58667888200", "authname": "Jin H.", "surname": "Jin", "given-name": "Hui", "initials": "H.", "afid": [{"@_fa": "true", "$": "60024758"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57284339800", "authid": "57284339800", "authname": "Ma S.", "surname": "Ma", "given-name": "Shaowei", "initials": "S.", "afid": [{"@_fa": "true", "$": "60024758"}]}], "authkeywords": "Computer vision | direct method | feature point method | image features | image processing | SLAM", "article-number": "e090523216719", "source-id": "21100979315", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "11": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85173251692"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85173251692?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173251692&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85173251692&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85173251692", "dc:identifier": "SCOPUS_ID:85173251692", "eid": "2-s2.0-85173251692", "dc:title": "Real yields and PVSYST simulations: Comparative analysis based on four photovoltaic installations at Ibn Tofail University", "dc:creator": "Ait Omar O.", "prism:publicationName": "Energy Harvesting and Systems", "prism:issn": "23298774", "prism:eIssn": "23298766", "prism:pageRange": null, "prism:coverDate": "2023-01-01", "prism:coverDisplayDate": "2023", "prism:doi": "10.1515/ehs-2023-0064", "dc:description": "Since the PVSYST simulator is the most well-known software among researchers and PV experts, we chose to compare its results to those of the manual method. Thus, the objective of the article was to obtain the degree of similarity between the results of the PVSYST simulation and the manual calculation of the same parameters, based on the study of the photovoltaic systems of the University Ibn Tofail. Those installations are installed in the Faculty of Letters, Science, the Presidency and CFC. The later used in our study, have different parameters. Hence, to collect these parameters and their distinct data we used multiple sources. The datasheets of each components of the PV system contains the parameters that distinguish the devices therefore it was mandatory to look for that information, since it will facilitate our study. The meteorological database PVGIS, was our reference for the temperature and irradiation data. What's more is the PVSYST software that helps in the simulation of the PV system and thus having a detailed report with massive information. All this collection of data was aiming to help us comparing the results of yields and other parameters by manual calculation versus simulation in PVSYST. Morocco has demonstrated a strong commitment to combat climate change by embracing renewable energy, particularly photovoltaic systems. In this pursuit, universities like Ibn Tofail University (UIT) play a crucial role in addressing climate challenges and developing research solutions for mitigation. UIT actively participates in projects related to environmental protection and sustainable development, contributing to Morocco's growth and higher education advancement. As part of its efforts, UIT has been involved in implementing sustainable green projects and promoting renewable energy technologies. A specific study at UIT aimed to compare PVSYST simulation results with manual calculations for four PV systems on campus, considering parameters such as orientation, electrical installation, and panel types. The International Energy Agency (IEA) Photovoltaic Systems Program has established standards and a key concept, the yield factor, measuring the net energy production over a facility's lifetime compared to the energy used for construction, operation, and supply. By evaluating the accuracy and efficiency of PVSYST, researchers sought to advance the use of PV systems and contribute to Morocco's renewable energy goals. Such research not only aids in the progression of renewable energy technology but also aligns with Morocco's vision for sustainable development and environmental protection.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60011066", "afid": "60011066", "affilname": "Universit\u00e9 Ibn Tofail", "affiliation-city": "Kenitra", "affiliation-country": "Morocco"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/58632121900", "authid": "58632121900", "authname": "Ait Omar O.", "surname": "Ait Omar", "given-name": "Oumaima", "initials": "O.", "afid": [{"@_fa": "true", "$": "60011066"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57202209984", "authid": "57202209984", "authname": "El Fadil H.", "surname": "El Fadil", "given-name": "Hassan", "initials": "H.", "afid": [{"@_fa": "true", "$": "60011066"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/58631795600", "authid": "58631795600", "authname": "El Fezazi N.E.", "surname": "El Fezazi", "given-name": "Nour Eddine", "initials": "N.E.", "afid": [{"@_fa": "true", "$": "60011066"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57566753300", "authid": "57566753300", "authname": "Oumimoun Z.", "surname": "Oumimoun", "given-name": "Zakaria", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60011066"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57217102775", "authid": "57217102775", "authname": "Ait Errouhi A.", "surname": "Ait Errouhi", "given-name": "Ahmed", "initials": "A.", "afid": [{"@_fa": "true", "$": "60011066"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57195402696", "authid": "57195402696", "authname": "Choukai O.", "surname": "Choukai", "given-name": "Oumaima", "initials": "O.", "afid": [{"@_fa": "true", "$": "60011066"}]}], "authkeywords": "comparison | photovoltaic | production | PVSYST | solar", "source-id": "21100911339", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "12": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85165623672"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85165623672?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85165623672&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85165623672&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85165623672", "dc:identifier": "SCOPUS_ID:85165623672", "eid": "2-s2.0-85165623672", "dc:title": "Leveraging digital technologies for\u00a0circular economy in\u00a0construction industry: a\u00a0way forward", "dc:creator": "Rodrigo N.", "prism:publicationName": "Smart and Sustainable Built Environment", "prism:issn": "20466099", "prism:eIssn": "20466102", "prism:pageRange": null, "prism:coverDate": "2023-01-01", "prism:coverDisplayDate": "2023", "prism:doi": "10.1108/SASBE-05-2023-0111", "dc:description": "Purpose: This study aims to investigate the literature related to the use of digital technologies for promoting circular economy (CE) in the construction industry. Design/methodology/approach: A comprehensive approach was adopted, involving bibliometric analysis, text-mining analysis and content analysis to meet three objectives (1) to unveil the evolutionary progress of the field, (2) to identify the key research themes in the field and (3) to identify challenges hindering the implementation of digital technologies for CE. Findings: A total of 365 publications was analysed. The results revealed eight key digital technologies categorised into two main clusters including \u201cdigitalisation and advanced technologies\u201d and \u201csustainable construction technologies\u201d. The former involved technologies, namely machine learning, artificial intelligence, deep learning, big data analytics and object detection and computer vision that were used for (1) forecasting construction and demolition (C&D) waste generation, (2) waste identification and classification and (3)\u00a0computer vision for waste management. The latter included technologies such as Internet of Things (IoT), blockchain and building information modelling (BIM) that help optimise resource use, enhance transparency and sustainability practices in the industry. Overall, these technologies show great potential for improving waste management and enabling CE in construction. Originality/value: This research employs a holistic approach to provide a status-quo understanding of the digital technologies that can be utilised to support the implementation of CE in construction. Further, this study underlines the key challenges associated with adopting digital technologies, whilst also offering opportunities for future improvement of the field.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60009512", "afid": "60009512", "affilname": "The University of Adelaide", "affiliation-city": "Adelaide", "affiliation-country": "Australia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57966720000", "authid": "57966720000", "orcid": "0000-0003-0896-1239", "authname": "Rodrigo N.", "surname": "Rodrigo", "given-name": "Navodana", "initials": "N.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56703401200", "authid": "56703401200", "orcid": "0000-0002-4744-5088", "authname": "Omrany H.", "surname": "Omrany", "given-name": "Hossein", "initials": "H.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55359185100", "authid": "55359185100", "authname": "Chang R.", "surname": "Chang", "given-name": "Ruidong", "initials": "R.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/23020460400", "authid": "23020460400", "orcid": "0000-0002-8279-9666", "authname": "Zuo J.", "surname": "Zuo", "given-name": "Jian", "initials": "J.", "afid": [{"@_fa": "true", "$": "60009512"}]}], "authkeywords": "Circular economy | Construction industry | Construction waste | Digital technologies | Digitalisation | Sustainable construction | Waste management | Waste recognition", "source-id": "21100385605", "fund-no": "undefined", "fund-sponsor": "University of Adelaide", "openaccess": "0", "openaccessFlag": false}, "13": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85141378950"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85141378950?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85141378950&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85141378950&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85141378950", "dc:identifier": "SCOPUS_ID:85141378950", "eid": "2-s2.0-85141378950", "dc:title": "Long-term Visual Tracking: Review and Experimental Comparison", "dc:creator": "Liu C.", "prism:publicationName": "Machine Intelligence Research", "prism:issn": "2731538X", "prism:eIssn": "27315398", "prism:volume": "19", "prism:issueIdentifier": "6", "prism:pageRange": "512-530", "prism:coverDate": "2022-12-01", "prism:coverDisplayDate": "December 2022", "prism:doi": "10.1007/s11633-022-1344-1", "dc:description": "As a fundamental task in computer vision, visual object tracking has received much attention in recent years. Most studies focus on short-term visual tracking which addresses shorter videos and always-visible targets. However, long-term visual tracking is much closer to practical applications with more complicated challenges. There exists a longer duration such as minute-level or even hour-level in the long-term tracking task, and the task also needs to handle more frequent target disappearance and reappearance. In this paper, we provide a thorough review of long-term tracking, summarizing long-term tracking algorithms from two perspectives: framework architectures and utilization of intermediate tracking results. Then we provide a detailed description of existing benchmarks and corresponding evaluation protocols. Furthermore, we conduct extensive experiments and analyse the performance of trackers on six benchmarks: VOTLT2018, VOTLT2019 (2020/2021), OxUvA, LaSOT, TLP and the long-term subset of VTUAV-V. Finally, we discuss the future prospects from multiple perspectives, including algorithm design and benchmark construction. To our knowledge, this is the first comprehensive survey for long-term visual object tracking. The relevant content is available at https://github.com/wangdong-dut/Long-term-Visual-Tracking.", "citedby-count": "4", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60069722", "afid": "60069722", "affilname": "Dalian Minzu University", "affiliation-city": "Dalian", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60004538", "afid": "60004538", "affilname": "Dalian University of Technology", "affiliation-city": "Dalian", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57190496811", "authid": "57190496811", "orcid": "0000-0002-2018-7162", "authname": "Liu C.", "surname": "Liu", "given-name": "Chang", "initials": "C.", "afid": [{"@_fa": "true", "$": "60004538"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57955898000", "authid": "57955898000", "authname": "Chen X.F.", "surname": "Chen", "given-name": "Xiao Fan", "initials": "X.F.", "afid": [{"@_fa": "true", "$": "60004538"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/35291404500", "authid": "35291404500", "authname": "Bo C.J.", "surname": "Bo", "given-name": "Chun Juan", "initials": "C.J.", "afid": [{"@_fa": "true", "$": "60004538"}, {"@_fa": "true", "$": "60069722"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/56918730700", "authid": "56918730700", "orcid": "0000-0002-6976-4004", "authname": "Wang D.", "surname": "Wang", "given-name": "Dong", "initials": "D.", "afid": [{"@_fa": "true", "$": "60004538"}]}], "authkeywords": "long-term tracking | online update | re-detection | short-term tracking | Visual object tracking", "source-id": "21101072017", "fund-acr": "NSFC", "fund-no": "8091B032155", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "14": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85123569408"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85123569408?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85123569408&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85123569408&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85123569408", "dc:identifier": "SCOPUS_ID:85123569408", "eid": "2-s2.0-85123569408", "dc:title": "String kernels construction and fusion: a survey with bioinformatics application", "dc:creator": "Qi R.", "prism:publicationName": "Frontiers of Computer Science", "prism:issn": "20952228", "prism:eIssn": "20952236", "prism:volume": "16", "prism:issueIdentifier": "6", "prism:pageRange": null, "prism:coverDate": "2022-12-01", "prism:coverDisplayDate": "December 2022", "prism:doi": "10.1007/s11704-021-1118-x", "dc:description": "The kernel method, especially the kernel-fusion method, is widely used in social networks, computer vision, bioinformatics, and other applications. It deals effectively with nonlinear classification problems, which can map linearly inseparable biological sequence data from low to high-dimensional space for more accurate differentiation, enabling the use of kernel methods to predict the structure and function of sequences. Therefore, the kernel method is significant in the solution of bioinformatics problems. Various kernels applied in bioinformatics are explained clearly, which can help readers to select proper kernels to distinguish tasks. Mass biological sequence data occur in practical applications. Research of the use of machine learning methods to obtain knowledge, and how to explore the structure and function of biological methods for theoretical prediction, have always been emphasized in bioinformatics. The kernel method has gradually become an important learning algorithm that is widely used in gene expression and biological sequence prediction. This review focuses on the requirements of classification tasks of biological sequence data. It studies kernel methods and optimization algorithms, including methods of constructing kernel matrices based on the characteristics of biological sequences and kernel fusion methods existing in a multiple kernel learning framework.", "citedby-count": "6", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60019533", "afid": "60019533", "affilname": "Tianjin University", "affiliation-city": "Tianjin", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60005465", "afid": "60005465", "affilname": "University of Electronic Science and Technology of China", "affiliation-city": "Chengdu", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60001340", "afid": "60001340", "affilname": "Hainan Normal University", "affiliation-city": "Haikou", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57199324151", "authid": "57199324151", "authname": "Qi R.", "surname": "Qi", "given-name": "Ren", "initials": "R.", "afid": [{"@_fa": "true", "$": "60019533"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56477986800", "authid": "56477986800", "authname": "Guo F.", "surname": "Guo", "given-name": "Fei", "initials": "F.", "afid": [{"@_fa": "true", "$": "60019533"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/23391564900", "authid": "23391564900", "authname": "Zou Q.", "surname": "Zou", "given-name": "Quan", "initials": "Q.", "afid": [{"@_fa": "true", "$": "60005465"}, {"@_fa": "true", "$": "60001340"}]}], "authkeywords": "biological sequences analysis | kernel fusion methods | multiple kernel learning | support vector machines", "article-number": "166904", "source-id": "21100200426", "fund-acr": "NSFC", "fund-no": "61771331", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "15": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85122058447"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85122058447?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85122058447&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85122058447&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85122058447", "dc:identifier": "SCOPUS_ID:85122058447", "eid": "2-s2.0-85122058447", "dc:title": "Hyperbolic Deep Neural Networks: A Survey", "dc:creator": "Peng W.", "prism:publicationName": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "prism:issn": "01628828", "prism:eIssn": "19393539", "prism:volume": "44", "prism:issueIdentifier": "12", "prism:pageRange": "10023-10044", "prism:coverDate": "2022-12-01", "prism:coverDisplayDate": "1 December 2022", "prism:doi": "10.1109/TPAMI.2021.3136921", "dc:description": "Recently, hyperbolic deep neural networks (HDNNs) have been gaining momentum as the deep representations in the hyperbolic space provide high fidelity embeddings with few dimensions, especially for data possessing hierarchical structure. Such a hyperbolic neural architecture is quickly extended to different scientific fields, including natural language processing, single-cell RNA-sequence analysis, graph embedding, financial analysis, and computer vision. The promising results demonstrate its superior capability, significant compactness of the model, and a substantially better physical interpretability than its counterpart in the euclidean space. To stimulate future research, this paper presents a comprehensive review of the literature around the neural components in the construction of HDNN, as well as the generalization of the leading deep approaches to the hyperbolic space. It also presents current applications of various tasks, together with insightful observations and identifying open questions and promising future directions.", "citedby-count": "19", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60012954", "afid": "60012954", "affilname": "Oulun Yliopisto", "affiliation-city": "Oulu", "affiliation-country": "Finland"}], "pubmed-id": "34932472", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57212636680", "authid": "57212636680", "orcid": "0000-0002-2892-5764", "authname": "Peng W.", "surname": "Peng", "given-name": "Wei", "initials": "W.", "afid": [{"@_fa": "true", "$": "60012954"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57222017609", "authid": "57222017609", "authname": "Varanka T.", "surname": "Varanka", "given-name": "Tuomas", "initials": "T.", "afid": [{"@_fa": "true", "$": "60012954"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57219739625", "authid": "57219739625", "authname": "Mostafa A.", "surname": "Mostafa", "given-name": "Abdelrahman", "initials": "A.", "afid": [{"@_fa": "true", "$": "60012954"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/56023994700", "authid": "56023994700", "orcid": "0000-0001-5884-8475", "authname": "Shi H.", "surname": "Shi", "given-name": "Henglin", "initials": "H.", "afid": [{"@_fa": "true", "$": "60012954"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/47661917700", "authid": "47661917700", "orcid": "0000-0003-3694-206X", "authname": "Zhao G.", "surname": "Zhao", "given-name": "Guoying", "initials": "G.", "afid": [{"@_fa": "true", "$": "60012954"}]}], "authkeywords": "hyperbolic neural networks | Lorentz model | Neural networks on Riemannian manifold | Poincar\u00c3\u00a9 model", "source-id": "24254", "fund-acr": "AKA", "fund-no": "328115", "fund-sponsor": "Academy of Finland", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherhybridgold"}, {"$": "repository"}, {"$": "repositoryvor"}, {"$": "repositoryam"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Hybrid Gold"}, {"$": "Green"}]}}, "16": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85111137421"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85111137421?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85111137421&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85111137421&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85111137421", "dc:identifier": "SCOPUS_ID:85111137421", "eid": "2-s2.0-85111137421", "dc:title": "A scientometric review of construction progress monitoring studies", "dc:creator": "Patel T.", "prism:publicationName": "Engineering, Construction and Architectural Management", "prism:issn": "09699988", "prism:volume": "29", "prism:issueIdentifier": "9", "prism:pageRange": "3237-3266", "prism:coverDate": "2022-11-24", "prism:coverDisplayDate": "24 November 2022", "prism:doi": "10.1108/ECAM-10-2020-0799", "dc:description": "Purpose: This article aims to explore valuable insights into the construction progress monitoring (CPM) research domain, which include main research topics, knowledge gaps and future research themes. For a long time, CPM has been significantly researched with increasing enthusiasm. Although a few review studies have been carried out, there is non-existence of a quantitative review study that can deliver a holistic picture of CPM. Design/methodology/approach: The science mapping-based scientometric analysis was systematically processed with 1,835 CPM-related journal articles retrieved from Scopus. The co-authorship analysis and direct citation analysis were carried out to identify the most influential researchers, countries and publishers of the knowledge domain. The co-occurrence analysis of keyword was assessed to reveal the most dominating research topics and research trend with the visual representation of the considered research domain. Findings: This study reveals seven clusters of main research topics from the keyword co-occurrence analysis. The evolution of research confirms that CPM-related research studies were mainly focused on fundamental and traditional CPM research topics before 2007. The period between 2007 and 2020 has seen a shift of research efforts towards digitalization and automation. The result suggests Building Information Modelling (BIM) as the most common, growing and influential research topic in the CPM research domain. It has been used in combination with different data acquisition technologies (e.g. photogrammetry, videogrammetry, laser scanning, Internet of Things (IoT) sensors) and data analytics approaches (e.g. machine learning and computer vision). Practical implications: This study provides the horizon of potential research in the research domain of CPM to researchers, policymakers and practitioners by availing of main research themes, current knowledge gaps and future research directions. Originality/value: This paper represents the first scientometric study depicting the state-of-the-art of the research by assessing the current knowledge domain of CPM.", "citedby-count": "14", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020585", "afid": "60020585", "affilname": "University of Canterbury", "affiliation-city": "Christchurch", "affiliation-country": "New Zealand"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60005686", "afid": "60005686", "affilname": "The University of Auckland", "affiliation-city": "Auckland", "affiliation-country": "New Zealand"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57213805229", "authid": "57213805229", "orcid": "0000-0002-1242-1932", "authname": "Patel T.", "surname": "Patel", "given-name": "Tirth", "initials": "T.", "afid": [{"@_fa": "true", "$": "60020585"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56602167900", "authid": "56602167900", "authname": "Guo B.H.W.", "surname": "Guo", "given-name": "Brian H.W.", "initials": "B.H.W.", "afid": [{"@_fa": "true", "$": "60020585"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57072337800", "authid": "57072337800", "orcid": "0000-0001-6150-6126", "authname": "Zou Y.", "surname": "Zou", "given-name": "Yang", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60005686"}]}], "authkeywords": "Building information modelling | Construction | Project management | Scheduling | Technology", "source-id": "15249", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "17": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097072221"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097072221?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097072221&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097072221&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097072221", "dc:identifier": "SCOPUS_ID:85097072221", "eid": "2-s2.0-85097072221", "dc:title": "The renaissance of augmented reality in construction: history, present status and future directions", "dc:creator": "Chen K.", "prism:publicationName": "Smart and Sustainable Built Environment", "prism:issn": "20466099", "prism:eIssn": "20466102", "prism:volume": "11", "prism:issueIdentifier": "3", "prism:pageRange": "575-592", "prism:coverDate": "2022-11-22", "prism:coverDisplayDate": "22 November 2022", "prism:doi": "10.1108/SASBE-08-2020-0124", "dc:description": "Purpose: Augmented reality (AR) has become one of the most promising technologies in construction since it can seamlessly connect the physical construction environment and virtual contents. In view of the recent research efforts, this study attempts to summarize the latest research achievements and inform future development of AR in construction. Design/methodology/approach: The review was conducted in three steps. First, a keyword search was adopted, and 546 papers were found from Scopus and Web of Science. Second, each paper was screened based on the selection criteria, and a final set of 69 papers was obtained. Third, specific AR applications and the associated technical details were extracted from the 69 papers for further analysis. Findings: The review shows that: (1) design assessment, process monitoring and maintenance management and operation were the most frequently cited AR applications in the design, construction, and operation stages, respectively; (2) information browser and tangible interaction were more frequently adopted than collaborative interaction and hybrid interaction; and (3) AR has been integrated with BIM, computer vision, and cloud computing for enhanced functions. Originality/value: The contributions of this study to the body of knowledge are twofold. First, this study extends the understanding of AR applications in the construction setting. Second, this study identifies possible improvements in the design and development of AR systems in order to leverage their benefits to construction.", "citedby-count": "19", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025761", "afid": "60025761", "affilname": "Huazhong University of Science and Technology", "affiliation-city": "Wuhan", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60006541", "afid": "60006541", "affilname": "The University of Hong Kong", "affiliation-city": "Hong Kong", "affiliation-country": "Hong Kong"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57886821300", "authid": "57886821300", "authname": "Chen K.", "surname": "Chen", "given-name": "Ke", "initials": "K.", "afid": [{"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56720069500", "authid": "56720069500", "orcid": "0000-0003-2217-3693", "authname": "Xue F.", "surname": "Xue", "given-name": "Fan", "initials": "F.", "afid": [{"@_fa": "true", "$": "60006541"}]}], "authkeywords": "Augmented reality | Construction management | Interaction | Physical environment | Review | Virtual content", "source-id": "21100385605", "fund-no": "2019kfyXJJS185", "fund-sponsor": "Fundamental Research Funds for the Central Universities", "openaccess": "0", "openaccessFlag": false}, "18": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137101512"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137101512?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137101512&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137101512&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137101512", "dc:identifier": "SCOPUS_ID:85137101512", "eid": "2-s2.0-85137101512", "dc:title": "Retinal Vessel Segmentation, a Review of Classic and Deep Methods", "dc:creator": "Khandouzi A.", "prism:publicationName": "Annals of Biomedical Engineering", "prism:issn": "00906964", "prism:eIssn": "15739686", "prism:volume": "50", "prism:issueIdentifier": "10", "prism:pageRange": "1292-1314", "prism:coverDate": "2022-10-01", "prism:coverDisplayDate": "October 2022", "prism:doi": "10.1007/s10439-022-03058-0", "dc:description": "Retinal illnesses such as diabetic retinopathy (DR) are the main causes of vision loss. In the early recognition of eye diseases, the segmentation of blood vessels in retina images plays an important role. Different symptoms of ocular diseases can be identified by the geometric features of ocular arteries. However, due to the complex construction of the blood vessels and their different thicknesses, segmenting the retina image is a challenging task. There are a number of algorithms that helped the detection of retinal diseases. This paper presents an overview of papers from 2016 to 2022 that discuss machine learning and deep learning methods for automatic vessel segmentation. The methods are divided into two groups: Deep learning-based, and classic methods. Algorithms, classifiers, pre-processing and specific techniques of each group is described, comprehensively. The performances of recent works are compared based on their achieved accuracy in different datasets in inclusive tables. A survey of most popular datasets like DRIVE, STARE, HRF and CHASE_DB1 is also given in this paper. Finally, a list of findings from this review is presented in the conclusion section.", "citedby-count": "9", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60089290", "afid": "60089290", "affilname": "Babol Noshirvani University of Technology", "affiliation-city": "Babol", "affiliation-country": "Iran"}], "pubmed-id": "36008569", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57558041300", "authid": "57558041300", "authname": "Khandouzi A.", "surname": "Khandouzi", "given-name": "Ali", "initials": "A.", "afid": [{"@_fa": "true", "$": "60089290"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57870248100", "authid": "57870248100", "authname": "Ariafar A.", "surname": "Ariafar", "given-name": "Ali", "initials": "A.", "afid": [{"@_fa": "true", "$": "60089290"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57869953100", "authid": "57869953100", "authname": "Mashayekhpour Z.", "surname": "Mashayekhpour", "given-name": "Zahra", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60089290"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57559069100", "authid": "57559069100", "authname": "Pazira M.", "surname": "Pazira", "given-name": "Milad", "initials": "M.", "afid": [{"@_fa": "true", "$": "60089290"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/54897966700", "authid": "54897966700", "orcid": "0000-0002-2882-4613", "authname": "Baleghi Y.", "surname": "Baleghi", "given-name": "Yasser", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60089290"}]}], "authkeywords": "Blood vessels | Convolutional neural network | Deep learning | Medical imaging | Retinal vessel segmentation", "source-id": "27474", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "19": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135145463"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135145463?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85135145463&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85135145463&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0168169922005415"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85135145463", "dc:identifier": "SCOPUS_ID:85135145463", "eid": "2-s2.0-85135145463", "dc:title": "Barriers to computer vision applications in pig production facilities", "dc:creator": "Li J.", "prism:publicationName": "Computers and Electronics in Agriculture", "prism:issn": "01681699", "prism:volume": "200", "prism:pageRange": null, "prism:coverDate": "2022-09-01", "prism:coverDisplayDate": "September 2022", "prism:doi": "10.1016/j.compag.2022.107227", "pii": "S0168169922005415", "dc:description": "Surveillance and analysis of behavior can be used to detect and characterize health disruption and welfare status in animals. The accurate identification of changes in behavior is a time-consuming task for caretakers in large, commercial pig production systems and requires strong observational skills and a working knowledge of animal husbandry and livestock systems operations. In recent years, many studies have explored the use of various technologies and sensors to assist animal caretakers in monitoring animal activity and behavior. Of these technologies, computer vision offers the most consistent promise as an effective aid in animal care, and yet, a systematic review of the state of application of this technology indicates that there are many significant barriers to its widespread adoption and successful utilization in commercial production system settings. One of the most important of these barriers is the recognition of the sources of errors from objective behavior labeling that are not measurable by current algorithm performance evaluations. Additionally, there is a significant disconnect between the remarkable advances in computer vision research interests and the integration of advances and practical needs being instituted by scientific experts working in commercial animal production partnerships. This lack of synergy between experts in the computer vision and animal health and production sectors means that existing and emerging datasets tend to have a very particular focus that cannot be easily pivoted or extended for use in other contexts, resulting in a generality versus particularity conundrum. This goal of this paper is to help catalogue and consider the major obstacles and impediments to the effective use of computer vision associated technologies in the swine industry by offering a systematic analysis of computer vision applications specific to commercial pig management by reviewing and summarizing the following: (i) the purpose and associated challenges of computer vision applications in pig behavior analysis; (ii) the use of computer vision algorithms and datasets for pig husbandry and management tasks; (iii) the process of dataset construction for computer vision algorithm development. In this appraisal, we outline common difficulties and challenges associated with each of these themes and suggest possible solutions. Finally, we highlight the opportunities for future research in computer vision applications that can build upon existing knowledge of pig management by extending our capability to interpret pig behaviors and thereby overcome the current barriers to applying computer vision technologies to pig production systems. In conclusion, we believe productive collaboration between animal-based scientists and computer-based scientists may accelerate animal behavior studies and lead the computer vision technologies to commercial applications in pig production facilities.", "citedby-count": "7", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60013551", "afid": "60013551", "affilname": "China Agricultural University", "affiliation-city": "Beijing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60000745", "afid": "60000745", "affilname": "University of Illinois Urbana-Champaign", "affiliation-city": "Urbana", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "10", "$": "10"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57216664214", "authid": "57216664214", "orcid": "0000-0003-3062-5768", "authname": "Li J.", "surname": "Li", "given-name": "Jiangong", "initials": "J.", "afid": [{"@_fa": "true", "$": "60000745"}, {"@_fa": "true", "$": "60013551"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57198352792", "authid": "57198352792", "authname": "Green-Miller A.R.", "surname": "Green-Miller", "given-name": "Angela R.", "initials": "A.R.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57221044307", "authid": "57221044307", "authname": "Hu X.", "surname": "Hu", "given-name": "Xiaodan", "initials": "X.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/56763962100", "authid": "56763962100", "orcid": "0000-0002-5509-445X", "authname": "Lucic A.", "surname": "Lucic", "given-name": "Ana", "initials": "A.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57197314551", "authid": "57197314551", "authname": "Mahesh Mohan M.R.", "surname": "Mahesh Mohan", "given-name": "M. R.", "initials": "M.R.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/6602508522", "authid": "6602508522", "orcid": "0000-0003-2538-2845", "authname": "Dilger R.N.", "surname": "Dilger", "given-name": "Ryan N.", "initials": "R.N.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/57204022710", "authid": "57204022710", "authname": "Condotta I.C.F.S.", "surname": "Condotta", "given-name": "Isabella C.F.S.", "initials": "I.C.F.S.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "8", "author-url": "https://api.elsevier.com/content/author/author_id/7004887050", "authid": "7004887050", "authname": "Aldridge B.", "surname": "Aldridge", "given-name": "Brian", "initials": "B.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "9", "author-url": "https://api.elsevier.com/content/author/author_id/56485125500", "authid": "56485125500", "authname": "Hart J.M.", "surname": "Hart", "given-name": "John M.", "initials": "J.M.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "10", "author-url": "https://api.elsevier.com/content/author/author_id/35515078200", "authid": "35515078200", "authname": "Ahuja N.", "surname": "Ahuja", "given-name": "Narendra", "initials": "N.", "afid": [{"@_fa": "true", "$": "60000745"}]}], "authkeywords": "Behavior | Computer vision | Dataset | Deep learning | Precision livestock farming | Swine", "article-number": "107227", "source-id": "30441", "fund-acr": "NIFA", "fund-no": "1024178", "fund-sponsor": "National Institute of Food and Agriculture", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfree2read"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Bronze"}]}}, "20": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108456365"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108456365?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108456365&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85108456365&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85108456365", "dc:identifier": "SCOPUS_ID:85108456365", "eid": "2-s2.0-85108456365", "dc:title": "Productivity monitoring in building construction projects: a systematic review", "dc:creator": "Alaloul W.S.", "prism:publicationName": "Engineering, Construction and Architectural Management", "prism:issn": "09699988", "prism:volume": "29", "prism:issueIdentifier": "7", "prism:pageRange": "2760-2785", "prism:coverDate": "2022-08-03", "prism:coverDisplayDate": "3 August 2022", "prism:doi": "10.1108/ECAM-03-2021-0211", "dc:description": "Purpose: The unique nature of the construction sector makes it fall behind other sectors in terms of productivity. Monitoring construction productivity is crucial for the construction project's success. Current practices for construction productivity monitoring are time-consuming, manned and error prone. Although previous studies have been implemented toward reducing these limitations, a gap still exists in the automated monitoring of construction productivity. Design/methodology/approach: This study aims to investigate and assess the different techniques used for monitoring productivity in building construction projects. Therefore, a mixed review methodology (bibliometric analysis and systematic review) was adopted. All the related publications were collected from different databases, which were further screened to get the most relevant based on the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) criteria. Findings: A detailed review was performed, and it was found that traditional methods, computer vision-based and photogrammetry are the most adopted data acquisition for productivity monitoring of building projects, respectively. Machine learning algorithms (ANN, SVM) and BIM were integrated with monitoring tools and technologies to enhance the automated monitoring performance in construction productivity. Also, it was observed that current studies did not cover all the complex construction job sites and they were applied based on a small sample of construction workers and machines separately. Originality/value: This review paper contributes to the literature on construction management by providing insight into different productivity monitoring techniques.", "citedby-count": "14", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60062395", "afid": "60062395", "affilname": "Al-Balqa Applied University", "affiliation-city": "Al Salt", "affiliation-country": "Jordan"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60001278", "afid": "60001278", "affilname": "Universiti Teknologi PETRONAS", "affiliation-city": "Seri Iskandar", "affiliation-country": "Malaysia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57188692830", "authid": "57188692830", "authname": "Alaloul W.S.", "surname": "Alaloul", "given-name": "Wesam Salah", "initials": "W.S.", "afid": [{"@_fa": "true", "$": "60001278"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56719770500", "authid": "56719770500", "authname": "Alzubi K.M.", "surname": "Alzubi", "given-name": "Khalid M.", "initials": "K.M.", "afid": [{"@_fa": "true", "$": "60001278"}, {"@_fa": "true", "$": "60062395"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55812372900", "authid": "55812372900", "authname": "Malkawi A.B.", "surname": "Malkawi", "given-name": "Ahmad B.", "initials": "A.B.", "afid": [{"@_fa": "true", "$": "60062395"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57224865854", "authid": "57224865854", "authname": "Al Salaheen M.", "surname": "Al Salaheen", "given-name": "Marsail", "initials": "M.", "afid": [{"@_fa": "true", "$": "60001278"}, {"@_fa": "true", "$": "60062395"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57213145013", "authid": "57213145013", "authname": "Musarat M.A.", "surname": "Musarat", "given-name": "Muhammad Ali", "initials": "M.A.", "afid": [{"@_fa": "true", "$": "60001278"}]}], "authkeywords": "Construction | Monitoring techniques | Productivity measuring | Productivity monitoring", "source-id": "15249", "fund-acr": "UTP", "fund-no": "undefined", "fund-sponsor": "Universiti Teknologi Petronas", "openaccess": "0", "openaccessFlag": false}, "21": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136293452"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136293452?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136293452&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85136293452&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85136293452", "dc:identifier": "SCOPUS_ID:85136293452", "eid": "2-s2.0-85136293452", "dc:title": "A Review of Vision-Laser-Based Civil Infrastructure Inspection and Monitoring", "dc:creator": "Zhou H.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "22", "prism:issueIdentifier": "15", "prism:pageRange": null, "prism:coverDate": "2022-08-01", "prism:coverDisplayDate": "August 2022", "prism:doi": "10.3390/s22155882", "dc:description": "Structural health and construction security are important problems in civil engineering. Regular infrastructure inspection and monitoring methods are mostly performed manually. Early automatic structural health monitoring techniques were mostly based on contact sensors, which usually are difficult to maintain in complex infrastructure environments. Therefore, non-contact infrastructure inspection and monitoring techniques received increasing interest in recent years, and they are widely used in all aspects of infrastructure life, owing to their convenience and non-destructive properties. This paper provides an overview of vision-based inspection and vision\u2013laser-based monitoring techniques and applications. The inspection part includes image-processing algorithms, object detection, and semantic segmentation. In particular, infrastructure monitoring involves not only visual technologies but also different fusion methods of vision and lasers. Furthermore, the most important challenges for future automatic non-contact inspections and monitoring are discussed and the paper correspondingly concludes with state-of-the-art algorithms and applications to resolve these challenges.", "citedby-count": "9", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60092860", "afid": "60092860", "affilname": "Beijing University of Civil Engineering and Architecture", "affiliation-city": "Beijing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60013551", "afid": "60013551", "affilname": "China Agricultural University", "affiliation-city": "Beijing", "affiliation-country": "China"}], "pubmed-id": "35957439", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/7404743342", "authid": "7404743342", "orcid": "0000-0002-2186-8082", "authname": "Zhou H.", "surname": "Zhou", "given-name": "Huixing", "initials": "H.", "afid": [{"@_fa": "true", "$": "60092860"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57828762800", "authid": "57828762800", "orcid": "0000-0003-3130-4632", "authname": "Xu C.", "surname": "Xu", "given-name": "Chongwen", "initials": "C.", "afid": [{"@_fa": "true", "$": "60092860"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55761515900", "authid": "55761515900", "authname": "Tang X.", "surname": "Tang", "given-name": "Xiuying", "initials": "X.", "afid": [{"@_fa": "true", "$": "60013551"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57273141700", "authid": "57273141700", "authname": "Wang S.", "surname": "Wang", "given-name": "Shun", "initials": "S.", "afid": [{"@_fa": "true", "$": "60092860"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57272655200", "authid": "57272655200", "authname": "Zhang Z.", "surname": "Zhang", "given-name": "Zhongyue", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60092860"}]}], "authkeywords": "infrastructure inspection and monitoring | non-contact | sensor fusion | vision\u2013laser-based", "article-number": "5882", "source-id": "130124", "fund-acr": "MOHURD", "fund-no": "KZ202110016024", "fund-sponsor": "Beijing Municipal Commission of Education", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "22": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85130301573"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85130301573?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85130301573&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85130301573&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85130301573", "dc:identifier": "SCOPUS_ID:85130301573", "eid": "2-s2.0-85130301573", "dc:title": "Emerging tissue engineering strategies for the corneal regeneration", "dc:creator": "Tafti M.F.", "prism:publicationName": "Journal of Tissue Engineering and Regenerative Medicine", "prism:issn": "19326254", "prism:eIssn": "19327005", "prism:volume": "16", "prism:issueIdentifier": "8", "prism:pageRange": "683-706", "prism:coverDate": "2022-08-01", "prism:coverDisplayDate": "August 2022", "prism:doi": "10.1002/term.3309", "dc:description": "Cornea as the outermost layer of the eye is at risk of various genetic and environmental diseases that can damage the cornea and impair vision. Corneal transplantation is among the most applicable surgical procedures for repairing the defected tissue. However, the scarcity of healthy tissue donations as well as transplantation failure has remained as the biggest challenges in confront of corneal grafting. Therefore, alternative approaches based on stem-cell transplantation and classic regenerative medicine have been developed for corneal regeneration. In this review, the application and limitation of the recently-used advanced approaches for regeneration of cornea are discussed. Additionally, other emerging powerful techniques such as 5D printing as a new branch of scaffold-based technologies for construction of tissues other than the cornea are highlighted and suggested as alternatives for corneal reconstruction. The introduced novel techniques may have great potential for clinical applications in corneal repair including disease modeling, 3D pattern scheming, and personalized medicine.", "citedby-count": "4", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60029767", "afid": "60029767", "affilname": "Universidad Miguel Hern\u00e1ndez de Elche", "affiliation-city": "Elche", "affiliation-country": "Spain"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60024530", "afid": "60024530", "affilname": "Semnan University of Medical Sciences and Health Services", "affiliation-city": "Semnan", "affiliation-country": "Iran"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60023789", "afid": "60023789", "affilname": "VISSUM Corporaci\u00f3n Oftalmologica", "affiliation-city": "Alicante", "affiliation-country": "Spain"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60019580", "afid": "60019580", "affilname": "National Institute for Genetic Engineering and Biotechnology Iran", "affiliation-city": "Tehran", "affiliation-country": "Iran"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60010017", "afid": "60010017", "affilname": "Baqiyatallah University of Medical Sciences", "affiliation-city": "Tehran", "affiliation-country": "Iran"}], "pubmed-id": "35585479", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57696225200", "authid": "57696225200", "authname": "Tafti M.F.", "surname": "Tafti", "given-name": "Mahsa Fallah", "initials": "M.F.", "afid": [{"@_fa": "true", "$": "60019580"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55053606400", "authid": "55053606400", "authname": "Aghamollaei H.", "surname": "Aghamollaei", "given-name": "Hossein", "initials": "H.", "afid": [{"@_fa": "true", "$": "60010017"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57203680638", "authid": "57203680638", "orcid": "0000-0002-4645-8661", "authname": "Moghaddam M.M.", "surname": "Moghaddam", "given-name": "Mehrdad Moosazadeh", "initials": "M.M.", "afid": [{"@_fa": "true", "$": "60010017"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57055717700", "authid": "57055717700", "authname": "Jadidi K.", "surname": "Jadidi", "given-name": "Khosrow", "initials": "K.", "afid": [{"@_fa": "true", "$": "60024530"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/7101661048", "authid": "7101661048", "authname": "Alio J.L.", "surname": "Alio", "given-name": "Jorge L.", "initials": "J.L.", "afid": [{"@_fa": "true", "$": "60023789"}, {"@_fa": "true", "$": "60023789"}, {"@_fa": "true", "$": "60029767"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/12902572400", "authid": "12902572400", "authname": "Faghihi S.", "surname": "Faghihi", "given-name": "Shahab", "initials": "S.", "afid": [{"@_fa": "true", "$": "60019580"}]}], "authkeywords": "3D model | bioprinting | cell therapy | cornea | personalized medicine | scaffold fabrication | tissue regeneration", "source-id": "10700153301", "fund-acr": "NIGEB", "fund-no": "undefined", "fund-sponsor": "National Institute for Genetic Engineering and Biotechnology", "openaccess": "0", "openaccessFlag": false}, "23": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85129465824"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85129465824?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85129465824&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85129465824&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580522001753"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85129465824", "dc:identifier": "SCOPUS_ID:85129465824", "eid": "2-s2.0-85129465824", "dc:title": "Deep learning-based data analytics for safety in construction", "dc:creator": "Liu J.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "140", "prism:pageRange": null, "prism:coverDate": "2022-08-01", "prism:coverDisplayDate": "August 2022", "prism:doi": "10.1016/j.autcon.2022.104302", "pii": "S0926580522001753", "dc:description": "Deep learning has been acknowledged as being robust in managing and controlling the performance of construction safety. However, there is an absence of state-of-the-art review that examines its developments and applications from the perspective of data utilization. Our review aims to fill this void and addresses the following research question: what developments in deep learning for data mining have been made to manage safety in construction? We systematically review the extant literature of deep-learning-based data analytics for construction safety management, including: (1) image/video-based; (2) text-based; (3) non-visual sensor-based; and (4) multi-modal-based. The review revealed three challenges of existing research in the construction industry: (1) lack of high-quality database; (2) inadequate ability of deep learning models; and (3) limited application scenarios. Based on our observations for the prevailing literature and practice, we identify that future research on safety management is needed and focused on the: (1) development of dynamic multi-modal knowledge graph; and (2) knowledge graph-based decision-making for safety. The application of deep learning is an emerging line of inquiry in construction, and this study not only identifies new research opportunities to support safety management, but also facilitates practicing deep learning for construction projects.", "citedby-count": "14", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025761", "afid": "60025761", "affilname": "Huazhong University of Science and Technology", "affiliation-city": "Wuhan", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60022193", "afid": "60022193", "affilname": "University of Canberra", "affiliation-city": "Canberra", "affiliation-country": "Australia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57216800716", "authid": "57216800716", "authname": "Liu J.", "surname": "Liu", "given-name": "Jiajing", "initials": "J.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/23976309500", "authid": "23976309500", "authname": "Luo H.", "surname": "Luo", "given-name": "Hanbin", "initials": "H.", "afid": [{"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57314283300", "authid": "57314283300", "authname": "Liu H.", "surname": "Liu", "given-name": "Henry", "initials": "H.", "afid": [{"@_fa": "true", "$": "60022193"}]}], "authkeywords": "Computer vision | Deep learning | Knowledge graph | Natural language processing | Safety", "article-number": "104302", "source-id": "24931", "fund-acr": "NSFC", "fund-no": "51978302", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "24": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137350968"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137350968?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137350968&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137350968&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85137350968", "dc:identifier": "SCOPUS_ID:85137350968", "eid": "2-s2.0-85137350968", "dc:title": "Automated Computer Vision-Based Construction Progress Monitoring: A Systematic Review", "dc:creator": "Sami Ur Rehman M.", "prism:publicationName": "Buildings", "prism:eIssn": "20755309", "prism:volume": "12", "prism:issueIdentifier": "7", "prism:pageRange": null, "prism:coverDate": "2022-07-01", "prism:coverDisplayDate": "July 2022", "prism:doi": "10.3390/buildings12071037", "dc:description": "The progress monitoring (PM) of construction projects is an essential aspect of project control that enables the stakeholders to make timely decisions to ensure successful project delivery, but ongoing practices are largely manual and document-centric. However, the integration of technologically advanced tools into construction practices has shown the potential to automate construction PM (CPM) using real-time data collection, analysis, and visualization for effective and timely decision making. In this study, we assess the level of automation achieved through various methods that enable automated computer vision (CV)-based CPM. A detailed literature review is presented, discussing the complete process of CV-based CPM based on the research conducted between 2011 and 2021. The CV-based CPM process comprises four sub-processes: data acquisition, information retrieval, progress estimation, and output visualization. Most techniques encompassing these sub-processes require human intervention to perform the desired tasks, and the inter-connectivity among them is absent. We conclude that CV-based CPM research is centric on resolving technical feasibility studies using image-based processing of site data, which are still experimental and lack connectivity to its applications for construction management. This review highlighted the most efficient techniques involved in the CV-based CPM and accentuated the need for the inter-connectivity between sub-processes for an effective alternative to traditional practices.", "citedby-count": "12", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020321", "afid": "60020321", "affilname": "University of Southern Queensland", "affiliation-city": "Toowoomba", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60008665", "afid": "60008665", "affilname": "United Arab Emirates University", "affiliation-city": "Al Ain", "affiliation-country": "United Arab Emirates"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57215048690", "authid": "57215048690", "orcid": "0000-0003-3394-0157", "authname": "Sami Ur Rehman M.", "surname": "Sami Ur Rehman", "given-name": "Muhammad", "initials": "M.", "afid": [{"@_fa": "true", "$": "60008665"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55671258600", "authid": "55671258600", "orcid": "0000-0002-1063-6761", "authname": "Shafiq M.T.", "surname": "Shafiq", "given-name": "Muhammad Tariq", "initials": "M.T.", "afid": [{"@_fa": "true", "$": "60008665"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57209067688", "authid": "57209067688", "orcid": "0000-0002-6221-1175", "authname": "Ullah F.", "surname": "Ullah", "given-name": "Fahim", "initials": "F.", "afid": [{"@_fa": "true", "$": "60020321"}]}], "authkeywords": "automated progress monitoring | computer vision | construction progress monitoring | process assessment | systematic review | vision-based automation", "article-number": "1037", "source-id": "26980", "fund-no": "31N397", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryam"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "25": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85127703759"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85127703759?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85127703759&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85127703759&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580522001182"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127703759", "dc:identifier": "SCOPUS_ID:85127703759", "eid": "2-s2.0-85127703759", "dc:title": "Computer vision-based construction progress monitoring", "dc:creator": "Reja V.K.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "138", "prism:pageRange": null, "prism:coverDate": "2022-06-01", "prism:coverDisplayDate": "June 2022", "prism:doi": "10.1016/j.autcon.2022.104245", "pii": "S0926580522001182", "dc:description": "Automating the process of construction progress monitoring through computer vision can enable effective control of projects. Systematic classification of available methods and technologies is necessary to structure this complex, multi-stage process. Using the PRISMA framework, relevant studies in the area were identified. The various concepts, tools, technologies, and algorithms reported by these studies were iteratively categorised, developing an integrated process framework for Computer-Vision-Based Construction Progress Monitoring (CV-CPM). This framework comprises: data acquisition and 3D-reconstruction, as-built modelling, and progress assessment. Each stage is discussed in detail, positioning key studies, and concurrently comparing the methods used therein. The four levels of progress monitoring are defined and found to strongly influence all stages of the framework. The need for benchmarking CV-CPM pipelines and components are discussed, and potential research questions within each stage are identified. The relevance of CV-CPM to support emerging areas such as Digital Twin is also discussed.", "citedby-count": "25", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025757", "afid": "60025757", "affilname": "Indian Institute of Technology Madras", "affiliation-city": "Chennai", "affiliation-country": "India"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60023932", "afid": "60023932", "affilname": "University of Technology Sydney", "affiliation-city": "Sydney", "affiliation-country": "Australia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57210809822", "authid": "57210809822", "authname": "Reja V.K.", "surname": "Reja", "given-name": "Varun Kumar", "initials": "V.K.", "afid": [{"@_fa": "true", "$": "60025757"}, {"@_fa": "true", "$": "60023932"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/6603924844", "authid": "6603924844", "authname": "Varghese K.", "surname": "Varghese", "given-name": "Koshy", "initials": "K.", "afid": [{"@_fa": "true", "$": "60025757"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57208140329", "authid": "57208140329", "authname": "Ha Q.P.", "surname": "Ha", "given-name": "Quang Phuc", "initials": "Q.P.", "afid": [{"@_fa": "true", "$": "60023932"}]}], "authkeywords": "3D reconstruction | As-built modelling | Automated construction | Computer vision | Data acquisition | Digital Twin | Literature review | Point cloud | Progress monitoring | Scan to BIM", "article-number": "104245", "source-id": "24931", "fund-acr": "MoE", "fund-no": "undefined", "fund-sponsor": "Ministry of Education, India", "openaccess": "0", "openaccessFlag": false}, "26": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85127435611"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85127435611?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85127435611&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85127435611&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85127435611", "dc:identifier": "SCOPUS_ID:85127435611", "eid": "2-s2.0-85127435611", "dc:title": "Vision-Based Defect Inspection and Condition Assessment for Sewer Pipes: A Comprehensive Survey", "dc:creator": "Li Y.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "22", "prism:issueIdentifier": "7", "prism:pageRange": null, "prism:coverDate": "2022-04-01", "prism:coverDisplayDate": "April-1 2022", "prism:doi": "10.3390/s22072722", "dc:description": "Due to the advantages of economics, safety, and efficiency, vision-based analysis techniques have recently gained conspicuous advancements, enabling them to be extensively applied for autonomous constructions. Although numerous studies regarding the defect inspection and condition assessment in underground sewer pipelines have presently emerged, we still lack a thorough and comprehensive survey of the latest developments. This survey presents a systematical taxonomy of diverse sewer inspection algorithms, which are sorted into three categories that include defect classification, defect detection, and defect segmentation. After reviewing the related sewer defect inspection studies for the past 22 years, the main research trends are organized and discussed in detail according to the proposed technical taxonomy. In addition, different datasets and the evaluation metrics used in the cited literature are described and explained. Furthermore, the performances of the state-of-the-art methods are reported from the aspects of processing accuracy and speed.", "citedby-count": "10", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60027884", "afid": "60027884", "affilname": "Sejong University", "affiliation-city": "Seoul", "affiliation-country": "South Korea"}], "pubmed-id": "35408337", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57218425855", "authid": "57218425855", "authname": "Li Y.", "surname": "Li", "given-name": "Yanfen", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60027884"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57212682280", "authid": "57212682280", "authname": "Wang H.", "surname": "Wang", "given-name": "Hanxiang", "initials": "H.", "afid": [{"@_fa": "true", "$": "60027884"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57201389017", "authid": "57201389017", "authname": "Dang L.M.", "surname": "Dang", "given-name": "L. Minh", "initials": "L.M.", "afid": [{"@_fa": "true", "$": "60027884"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/7404036823", "authid": "7404036823", "authname": "Song H.K.", "surname": "Song", "given-name": "Hyoung Kyu", "initials": "H.K.", "afid": [{"@_fa": "true", "$": "60027884"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/23397814300", "authid": "23397814300", "authname": "Moon H.", "surname": "Moon", "given-name": "Hyeonjoon", "initials": "H.", "afid": [{"@_fa": "true", "$": "60027884"}]}], "authkeywords": "computer vision | condition assessment | defect inspection | sewer pipes | survey", "article-number": "2722", "source-id": "130124", "fund-acr": "MOE", "fund-no": "2020R1A6A1A03038540", "fund-sponsor": "Ministry of Education", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "27": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85124042191"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85124042191?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85124042191&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85124042191&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580522000267"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85124042191", "dc:identifier": "SCOPUS_ID:85124042191", "eid": "2-s2.0-85124042191", "dc:title": "Tag and IoT based safety hook monitoring for prevention of falls from height", "dc:creator": "Khan M.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "136", "prism:pageRange": null, "prism:coverDate": "2022-04-01", "prism:coverDisplayDate": "April 2022", "prism:doi": "10.1016/j.autcon.2022.104153", "pii": "S0926580522000267", "dc:description": "Monitoring the unsafe behavior of construction workers at risky elevations is essential for eliminating fall from height (FFH) accidents. This study aims to bridge the gap between technological advancements and their application in the construction industry by introducing real-time hybrid vision- and IoT-based systems for safety engineers to monitor the use of safety hooks at risky elevations in real-time. The proposed system for hybrid smart safety hooks (HSSH) integrates three components: 1) vision (AprilTag detection) and IoT sensors (IMU and Altimeter) based monitoring systems, 2) web-based management platform (WBMP), and 3) backend cloud server (BCS) storage system. The proposed system aims to help safety managers by efficiently automating multiple workers' safety monitoring in real-time at the complex construction sites where performing a hazardous activity at a risk height may lead to FFH fatality. WBMP system provides a mode of communication and visualization, whereas BCS records the behavior of every worker, facilitating mitigative planning by safety engineers. The proposed HSSH system enhanced the performance of the SSH and the feasibility of deployment at real construction sites. Future research will involve the extensive integration of sensors for detailed insights of workers exposed to other hazards during construction.", "citedby-count": "20", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60070785", "afid": "60070785", "affilname": "Ajman University", "affiliation-city": "Ajman", "affiliation-country": "United Arab Emirates"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60014237", "afid": "60014237", "affilname": "Chung-Ang University", "affiliation-city": "Seoul", "affiliation-country": "South Korea"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57226299781", "authid": "57226299781", "authname": "Khan M.", "surname": "Khan", "given-name": "Muhammad", "initials": "M.", "afid": [{"@_fa": "true", "$": "60014237"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57302210600", "authid": "57302210600", "authname": "Khalid R.", "surname": "Khalid", "given-name": "Rabia", "initials": "R.", "afid": [{"@_fa": "true", "$": "60014237"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57302052300", "authid": "57302052300", "authname": "Anjum S.", "surname": "Anjum", "given-name": "Sharjeel", "initials": "S.", "afid": [{"@_fa": "true", "$": "60014237"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57208717753", "authid": "57208717753", "authname": "Khan N.", "surname": "Khan", "given-name": "Numan", "initials": "N.", "afid": [{"@_fa": "true", "$": "60014237"}, {"@_fa": "true", "$": "60070785"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57225186153", "authid": "57225186153", "authname": "Cho S.", "surname": "Cho", "given-name": "Seungwon", "initials": "S.", "afid": [{"@_fa": "true", "$": "60014237"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/55728031400", "authid": "55728031400", "authname": "Park C.", "surname": "Park", "given-name": "Chansik", "initials": "C.", "afid": [{"@_fa": "true", "$": "60014237"}]}], "authkeywords": "Computer vision | Construction accidents | Fall from height (FFH) | Internet of things (IoT) | Safety management | Safety monitoring | Smart Safety Hook (SSH) | Tag and IoT-based monitoring | Worker safety", "article-number": "104153", "source-id": "24931", "fund-acr": "CAU", "fund-no": "NRF-2020R1A4A4078916", "fund-sponsor": "Chung-Ang University", "openaccess": "0", "openaccessFlag": false}, "28": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85126990337"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85126990337?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85126990337&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85126990337&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85126990337", "dc:identifier": "SCOPUS_ID:85126990337", "eid": "2-s2.0-85126990337", "dc:title": "Application of machine vision-based NDT technology in ceramic surface defect detection - A review", "dc:creator": "Dong G.", "prism:publicationName": "Materialpruefung/Materials Testing", "prism:issn": "00255300", "prism:volume": "64", "prism:issueIdentifier": "2", "prism:pageRange": "202-219", "prism:coverDate": "2022-02-01", "prism:coverDisplayDate": "February 2022", "prism:doi": "10.1515/mt-2021-2012", "dc:description": "For its good mechanical, thermal, and chemical property, ceramic materials are widely used in construction, chemical industry, electric power, communication and other fields. However, due to its particularity and complex production process, quality problems usually occur, of which the most common one is surface defects. For ceramic products, the defects are usually small and complicated, and manual methods are difficult to ensure the accuracy and speed of detection. Relevant researchers have proposed a variety of machine vision-based ceramic defect detection methods, but these methods still need to break through in solving the key problems of ceramic surface glaze reflection, complex detection environment, low algorithm efficiency and low real-time performance. To this end, this article reviews the application status of machine vision on ceramic surface defect detection in recent years, summarizes and analyzes the existing non-destructive testing (NDT) technology method, and points out the main factors that affect the development of ceramic surfaces defect detection technology and puts forward the corresponding solutions.", "citedby-count": "4", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60073571", "afid": "60073571", "affilname": "Jingdezhen Ceramic University", "affiliation-city": "Jingdezhen", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025278", "afid": "60025278", "affilname": "Tsinghua University", "affiliation-city": "Beijing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60024542", "afid": "60024542", "affilname": "South China University of Technology", "affiliation-city": "Guangzhou", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60005816", "afid": "60005816", "affilname": "South China Normal University", "affiliation-city": "Guangzhou", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "7", "$": "7"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57205285818", "authid": "57205285818", "authname": "Dong G.", "surname": "Dong", "given-name": "Guanping", "initials": "G.", "afid": [{"@_fa": "true", "$": "60073571"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57226526104", "authid": "57226526104", "authname": "Sun S.", "surname": "Sun", "given-name": "Shanwei", "initials": "S.", "afid": [{"@_fa": "true", "$": "60073571"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8927502900", "authid": "8927502900", "authname": "Wang Z.", "surname": "Wang", "given-name": "Zixi", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60025278"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57201057251", "authid": "57201057251", "authname": "Wu N.", "surname": "Wu", "given-name": "Nanshou", "initials": "N.", "afid": [{"@_fa": "true", "$": "60005816"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57195999454", "authid": "57195999454", "authname": "Huang P.", "surname": "Huang", "given-name": "Pingnan", "initials": "P.", "afid": [{"@_fa": "true", "$": "60024542"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57158213900", "authid": "57158213900", "authname": "Feng H.", "surname": "Feng", "given-name": "Hao", "initials": "H.", "afid": [{"@_fa": "true", "$": "60073571"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/16550555900", "authid": "16550555900", "authname": "Pan M.", "surname": "Pan", "given-name": "Minqiang", "initials": "M.", "afid": [{"@_fa": "true", "$": "60024542"}]}], "authkeywords": "ceramic materials | deep learning | defect detection | machine vision | non-destructive testing", "source-id": "21225", "fund-acr": "JCI", "fund-no": "20298002", "fund-sponsor": "Jingdezhen Ceramic Institute", "openaccess": "0", "openaccessFlag": false}, "29": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85143965887"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85143965887?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85143965887&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85143965887&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85143965887", "dc:identifier": "SCOPUS_ID:85143965887", "eid": "2-s2.0-85143965887", "dc:title": "BIM and real estate valuation: challenges, potentials and lessons for future directions", "dc:creator": "Jafary P.", "prism:publicationName": "Engineering, Construction and Architectural Management", "prism:issn": "09699988", "prism:pageRange": null, "prism:coverDate": "2022-01-01", "prism:coverDisplayDate": "2022", "prism:doi": "10.1108/ECAM-07-2022-0642", "dc:description": "Purpose: Building information modeling (BIM) is a striking development in the architecture, engineering and construction (AEC) industry, which provides in-depth information on different stages of the building lifecycle. Real estate valuation, as a fully interconnected field with the AEC industry, can benefit from 3D technical achievements in BIM technologies. Some studies have attempted to use BIM for real estate valuation procedures. However, there is still a limited understanding of appropriate mechanisms to utilize BIM for valuation purposes and the consequent impact that BIM can have on decreasing the existing uncertainties in the valuation methods. Therefore, the paper aims to analyze the literature on BIM for real estate valuation practices. Design/methodology/approach: This paper presents a systematic review to analyze existing utilizations of BIM for real estate valuation practices, discovers the challenges, limitations and gaps of the current applications and presents potential domains for future investigations. Research was conducted on the Web of Science, Scopus and Google Scholar databases to find relevant references that could contribute to the study. A total of 52 publications including journal papers, conference papers and proceedings, book chapters and PhD and master's theses were identified and thoroughly reviewed. There was no limitation on the starting date of research, but the end date was May 2022. Findings: Four domains of application have been identified: (1) developing machine learning-based valuation models using the variables that could directly be captured through BIM and industry foundation classes (IFC) data instances of building objects and their attributes; (2) evaluating the capacity of 3D factors extractable from BIM and 3D GIS in increasing the accuracy of existing valuation models; (3) employing BIM for accurate estimation of components of cost approach-based valuation practices; and (4) extraction of useful visual features for real estate valuation from BIM representations instead of 2D images through deep learning and computer vision. Originality/value: This paper contributes to research efforts on utilization of 3D modeling in real estate valuation practices. In this regard, this paper presents a broad overview of the current applications of BIM for valuation procedures and provides potential ways forward for future investigations.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60026553", "afid": "60026553", "affilname": "University of Melbourne", "affiliation-city": "Melbourne", "affiliation-country": "Australia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57950390600", "authid": "57950390600", "authname": "Jafary P.", "surname": "Jafary", "given-name": "Peyman", "initials": "P.", "afid": [{"@_fa": "true", "$": "60026553"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/45561674000", "authid": "45561674000", "authname": "Shojaei D.", "surname": "Shojaei", "given-name": "Davood", "initials": "D.", "afid": [{"@_fa": "true", "$": "60026553"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/6603307682", "authid": "6603307682", "authname": "Rajabifard A.", "surname": "Rajabifard", "given-name": "Abbas", "initials": "A.", "afid": [{"@_fa": "true", "$": "60026553"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57209597335", "authid": "57209597335", "authname": "Ngo T.", "surname": "Ngo", "given-name": "Tuan", "initials": "T.", "afid": [{"@_fa": "true", "$": "60026553"}]}], "authkeywords": "Artificial intelligence (AI) | Building information modeling (BIM) | Machine\u00a0learning (ML) | Real estate valuation | Three-dimensional (3D) data", "source-id": "15249", "fund-no": "undefined", "fund-sponsor": "Australian Government", "openaccess": "0", "openaccessFlag": false}, "30": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140620893"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140620893?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140620893&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140620893&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85140620893", "dc:identifier": "SCOPUS_ID:85140620893", "eid": "2-s2.0-85140620893", "dc:title": "Applications of Artificial Intelligence Enhanced Drones in Distress Pavement, Pothole Detection, and Healthcare Monitoring with Service Delivery", "dc:creator": "Wang Y.", "prism:publicationName": "Journal of Engineering (United Kingdom)", "prism:issn": "23144904", "prism:eIssn": "23144912", "prism:volume": "2022", "prism:pageRange": null, "prism:coverDate": "2022-01-01", "prism:coverDisplayDate": "2022", "prism:doi": "10.1155/2022/7733196", "dc:description": "Artificial Intelligence (AI) has fascinated the present study assigned to multiple areas such as distress detection on the pavement, pothole detection, and healthcare. The distress detection on pavement and roads and delivering healthcare and medical services need to be monitored through state-of-the-art technology, i.e., drone technology. Improvement in construction sites and healthcare delivery are of serious concern. Nowadays, computer vision techniques are commonly used in this area utilizing images and videos of construction sites. Due to confined data, researchers are using Unmanned Aerial Vehicles (UAVs) or Drone to get maximum information through 360\u00b0 monitoring. This review article presents the useful monitoring techniques using AI-enabled drones for scholars around the world. In this comprehensive review, initially, the image acquisition equipment along with the perks and limitations has been presented. Second, the main constraints related to different computer vision techniques are highlighted for detecting distress in the pavement. Then, the possible research solution to some of the distress issues such that detection of pavement texture, cracks or potholes, joint faulting, temperature segregation, and rutting issues are predicted. Finally, the application of AI-enhanced drones in the healthcare field is elucidated which showed their significance. Moreover, in this research, the comparative image analysis of pavement and path hole detection was presented for the collection of detailed information and accurate detection. In the future, the work can also be enhanced to monitor the live pavement distress detection, especially for busy roads and highways. Moreover, an analysis to determine and reduce the costs in the healthcare sectors and organizations is required for future work.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60003977", "afid": "60003977", "affilname": "Northwestern Polytechnical University", "affiliation-city": "Xi'an", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/113075193", "afid": "113075193", "affilname": "Xi\u2019an Aeronautical Institute", "affiliation-city": "Xi'an", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/58393472900", "authid": "58393472900", "authname": "Wang Y.", "surname": "Wang", "given-name": "Yue", "initials": "Y.", "afid": [{"@_fa": "true", "$": "113075193"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57941658300", "authid": "57941658300", "orcid": "0000-0003-3101-9436", "authname": "Ye T.", "surname": "Ye", "given-name": "Tian", "initials": "T.", "afid": [{"@_fa": "true", "$": "60003977"}]}], "article-number": "7733196", "source-id": "21100463939", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "31": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139448981"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139448981?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139448981&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85139448981&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85139448981", "dc:identifier": "SCOPUS_ID:85139448981", "eid": "2-s2.0-85139448981", "dc:title": "Overview of Emerging Technologies for Improving the Performance of Heavy-Duty Construction Machines", "dc:creator": "Khan A.U.", "prism:publicationName": "IEEE Access", "prism:eIssn": "21693536", "prism:volume": "10", "prism:pageRange": "103315-103336", "prism:coverDate": "2022-01-01", "prism:coverDisplayDate": "2022", "prism:doi": "10.1109/ACCESS.2022.3209818", "dc:description": "Construction equipment is one of the most significant resources in large construction projects, accounting for a considerable portion of the project budget. Improving the performance of heavy machinery can increase efficiency and reduce costs. However, research on boosting the machine efficiency is limited. This study adopts a mixed review methodology (systematic review and bibliometric analysis) and evaluates emerging technologies such as digital twin, cyber physical systems, geographic information systems, global navigation satellite systems, onboard instrumentation systems, radio frequency identification, internet of things, telematics, machine learning, deep learning, and computer vision for machine productivity, and provides insights into how they can be used to improve the performance of construction equipment. This study defined three major equipment operating areas - monitoring and control, tracking and navigation, and data-driven performance optimization - classified technologies and explored how they can increase machine productivity. Other circumstantial issues affecting machine operation and loopholes in the existing innovative tools used in machine processes have also been highlighted. This study contributes to the goal of deploying digital tools and outlines future directions for the development of automated machines to optimize project efficiency.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60013141", "afid": "60013141", "affilname": "Norges Teknisk-Naturvitenskapelige Universitet", "affiliation-city": "Trondheim", "affiliation-country": "Norway"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57918303100", "authid": "57918303100", "orcid": "0000-0001-7080-1135", "authname": "Khan A.U.", "surname": "Khan", "given-name": "Asmat Ullah", "initials": "A.U.", "afid": [{"@_fa": "true", "$": "60013141"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57195869314", "authid": "57195869314", "orcid": "0000-0001-9387-7650", "authname": "Huang L.", "surname": "Huang", "given-name": "Lizhen", "initials": "L.", "afid": [{"@_fa": "true", "$": "60013141"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57196038819", "authid": "57196038819", "authname": "Onstein E.", "surname": "Onstein", "given-name": "Erling", "initials": "E.", "afid": [{"@_fa": "true", "$": "60013141"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/56509394100", "authid": "56509394100", "orcid": "0000-0002-6195-8437", "authname": "Liu Y.", "surname": "Liu", "given-name": "Yongping", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60013141"}]}], "authkeywords": "Digital models | earthmoving | emerging | equipment productivity | mobile equipment | sensing | technologies | tracking", "source-id": "21100374601", "fund-acr": "NTNU", "fund-no": "undefined", "fund-sponsor": "Norges Teknisk-Naturvitenskapelige Universitet", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "32": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136216613"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136216613?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136216613&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85136216613&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85136216613", "dc:identifier": "SCOPUS_ID:85136216613", "eid": "2-s2.0-85136216613", "dc:title": "Remote Sensing Image Classification: A Comprehensive Review and Applications", "dc:creator": "Mehmood M.", "prism:publicationName": "Mathematical Problems in Engineering", "prism:issn": "1024123X", "prism:eIssn": "15635147", "prism:volume": "2022", "prism:pageRange": null, "prism:coverDate": "2022-01-01", "prism:coverDisplayDate": "2022", "prism:doi": "10.1155/2022/5880959", "dc:description": "Remote sensing is mainly used to investigate sites of dams, bridges, and pipelines to locate construction materials and provide detailed geographic information. In remote sensing image analysis, the images captured through satellite and drones are used to observe surface of the Earth. The main aim of any image classification-based system is to assign semantic labels to captured images, and consequently, using these labels, images can be arranged in a semantic order. The semantic arrangement of images is used in various domains of digital image processing and computer vision such as remote sensing, image retrieval, object recognition, image annotation, scene analysis, content-based image analysis, and video analysis. The earlier approaches for remote sensing image analysis are based on low-level and mid-level feature extraction and representation. These techniques have shown good performance by using different feature combinations and machine learning approaches. These earlier approaches have used small-scale image dataset. The recent trends for remote sensing image analysis are shifted to the use of deep learning model. Various hybrid approaches of deep learning have shown much better results than the use of a single deep learning model. In this review article, a detailed overview of the past trends is presented, based on low-level and mid-level feature representation using traditional machine learning concepts. A summary of publicly available image benchmarks for remote sensing image analysis is also presented. A detailed summary is presented at the end of each section. An overview regarding the current trends of deep learning models is presented along with a detailed comparison of various hybrid approaches based on recent trends. The performance evaluation metrics are also discussed. This review article provides a detailed knowledge related to the existing trends in remote sensing image classification and possible future research directions.", "citedby-count": "23", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60107948", "afid": "60107948", "affilname": "Mirpur University of Science and Technology", "affiliation-city": "Mirpur, Azad Kashmir", "affiliation-country": "Pakistan"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60070615", "afid": "60070615", "affilname": "Government College University Faisalabad", "affiliation-city": "Faisalabad", "affiliation-country": "Pakistan"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60059937", "afid": "60059937", "affilname": "National University of Sciences and Technology Pakistan", "affiliation-city": "Islamabad", "affiliation-country": "Pakistan"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57405596200", "authid": "57405596200", "authname": "Mehmood M.", "surname": "Mehmood", "given-name": "Maryam", "initials": "M.", "afid": [{"@_fa": "true", "$": "60107948"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57195609446", "authid": "57195609446", "authname": "Shahzad A.", "surname": "Shahzad", "given-name": "Ahsan", "initials": "A.", "afid": [{"@_fa": "true", "$": "60059937"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57202395911", "authid": "57202395911", "orcid": "0000-0002-8869-3037", "authname": "Zafar B.", "surname": "Zafar", "given-name": "Bushra", "initials": "B.", "afid": [{"@_fa": "true", "$": "60070615"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57223354975", "authid": "57223354975", "authname": "Shabbir A.", "surname": "Shabbir", "given-name": "Amsa", "initials": "A.", "afid": [{"@_fa": "true", "$": "60107948"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57206699343", "authid": "57206699343", "orcid": "0000-0002-0721-201X", "authname": "Ali N.", "surname": "Ali", "given-name": "Nouman", "initials": "N.", "afid": [{"@_fa": "true", "$": "60107948"}]}], "article-number": "5880959", "source-id": "13082", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "33": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85118161462"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85118161462?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85118161462&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85118161462&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580521004647"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85118161462", "dc:identifier": "SCOPUS_ID:85118161462", "eid": "2-s2.0-85118161462", "dc:title": "Deep-learning-based vision for earth-moving automation", "dc:creator": "Borngrund C.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "133", "prism:pageRange": null, "prism:coverDate": "2022-01-01", "prism:coverDisplayDate": "January 2022", "prism:doi": "10.1016/j.autcon.2021.104013", "pii": "S0926580521004647", "dc:description": "Earth-moving machines are heavy-duty vehicles designed for construction operations involving earthworks. The tasks performed by such machines typically involve navigation and interaction with materials such as soil, gravel, and blasted rock. Skilled operators use a combination of visual, sound, tactile and possibly motion feedback to perform tasks efficiently. We survey the literature in this research area and analyse the relative importance of different sensor system modalities focusing on deep-learning-based vision and automation for the short-cycle loading task. This is a common and repetitive task that is attractive to automate. The analysis indicates that computer vision, in combination with onboard sensors, is more critical than coordinate-based positioning. Furthermore, we find that data-driven approaches, in general, have high potential in terms of productivity, adaptability, versatility and wear and tear with respect to automation system solutions. The main knowledge gaps identified relate to loading non-fine heterogeneous material and navigation during loading and unloading.", "citedby-count": "7", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60007183", "afid": "60007183", "affilname": "Lule\u00e5 University of Technology", "affiliation-city": "Lulea", "affiliation-country": "Sweden"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57219553246", "authid": "57219553246", "orcid": "0000-0002-4716-9765", "authname": "Borngrund C.", "surname": "Borngrund", "given-name": "Carl", "initials": "C.", "afid": [{"@_fa": "true", "$": "60007183"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/10642298900", "authid": "10642298900", "authname": "Sandin F.", "surname": "Sandin", "given-name": "Fredrik", "initials": "F.", "afid": [{"@_fa": "true", "$": "60007183"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/6505898602", "authid": "6505898602", "authname": "Bodin U.", "surname": "Bodin", "given-name": "Ulf", "initials": "U.", "afid": [{"@_fa": "true", "$": "60007183"}]}], "authkeywords": "Automation | Computer vision | Construction equipment | Machine learning | Short-cycle Loading", "article-number": "104013", "source-id": "24931", "fund-no": "2019-03073", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherhybridgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Hybrid Gold"}]}}, "34": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85119840054"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85119840054?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85119840054&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85119840054&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S2352710221011578"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85119840054", "dc:identifier": "SCOPUS_ID:85119840054", "eid": "2-s2.0-85119840054", "dc:title": "Artificial intelligence in the construction industry: A review of present status, opportunities and future challenges", "dc:creator": "Abioye S.O.", "prism:publicationName": "Journal of Building Engineering", "prism:eIssn": "23527102", "prism:volume": "44", "prism:pageRange": null, "prism:coverDate": "2021-12-01", "prism:coverDisplayDate": "December 2021", "prism:doi": "10.1016/j.jobe.2021.103299", "pii": "S2352710221011578", "dc:description": "The growth of the construction industry is severely limited by the myriad complex challenges it faces such as cost and time overruns, health and safety, productivity and labour shortages. Also, construction industry is one the least digitized industries in the world, which has made it difficult for it to tackle the problems it currently faces. An advanced digital technology, Artificial Intelligence (AI), is currently revolutionising industries such as manufacturing, retail, and telecommunications. The subfields of AI such as machine learning, knowledge-based systems, computer vision, robotics and optimisation have successfully been applied in other industries to achieve increased profitability, efficiency, safety and security. While acknowledging the benefits of AI applications, numerous challenges which are relevant to AI still exist in the construction industry. This study aims to unravel AI applications, examine AI techniques being used and identify opportunites and challenges for AI applications in the construction industry. A critical review of available literature on AI applications in the construction industry such as activity monitoring, risk management, resource and waste optimisation was conducted. Furthermore, the opportunities and challenges of AI applications in construction were identified and presented in this study. This study provides insights into key AI applications as it applies to construction-specific challenges, as well as the pathway to realise the acrueable benefits of AI in the construction industry.", "citedby-count": "138", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60114346", "afid": "60114346", "affilname": "Bristol Business School", "affiliation-city": "Bristol", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020623", "afid": "60020623", "affilname": "Brunel University London", "affiliation-city": "Uxbridge", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60011031", "afid": "60011031", "affilname": "Obafemi Awolowo University", "affiliation-city": "Ife", "affiliation-country": "Nigeria"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "8", "$": "8"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57219777385", "authid": "57219777385", "authname": "Abioye S.O.", "surname": "Abioye", "given-name": "Sofiat O.", "initials": "S.O.", "afid": [{"@_fa": "true", "$": "60114346"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/15623716300", "authid": "15623716300", "orcid": "0000-0002-3411-372X", "authname": "Oyedele L.O.", "surname": "Oyedele", "given-name": "Lukumon O.", "initials": "L.O.", "afid": [{"@_fa": "true", "$": "60114346"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57196260329", "authid": "57196260329", "authname": "Akanbi L.", "surname": "Akanbi", "given-name": "Lukman", "initials": "L.", "afid": [{"@_fa": "true", "$": "60114346"}, {"@_fa": "true", "$": "60011031"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57207576395", "authid": "57207576395", "authname": "Ajayi A.", "surname": "Ajayi", "given-name": "Anuoluwapo", "initials": "A.", "afid": [{"@_fa": "true", "$": "60114346"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/55660708400", "authid": "55660708400", "authname": "Davila Delgado J.M.", "surname": "Davila Delgado", "given-name": "Juan Manuel", "initials": "J.M.", "afid": [{"@_fa": "true", "$": "60114346"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57224853326", "authid": "57224853326", "authname": "Bilal M.", "surname": "Bilal", "given-name": "Muhammad", "initials": "M.", "afid": [{"@_fa": "true", "$": "60114346"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/56770159900", "authid": "56770159900", "authname": "Akinade O.O.", "surname": "Akinade", "given-name": "Olugbenga O.", "initials": "O.O.", "afid": [{"@_fa": "true", "$": "60114346"}]}, {"@_fa": "true", "@seq": "8", "author-url": "https://api.elsevier.com/content/author/author_id/55448609200", "authid": "55448609200", "authname": "Ahmed A.", "surname": "Ahmed", "given-name": "Ashraf", "initials": "A.", "afid": [{"@_fa": "true", "$": "60020623"}]}], "authkeywords": "AI challenges | AI opportunities | Artificial intelligence | Construction industry | Machine learning | Robotics", "article-number": "103299", "source-id": "21100389518", "fund-acr": "EPSRC", "fund-no": "EP/S031480/1", "fund-sponsor": "Engineering and Physical Sciences Research Council", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherhybridgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Hybrid Gold"}, {"$": "Green"}]}}, "35": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114765919"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114765919?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85114765919&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85114765919&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580521003915"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85114765919", "dc:identifier": "SCOPUS_ID:85114765919", "eid": "2-s2.0-85114765919", "dc:title": "Computer vision applications in construction: Current state, opportunities &amp; challenges", "dc:creator": "Paneru S.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "132", "prism:pageRange": null, "prism:coverDate": "2021-12-01", "prism:coverDisplayDate": "December 2021", "prism:doi": "10.1016/j.autcon.2021.103940", "pii": "S0926580521003915", "dc:description": "Thousands of images and videos are collected from construction projects during construction. These contain valuable data that, if harnessed efficiently, can help automate or at least reduce human effort in diverse construction management activities such as progress monitoring, safety management, quality control and productivity tracking. Extracting meaningful information from images requires the development of technology and algorithms that enable computers to understand digital images or videos, replicating the functionality of human visual systems. This is the goal of computer vision. This review aims at providing an updated and categorized overview of computer vision applications in construction by examining the recent developments in the field and identifying the opportunities and challenges that future research needs to address to fully leverage the potential benefits of Computer Vision. We restrict the focus to four areas that can benefit the most from computer vision - Safety Management, Progress Monitoring, Productivity Tracking and Quality Control.", "citedby-count": "58", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60122769", "afid": "60122769", "affilname": "Warrington College of Business", "affiliation-city": "Gainesville", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57208078157", "authid": "57208078157", "authname": "Paneru S.", "surname": "Paneru", "given-name": "Suman", "initials": "S.", "afid": [{"@_fa": "true", "$": "60122769"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57193824458", "authid": "57193824458", "authname": "Jeelani I.", "surname": "Jeelani", "given-name": "Idris", "initials": "I.", "afid": [{"@_fa": "true", "$": "60122769"}]}], "authkeywords": "Computer vision | Monitoring | Technology in construction | Visual data analytics", "article-number": "103940", "source-id": "24931", "fund-acr": "NSF", "fund-no": "OAC-2004544", "fund-sponsor": "National Science Foundation", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfree2read"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Bronze"}]}}, "36": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114946355"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114946355?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85114946355&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85114946355&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85114946355", "dc:identifier": "SCOPUS_ID:85114946355", "eid": "2-s2.0-85114946355", "dc:title": "Overview of accurate coresets", "dc:creator": "Jubran I.", "prism:publicationName": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "prism:issn": "19424787", "prism:eIssn": "19424795", "prism:volume": "11", "prism:issueIdentifier": "6", "prism:pageRange": null, "prism:coverDate": "2021-11-01", "prism:coverDisplayDate": "November/December 2021", "prism:doi": "10.1002/widm.1429", "dc:description": "A coreset of an input set is its small summarization, such that solving a problem on the coreset as its input, provably yields the same result as solving the same problem on the original (full) set, for a given family of problems (models/classifiers/loss functions). Coresets have been suggested for many fundamental problems, for example, in machine/deep learning, computer vision, databases, and theoretical computer science. This introductory paper was written following requests regarding the many inconsistent coreset definitions, lack of source code, the required deep theoretical background from different fields, and the dense papers that make it hard for beginners to apply and develop coresets. The article provides folklore, classic, and simple results including step-by-step proofs and figures, for the simplest (accurate) coresets. Nevertheless, we did not find most of their constructions in the literature. Moreover, we expect that putting them together in a retrospective context would help the reader to grasp current results that usually generalize these fundamental observations. Experts might appreciate the unified notation and comparison table for existing results. Open source code is provided for all presented algorithms, to demonstrate their usage, and to support the readers who are more familiar with programming than mathematics. This article is categorized under: Algorithmic Development > Structure Discovery Fundamental Concepts of Data and Knowledge > Big Data Mining Technologies > Machine Learning.", "citedby-count": "2", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60002999", "afid": "60002999", "affilname": "University of Haifa", "affiliation-city": "Haifa", "affiliation-country": "Israel"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57217039708", "authid": "57217039708", "orcid": "0000-0003-1691-5064", "authname": "Jubran I.", "surname": "Jubran", "given-name": "Ibrahim", "initials": "I.", "afid": [{"@_fa": "true", "$": "60002999"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57218715522", "authid": "57218715522", "authname": "Maalouf A.", "surname": "Maalouf", "given-name": "Alaa", "initials": "A.", "afid": [{"@_fa": "true", "$": "60002999"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55890832600", "authid": "55890832600", "orcid": "0000-0002-7700-9711", "authname": "Feldman D.", "surname": "Feldman", "given-name": "Dan", "initials": "D.", "afid": [{"@_fa": "true", "$": "60002999"}]}], "authkeywords": "big data mining | computational geometry | coresets | data summarization | machine learning", "article-number": "e1429", "source-id": "21100228068", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "37": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85115308917"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85115308917?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85115308917&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85115308917&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85115308917", "dc:identifier": "SCOPUS_ID:85115308917", "eid": "2-s2.0-85115308917", "dc:title": "Applications of computer vision in monitoring the unsafe behavior of construction workers: Current status and challenges", "dc:creator": "Liu W.", "prism:publicationName": "Buildings", "prism:eIssn": "20755309", "prism:volume": "11", "prism:issueIdentifier": "9", "prism:pageRange": null, "prism:coverDate": "2021-09-01", "prism:coverDisplayDate": "September 2021", "prism:doi": "10.3390/buildings11090409", "dc:description": "The unsafe behavior of construction workers is one of the main causes of safety accidents at construction sites. To reduce the incidence of construction accidents and improve the safety performance of construction projects, there is a need to identify risky factors by monitoring the behavior of construction workers. Computer vision (CV) technology, which is a powerful and automated tool used for extracting images and video information from construction sites, has been recognized and adopted as an effective construction site monitoring technology for the identification of risky factors resulting from the unsafe behavior of construction workers. In this article, we introduce the research background of this field and conduct a systematic statistical analysis of the relevant literature in this field through the bibliometric analysis method. Thereafter, we adopt a content-based analysis method to depict the historical explorations in the field. On this basis, the limitations and challenges in this field are identified, and future research directions are proposed. It is found that CV technology can effectively monitor the unsafe behaviors of construction workers. The research findings can enhance people\u2019s understanding of construction safety management.", "citedby-count": "19", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60018805", "afid": "60018805", "affilname": "Deakin University", "affiliation-city": "Geelong", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60017482", "afid": "60017482", "affilname": "Jiangsu University", "affiliation-city": "Zhenjiang", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57221781245", "authid": "57221781245", "authname": "Liu W.", "surname": "Liu", "given-name": "Wenyao", "initials": "W.", "afid": [{"@_fa": "true", "$": "60017482"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/36704082100", "authid": "36704082100", "authname": "Meng Q.", "surname": "Meng", "given-name": "Qingfeng", "initials": "Q.", "afid": [{"@_fa": "true", "$": "60017482"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57191699978", "authid": "57191699978", "authname": "Li Z.", "surname": "Li", "given-name": "Zhen", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60017482"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/56469989300", "authid": "56469989300", "authname": "Hu X.", "surname": "Hu", "given-name": "Xin", "initials": "X.", "afid": [{"@_fa": "true", "$": "60018805"}]}], "authkeywords": "Computer vision | Construction workers | Literature review | Monitoring | Unsafe behavior", "article-number": "409", "source-id": "26980", "fund-acr": "NSFC", "fund-no": "71671078", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "38": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114871797"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114871797?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85114871797&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85114871797&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85114871797", "dc:identifier": "SCOPUS_ID:85114871797", "eid": "2-s2.0-85114871797", "dc:title": "Research trends of human\u2013computer interaction studies in construction hazard recognition: A bibliometric review", "dc:creator": "Wang J.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "21", "prism:issueIdentifier": "18", "prism:pageRange": null, "prism:coverDate": "2021-09-01", "prism:coverDisplayDate": "September 2021", "prism:doi": "10.3390/s21186172", "dc:description": "Human\u2013computer interaction, an interdisciplinary discipline, has become a frontier research topic in recent years. In the fourth industrial revolution, human\u2013computer interaction has been increasingly applied to construction safety management, which has significantly promoted the progress of hazard recognition in the construction industry. However, limited scholars have yet systematically reviewed the development of human\u2013computer interaction in construction hazard recognition. In this study, we analyzed 274 related papers published in ACM Digital Library, Web of Science, Google Scholar, and Scopus between 2000 and 2021 using bibliometric methods, systematically identified the research progress, key topics, and future research directions in this field, and proposed a research framework for human\u2013computer interaction in construction hazard recognition (CHR-HCI). The results showed that, in the past 20 years, the application of human\u2013computer interaction not only made significant contributions to the development of hazard recognition, but also generated a series of new research subjects, such as multimodal physiological data analysis in hazard recognition experiments, development of intuitive devices and sensors, and the human\u2013computer interaction safety management platform based on big data. Future research modules include computer vision, computer simulation, virtual reality, and ergonomics. In this study, we drew a theoretical map reflecting the existing research results and the relationship between them, and provided suggestions for the future development of human\u2013computer interaction in the field of hazard recognition from a practical perspective.", "citedby-count": "13", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60092860", "afid": "60092860", "affilname": "Beijing University of Civil Engineering and Architecture", "affiliation-city": "Beijing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60073652", "afid": "60073652", "affilname": "Tongji University", "affiliation-city": "Shanghai", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025278", "afid": "60025278", "affilname": "Tsinghua University", "affiliation-city": "Beijing", "affiliation-country": "China"}], "pubmed-id": "34577380", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57221836779", "authid": "57221836779", "authname": "Wang J.", "surname": "Wang", "given-name": "Jiaming", "initials": "J.", "afid": [{"@_fa": "true", "$": "60073652"}, {"@_fa": "true", "$": "60025278"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57221833194", "authid": "57221833194", "authname": "Cheng R.", "surname": "Cheng", "given-name": "Rui", "initials": "R.", "afid": [{"@_fa": "true", "$": "60025278"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/56300976100", "authid": "56300976100", "authname": "Liu M.", "surname": "Liu", "given-name": "Mei", "initials": "M.", "afid": [{"@_fa": "true", "$": "60092860"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/41961245200", "authid": "41961245200", "authname": "Liao P.C.", "surname": "Liao", "given-name": "Pin Chao", "initials": "P.C.", "afid": [{"@_fa": "true", "$": "60025278"}]}], "authkeywords": "Bibliometric review | Construction | Hazard recognition | Human-computer interaction", "article-number": "6172", "source-id": "130124", "fund-acr": "NNSFC", "fund-no": "51878382", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "39": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85112517487"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85112517487?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85112517487&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85112517487&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85112517487", "dc:identifier": "SCOPUS_ID:85112517487", "eid": "2-s2.0-85112517487", "dc:title": "Influence of artificial intelligence in civil engineering toward sustainable development\u2014a systematic literature review", "dc:creator": "Manzoor B.", "prism:publicationName": "Applied System Innovation", "prism:eIssn": "25715577", "prism:volume": "4", "prism:issueIdentifier": "3", "prism:pageRange": null, "prism:coverDate": "2021-09-01", "prism:coverDisplayDate": "September 2021", "prism:doi": "10.3390/asi4030052", "dc:description": "The widespread use of artificial intelligence (AI) in civil engineering has provided civil engineers with various benefits and opportunities, including a rich data collection, sustainable assessment, and productivity. The trend of construction is diverted toward sustainability with the aid of digital technologies. In this regard, this paper presents a systematic literature review (SLR) in order to explore the influence of AI in civil engineering toward sustainable development. In addition, SLR was carried out by using academic publications from Scopus (i.e., 3478 publications). Furthermore, screening is carried out, and eventually, 105 research publications in the field of AI were selected. Keywords were searched through Boolean operation \u201cArtificial Intelligence\u201d OR \u201cMachine intelligence\u201d OR \u201cMachine Learning\u201d OR \u201cComputational intelligence\u201d OR \u201cComputer vision\u201d OR \u201cExpert systems\u201d OR \u201cNeural networks\u201d AND \u201cCivil Engineering\u201d OR \u201cConstruction Engineering\u201d OR \u201cSustainable Development\u201d OR \u201cSustainability\u201d. According to the findings, it was revealed that the trend of publications received its high intention of researchers in 2020, the most important contribution of publications on AI toward sustainability by the Automation in Construction, the United States has the major influence among all the other countries, the main features of civil engineering toward sustainability are interconnectivity, functionality, unpredictability, and individuality. This research adds to the body of knowledge in civil engineering by visualizing and comprehending trends and patterns, as well as defining major research goals, journals, and countries. In addition, a theoretical framework has been proposed in light of the results for prospective researchers and cholars.", "citedby-count": "25", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60231078", "afid": "60231078", "affilname": "Razak Faculty of Technology and Informatics", "affiliation-city": "Kuala Lumpur", "affiliation-country": "Malaysia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60001278", "afid": "60001278", "affilname": "Universiti Teknologi PETRONAS", "affiliation-city": "Seri Iskandar", "affiliation-country": "Malaysia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/126183317", "afid": "126183317", "affilname": "Ara Institute of Canterbury", "affiliation-city": "Christchurch", "affiliation-country": "New Zealand"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "5", "$": "5"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57221966307", "authid": "57221966307", "authname": "Manzoor B.", "surname": "Manzoor", "given-name": "Bilal", "initials": "B.", "afid": [{"@_fa": "true", "$": "60001278"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/54995412700", "authid": "54995412700", "authname": "Othman I.", "surname": "Othman", "given-name": "Idris", "initials": "I.", "afid": [{"@_fa": "true", "$": "60001278"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55132047800", "authid": "55132047800", "authname": "Durdyev S.", "surname": "Durdyev", "given-name": "Serdar", "initials": "S.", "afid": [{"@_fa": "true", "$": "126183317"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/55255925100", "authid": "55255925100", "authname": "Ismail S.", "surname": "Ismail", "given-name": "Syuhaida", "initials": "S.", "afid": [{"@_fa": "true", "$": "60231078"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57196040472", "authid": "57196040472", "authname": "Wahab M.H.", "surname": "Wahab", "given-name": "Mohammad Hussaini", "initials": "M.H.", "afid": [{"@_fa": "true", "$": "60231078"}]}], "authkeywords": "Artificial intelligence | Civil engineering | Construction | Construction engineering | Machine learning | Sustainable development", "article-number": "52", "source-id": "21101024218", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "40": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85112310269"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85112310269?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85112310269&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85112310269&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85112310269", "dc:identifier": "SCOPUS_ID:85112310269", "eid": "2-s2.0-85112310269", "dc:title": "Computer vision-based construction process sensing for cyber\u2013physical systems: A review", "dc:creator": "Zhang B.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "21", "prism:issueIdentifier": "16", "prism:pageRange": null, "prism:coverDate": "2021-08-02", "prism:coverDisplayDate": "2 August 2021", "prism:doi": "10.3390/s21165468", "dc:description": "Cyber\u2013physical systems (CPSs) are generally considered to be the next generation of engineered systems. However, the actual application of CPSs in the Architecture, Engineering and Construction (AEC) industry is still at a low level. The sensing method in the construction process plays a very important role in the establishment of CPSs. Therefore, the purpose of this paper is to discuss the application potential of computer vision-based sensing methods and provide practical suggestions through a literature review. This paper provides a review of the current application of CPSs in the AEC industry, summarizes the current knowledge gaps, and discusses the problems with the current construction site sensing approach. Considering the unique advantages of the computer vision (CV) method at the construction site, the application of CV for different construction entities was reviewed and summarized to achieve a CV-based construction site sensing approach for construction process CPSs. The potential of CPS can be further stimulated by providing rich information from on-site sensing using CV methods. According to the review, this approach has unique advantages in the specific environment of the construction site. Based on the current knowledge gap identified in the literature review, this paper proposes a novel concept of visual-based construction site sensing method for CPS application, and an architecture for CV-based CPS is proposed as an implementation of this concept. The main contribution of this paper is to propose a CPS architecture using computer vision as the main information acquisition method based on the literature review. This architecture innovatively introduces computer vision as a sensing method of construction sites, and realizes low-cost and non-invasive information acquisition in complex construction scenarios. This method can be used as an important supplement to on-site sensing to further promote the automation and intelligence of the construction process.", "citedby-count": "4", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60073652", "afid": "60073652", "affilname": "Tongji University", "affiliation-city": "Shanghai", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/126714533", "afid": "126714533", "affilname": "Zhongyifeng Construction Group Co.", "affiliation-city": "Suzhou", "affiliation-country": "China"}], "pubmed-id": "34450910", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57208480606", "authid": "57208480606", "authname": "Zhang B.", "surname": "Zhang", "given-name": "Binghan", "initials": "B.", "afid": [{"@_fa": "true", "$": "60073652"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55584795282", "authid": "55584795282", "authname": "Yang B.", "surname": "Yang", "given-name": "Bin", "initials": "B.", "afid": [{"@_fa": "true", "$": "60073652"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57226662924", "authid": "57226662924", "authname": "Wang C.", "surname": "Wang", "given-name": "Congjun", "initials": "C.", "afid": [{"@_fa": "true", "$": "126714533"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57206193276", "authid": "57206193276", "authname": "Wang Z.", "surname": "Wang", "given-name": "Zhichen", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60073652"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57208483765", "authid": "57208483765", "authname": "Liu B.", "surname": "Liu", "given-name": "Boda", "initials": "B.", "afid": [{"@_fa": "true", "$": "60073652"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57226657437", "authid": "57226657437", "authname": "Fang T.", "surname": "Fang", "given-name": "Tengwei", "initials": "T.", "afid": [{"@_fa": "true", "$": "60073652"}]}], "authkeywords": "Computer vision | Cyber\u2013physical systems | Review | Sensing system", "article-number": "5468", "source-id": "130124", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "41": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108226573"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108226573?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108226573&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85108226573&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85108226573", "dc:identifier": "SCOPUS_ID:85108226573", "eid": "2-s2.0-85108226573", "dc:title": "Review: Development and technical design of tangible user interfaces in wide-field areas of application", "dc:creator": "Krestanova A.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "21", "prism:issueIdentifier": "13", "prism:pageRange": null, "prism:coverDate": "2021-07-01", "prism:coverDisplayDate": "1 July 2021", "prism:doi": "10.3390/s21134258", "dc:description": "A tangible user interface or TUI connects physical objects and digital interfaces. It is more interactive and interesting for users than a classic graphic user interface. This article presents a de-scriptive overview of TUI\u2019s real-world applications sorted into ten main application areas\u2014teaching of traditional subjects, medicine and psychology, programming, database development, music and arts, modeling of 3D objects, modeling in architecture, literature and storytelling, adjustable TUI solutions, and commercial TUI smart toys. The paper focuses on TUI\u2019s technical solutions and a description of technical constructions that influences the applicability of TUIs in the real world. Based on the review, the technical concept was divided into two main approaches: the sensory technical concept and technology based on a computer vision algorithm. The sensory technical concept is processed to use wireless technology, sensors, and feedback possibilities in TUI applications. The image processing approach is processed to a marker and markerless approach for object recognition, the use of cameras, and the use of computer vision platforms for TUI applications.", "citedby-count": "7", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60018768", "afid": "60018768", "affilname": "VSB \u2013 Technical University of Ostrava", "affiliation-city": "Ostrava", "affiliation-country": "Czech Republic"}], "pubmed-id": "34206398", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57201528823", "authid": "57201528823", "authname": "Krestanova A.", "surname": "Krestanova", "given-name": "Alice", "initials": "A.", "afid": [{"@_fa": "true", "$": "60018768"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57209013116", "authid": "57209013116", "authname": "Cerny M.", "surname": "Cerny", "given-name": "Martin", "initials": "M.", "afid": [{"@_fa": "true", "$": "60018768"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/35745535200", "authid": "35745535200", "authname": "Augustynek M.", "surname": "Augustynek", "given-name": "Martin", "initials": "M.", "afid": [{"@_fa": "true", "$": "60018768"}]}], "authkeywords": "Augmented reality | Education | Sensors | Smart object | Tangible | Tangible user interface", "article-number": "4258", "source-id": "130124", "fund-acr": "TACR", "fund-no": "TL02000313", "fund-sponsor": "Technology Agency of the Czech Republic", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "42": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104287364"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104287364?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85104287364&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85104287364&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580521001564"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85104287364", "dc:identifier": "SCOPUS_ID:85104287364", "eid": "2-s2.0-85104287364", "dc:title": "Computer vision-based interior construction progress monitoring: A literature review and future research directions", "dc:creator": "Ekanayake B.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "127", "prism:pageRange": null, "prism:coverDate": "2021-07-01", "prism:coverDisplayDate": "July 2021", "prism:doi": "10.1016/j.autcon.2021.103705", "pii": "S0926580521001564", "dc:description": "Computer vision (CV)-based technologies have been used to automate construction progress monitoring. The automation attempts to maximise precision and minimise human intervention in onsite progress monitoring. Such attempts have mainly focussed on exterior construction environments while there are significantly lesser number of studies on interior construction. This imbalance impedes automation of the onsite progress monitoring as a whole. Thus, the core intent of this study is to pave the way for advancing automated indoor progress monitoring by providing a systematic survey of extant literature. Main contributions of this survey include 1) presenting a full spectrum of CV-based approaches, tools, and algorithms adopted for indoor construction progress monitoring (ICPM) 2) portraying a succinct reference to the shortcomings, technical challenges, and scope limitations of the past studies on ICPM. The study then synthesises a readily usable agenda for hybridising CV with other data-driven technologies to improve automation in ICPM.", "citedby-count": "51", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60023932", "afid": "60023932", "affilname": "University of Technology Sydney", "affiliation-city": "Sydney", "affiliation-country": "Australia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57201192439", "authid": "57201192439", "authname": "Ekanayake B.", "surname": "Ekanayake", "given-name": "Biyanka", "initials": "B.", "afid": [{"@_fa": "true", "$": "60023932"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/23101564800", "authid": "23101564800", "authname": "Wong J.K.W.", "surname": "Wong", "given-name": "Johnny Kwok Wai", "initials": "J.K.W.", "afid": [{"@_fa": "true", "$": "60023932"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55633979900", "authid": "55633979900", "authname": "Fini A.A.F.", "surname": "Fini", "given-name": "Alireza Ahmadian Fard", "initials": "A.A.F.", "afid": [{"@_fa": "true", "$": "60023932"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57199140117", "authid": "57199140117", "authname": "Smith P.", "surname": "Smith", "given-name": "Peter", "initials": "P.", "afid": [{"@_fa": "true", "$": "60023932"}]}], "authkeywords": "Computer vision | Indoor construction projects | Interior construction environment | Progress monitoring", "article-number": "103705", "source-id": "24931", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "43": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105749280"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105749280?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105749280&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105749280&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85105749280", "dc:identifier": "SCOPUS_ID:85105749280", "eid": "2-s2.0-85105749280", "dc:title": "Construction of stretching\u2010bending sequential pattern to recognize work cycles for earthmoving excavator from long video sequences", "dc:creator": "Wu Y.", "prism:publicationName": "Sensors", "prism:issn": "14248220", "prism:volume": "21", "prism:issueIdentifier": "10", "prism:pageRange": null, "prism:coverDate": "2021-05-02", "prism:coverDisplayDate": "2 May 2021", "prism:doi": "10.3390/s21103427", "dc:description": "Counting the number of work cycles per unit of time of earthmoving excavators is es-sential in order to calculate their productivity in earthmoving projects. The existing methods based on computer vision (CV) find it difficult to recognize the work cycles of earthmoving excavators effectively in long video sequences. Even the most advanced sequential pattern\u2010based approach finds recognition difficult because it has to discern many atomic actions with a similar visual ap-pearance. In this paper, we combine atomic actions with a similar visual appearance to build a stretching\u2013bending sequential pattern (SBSP) containing only \u201cStretching\u201d and \u201cBending\u201d atomic actions. These two atomic actions are recognized using a deep learning\u2010based single\u2010shot detector (SSD). The intersection over union (IOU) is used to associate atomic actions to recognize the work cycle. In addition, we consider the impact of reality factors (such as driver misoperation) on work cycle recognition, which has been neglected in existing studies. We propose to use the time re-quired to transform \u201cStretching\u201d to \u201cBending\u201d in the work cycle to filter out abnormal work cycles caused by driver misoperation. A case study is used to evaluate the proposed method. The results show that SBSP can effectively recognize the work cycles of earthmoving excavators in real time in long video sequences and has the ability to calculate the productivity of earthmoving excavators accurately.", "citedby-count": "4", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020258", "afid": "60020258", "affilname": "Nanjing Normal University", "affiliation-city": "Nanjing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60014724", "afid": "60014724", "affilname": "Nanjing University of Finance and Economics", "affiliation-city": "Nanjing", "affiliation-country": "China"}], "pubmed-id": "34069105", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "8", "$": "8"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57193860617", "authid": "57193860617", "authname": "Wu Y.", "surname": "Wu", "given-name": "Yiguang", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55891347100", "authid": "55891347100", "authname": "Wang M.", "surname": "Wang", "given-name": "Meizhen", "initials": "M.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55717391000", "authid": "55717391000", "authname": "Liu X.", "surname": "Liu", "given-name": "Xuejun", "initials": "X.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/56969887700", "authid": "56969887700", "authname": "Wang Z.", "surname": "Wang", "given-name": "Ziran", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/57196150652", "authid": "57196150652", "authname": "Ma T.", "surname": "Ma", "given-name": "Tianwu", "initials": "T.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/57193625806", "authid": "57193625806", "authname": "Xie Y.", "surname": "Xie", "given-name": "Yujia", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60014724"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/57203768590", "authid": "57203768590", "authname": "Li X.", "surname": "Li", "given-name": "Xiuquan", "initials": "X.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}, {"@_fa": "true", "@seq": "8", "author-url": "https://api.elsevier.com/content/author/author_id/52164865000", "authid": "52164865000", "authname": "Wang X.", "surname": "Wang", "given-name": "Xing", "initials": "X.", "afid": [{"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}, {"@_fa": "true", "$": "60020258"}]}], "authkeywords": "Atomic action | Computer vision | Deep learning | Earthmoving excavators | Earthmoving projects | Long video sequences | Reality factors | Sequential pattern | Surveillance cameras | Work cycle", "article-number": "3427", "source-id": "130124", "fund-acr": "NSFC", "fund-no": "KYCX20_1180", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "44": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85099630465"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85099630465?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85099630465&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85099630465&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580520311183"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85099630465", "dc:identifier": "SCOPUS_ID:85099630465", "eid": "2-s2.0-85099630465", "dc:title": "Posture-related data collection methods for construction workers: A review", "dc:creator": "Yu Y.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "124", "prism:pageRange": null, "prism:coverDate": "2021-04-01", "prism:coverDisplayDate": "April 2021", "prism:doi": "10.1016/j.autcon.2020.103538", "pii": "S0926580520311183", "dc:description": "Construction workers' posture-related data is closely connected with their safety, health, and productivity performance. The importance of posture-related data has drawn the attention of researchers in construction management and other fields. Accordingly, many data collection methods have been developed and applied to collect posture-related data. Despite the importance of workers' posture-related data, there lacks a review of previous data collection methods in the construction industry. This paper fills the research gap by reviewing previous methods to collect posture-related data for construction workers via 1) summarizing working principles and applications of posture-related data collection in construction management, which demonstrates the extensive use of motion sensors and Red-Green-Blue (RGB) cameras in posture-related data collection, 2) comparing the above methods based on data quality and feasibility on construction sites, which reveals the reason why motion sensors and RGB cameras have been prevalent in previous studies, 3) revealing research gaps of posture-related data collection tools and applications, and providing possible future research directions.", "citedby-count": "28", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60014551", "afid": "60014551", "affilname": "Aston University", "affiliation-city": "Birmingham", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60009506", "afid": "60009506", "affilname": "King Fahd University of Petroleum and Minerals", "affiliation-city": "Dhahran", "affiliation-country": "Saudi Arabia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60008928", "afid": "60008928", "affilname": "The Hong Kong Polytechnic University", "affiliation-city": "Hong Kong", "affiliation-country": "Hong Kong"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57192163569", "authid": "57192163569", "authname": "Yu Y.", "surname": "Yu", "given-name": "Yantao", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60008928"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57192916165", "authid": "57192916165", "authname": "Umer W.", "surname": "Umer", "given-name": "Waleed", "initials": "W.", "afid": [{"@_fa": "true", "$": "60009506"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57013893700", "authid": "57013893700", "authname": "Yang X.", "surname": "Yang", "given-name": "Xincong", "initials": "X.", "afid": [{"@_fa": "true", "$": "60008928"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57195298937", "authid": "57195298937", "authname": "Antwi-Afari M.F.", "surname": "Antwi-Afari", "given-name": "Maxwell Fordjour", "initials": "M.F.", "afid": [{"@_fa": "true", "$": "60014551"}]}], "authkeywords": "Behavior-based safety (BBS) | Computer vision | Construction worker | Deep learning | Motion sensor | Occupational safety and health (OSH) | Pose estimation", "article-number": "103538", "source-id": "24931", "fund-acr": "RGC, UGC", "fund-no": "PolyU 152047/19E", "fund-sponsor": "Research Grants Council, University Grants Committee", "openaccess": "0", "openaccessFlag": false, "freetoread": {"value": [{"$": "all"}, {"$": "repository"}, {"$": "repositoryam"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Green"}]}}, "45": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097906264"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097906264?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097906264&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097906264&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580520310979"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097906264", "dc:identifier": "SCOPUS_ID:85097906264", "eid": "2-s2.0-85097906264", "dc:title": "Roles of artificial intelligence in construction engineering and management: A critical review and future trends", "dc:creator": "Pan Y.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "122", "prism:pageRange": null, "prism:coverDate": "2021-02-01", "prism:coverDisplayDate": "February 2021", "prism:doi": "10.1016/j.autcon.2020.103517", "pii": "S0926580520310979", "dc:description": "With the extensive adoption of artificial intelligence (AI), construction engineering and management (CEM) is experiencing a rapid digital transformation. Since AI-based solutions in CEM has become the current research focus, it needs to be comprehensively understood. In this regard, this paper presents a systematic review under both scientometric and qualitative analysis to present the current state of AI adoption in the context of CEM and discuss its future research trends. To begin with, a scientometric review is performed to explore the characteristics of keywords, journals, and clusters based on 4,473 journal articles published in 1997\u20132020. It is found that there has been an explosion of relevant papers especially in the past 10 years along with the change in keyword popularity from expert systems to building information modeling (BIM), digital twins, and others. Then, a brief understanding of CEM is provided, which can be benefited from the emerging trend of AI in terms of automation, risk mitigation, high efficiency, digitalization, and computer vision. Special concerns have been put on six hot research topics that amply the advantage of AI in CEM, including (1) knowledge representation and reasoning, (2) information fusion, (3) computer vision, (4) natural language processing, (5) intelligence optimization, and (6) process mining. The goal of these topics is to model, predict, and optimize issues in a data-driven manner throughout the whole lifecycle of the actual complex project. To further narrow the gap between AI and CEM, six key directions of future researches, such as smart robotics, cloud virtual and augmented reality (cloud VR/AR), Artificial Intelligence of Things (AIoT), digital twins, 4D printing, and blockchains, are highlighted to constantly facilitate the automation and intelligence in CEM.", "citedby-count": "331", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60118451", "afid": "60118451", "affilname": "School of Civil and Environmental Engineering", "affiliation-city": "Singapore City", "affiliation-country": "Singapore"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57205735838", "authid": "57205735838", "authname": "Pan Y.", "surname": "Pan", "given-name": "Yue", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60118451"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55271615200", "authid": "55271615200", "authname": "Zhang L.", "surname": "Zhang", "given-name": "Limao", "initials": "L.", "afid": [{"@_fa": "true", "$": "60118451"}]}], "authkeywords": "Artificial intelligence | Construction engineering and management | Critical review", "article-number": "103517", "source-id": "24931", "fund-acr": "MOE", "fund-no": "04MNP000279C120", "fund-sponsor": "Ministry of Education - Singapore", "openaccess": "0", "openaccessFlag": false}, "46": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097712417"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097712417?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097712417&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097712417&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580520310967"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097712417", "dc:identifier": "SCOPUS_ID:85097712417", "eid": "2-s2.0-85097712417", "dc:title": "Review of image-based analysis and applications in construction", "dc:creator": "Mostafa K.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "122", "prism:pageRange": null, "prism:coverDate": "2021-02-01", "prism:coverDisplayDate": "February 2021", "prism:doi": "10.1016/j.autcon.2020.103516", "pii": "S0926580520310967", "dc:description": "Image-based analysis techniques offer a robust way to solve engineering problems due to the availability of visual data (e.g., surveillance cameras). Hence, research efforts have focused on applying Image-based techniques in the construction industry to improve the safety and productivity of construction operations as well as the resilience and sustainability of the construction assets. This paper explores the state-of-the-art in Image-based analysis techniques and their applications in construction. Over 100 journal papers were retrieved from the Scopus database for an in-depth review of major applications, benefits, and areas of future research potential. Accordingly, Three main research directions were identified that utilize image-based technologies: (1) construction safety; (2) progress monitoring; and (3) damage assessment. It is observed that most research efforts focused on object detection (e.g., hardhats, defects) for safety inspection and repair planning. Potential future developments include integrating object detection with quantification and sizing techniques to develop more comprehensive applications.", "citedby-count": "51", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60014171", "afid": "60014171", "affilname": "University of Waterloo", "affiliation-city": "Waterloo", "affiliation-country": "Canada"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/122254176", "afid": "122254176", "affilname": "M. ASCE", "affiliation-city": null, "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/101933205", "afid": "101933205", "affilname": "ASCE", "affiliation-city": "Vicksburg", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57209216449", "authid": "57209216449", "authname": "Mostafa K.", "surname": "Mostafa", "given-name": "Kareem", "initials": "K.", "afid": [{"@_fa": "true", "$": "60014171"}, {"@_fa": "true", "$": "101933205"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/7004341761", "authid": "7004341761", "authname": "Hegazy T.", "surname": "Hegazy", "given-name": "Tarek", "initials": "T.", "afid": [{"@_fa": "true", "$": "60014171"}, {"@_fa": "true", "$": "122254176"}]}], "authkeywords": "Artificial intelligence | Computer vision | Construction | Convolutional neural networks (CNNs) | Damage assessment | Image-based analysis | Progress monitoring | Safety", "article-number": "103516", "source-id": "24931", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "47": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100115070"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100115070?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85100115070&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85100115070&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100115070", "dc:identifier": "SCOPUS_ID:85100115070", "eid": "2-s2.0-85100115070", "dc:title": "A systematic survey of ML datasets for prime CV research areas-media and metadata", "dc:creator": "Castro H.F.", "prism:publicationName": "Data", "prism:eIssn": "23065729", "prism:volume": "6", "prism:issueIdentifier": "2", "prism:pageRange": "1-85", "prism:coverDate": "2021-01-01", "prism:coverDisplayDate": "January 2021", "prism:doi": "10.3390/data6020012", "dc:description": "The ever-growing capabilities of computers have enabled pursuing Computer Vision through Machine Learning (i.e., MLCV). ML tools require large amounts of information to learn from (ML datasets). These are costly to produce but have received reduced attention regarding standardization. This prevents the cooperative production and exploitation of these resources, impedes countless synergies, and hinders ML research. No global view exists of the MLCV dataset tissue. Acquiring it is fundamental to enable standardization. We provide an extensive survey of the evolution and current state of MLCV datasets (1994 to 2019) for a set of specific CV areas as well as a quantitative and qualitative analysis of the results. Data were gathered from online scientific databases (e.g., Google Scholar, CiteSeerX). We reveal the heterogeneous plethora that comprises the MLCV dataset tissue; their continuous growth in volume and complexity; the specificities of the evolution of their media and metadata components regarding a range of aspects; and that MLCV progress requires the construction of a global standardized (structuring, manipulating, and sharing) MLCV \u201clibrary\u201d. Accordingly, we formulate a novel interpretation of this dataset collective as a global tissue of synthetic cognitive visual memories and define the immediately necessary steps to advance its standardization and integration.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020432", "afid": "60020432", "affilname": "Institute for Systems and Computer Engineering, Technology and Science", "affiliation-city": "Porto", "affiliation-country": "Portugal"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60007249", "afid": "60007249", "affilname": "Universidade do Porto", "affiliation-city": "Porto", "affiliation-country": "Portugal"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/8295122200", "authid": "8295122200", "authname": "Castro H.F.", "surname": "Castro", "given-name": "Helder F.", "initials": "H.F.", "afid": [{"@_fa": "true", "$": "60020432"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/9245302400", "authid": "9245302400", "authname": "Cardoso J.S.", "surname": "Cardoso", "given-name": "Jaime S.", "initials": "J.S.", "afid": [{"@_fa": "true", "$": "60020432"}, {"@_fa": "true", "$": "60007249"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/24721069200", "authid": "24721069200", "authname": "Andrade M.T.", "surname": "Andrade", "given-name": "Maria T.", "initials": "M.T.", "afid": [{"@_fa": "true", "$": "60020432"}, {"@_fa": "true", "$": "60007249"}]}], "authkeywords": "Computer vision | Dataset | Integration | Machine learning | Media | Metadata", "article-number": "12", "source-id": "21100924372", "fund-acr": "FCT", "fund-no": "SFRH/BPD/108329/2015", "fund-sponsor": "Funda\u00e7\u00e3o para a Ci\u00eancia e a Tecnologia", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "48": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85088372447"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85088372447?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85088372447&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85088372447&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S235271022031915X"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85088372447", "dc:identifier": "SCOPUS_ID:85088372447", "eid": "2-s2.0-85088372447", "dc:title": "Scene understanding in construction and buildings using image processing methods: A comprehensive review and a case study", "dc:creator": "Arashpour M.", "prism:publicationName": "Journal of Building Engineering", "prism:eIssn": "23527102", "prism:volume": "33", "prism:pageRange": null, "prism:coverDate": "2021-01-01", "prism:coverDisplayDate": "January 2021", "prism:doi": "10.1016/j.jobe.2020.101672", "pii": "S235271022031915X", "dc:description": "Acquiring photos and videos has become a new norm in construction and building projects. However, imagery data is not utilized effectively due to the shortage of required skillsets in the industry and nonfamiliarity with classic image processing methods. Computer vision research in the context of construction and building has heavily focused on the interface between machine learning, and object tracking and activity recognition. Although positive results have been reported, namely improved productivity, safety and quality, implementations in the industry will not be immediate. Furthermore, algorithms such as convolutional neural networks (CNN), residual neural networks (ResNet) and recurrent neural networks (RNN) usually need to undergo extensive transfer learning in order to capture project-specific information in civil infrastructure engineering. This paper revisits classic image processing methods that can capture clues of site scenes with capability of high-level reasoning and inference. The work contributes to the body of knowledge by reviewing color, geometry and feature-based diagnostics in project environments.", "citedby-count": "58", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60026553", "afid": "60026553", "affilname": "University of Melbourne", "affiliation-city": "Melbourne", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60019578", "afid": "60019578", "affilname": "Monash University", "affiliation-city": "Melbourne", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60008928", "afid": "60008928", "affilname": "The Hong Kong Polytechnic University", "affiliation-city": "Hong Kong", "affiliation-country": "Hong Kong"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55520813200", "authid": "55520813200", "authname": "Arashpour M.", "surname": "Arashpour", "given-name": "Mehrdad", "initials": "M.", "afid": [{"@_fa": "true", "$": "60019578"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57209597335", "authid": "57209597335", "authname": "Ngo T.", "surname": "Ngo", "given-name": "Tuan", "initials": "T.", "afid": [{"@_fa": "true", "$": "60026553"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8692514900", "authid": "8692514900", "authname": "Li H.", "surname": "Li", "given-name": "Heng", "initials": "H.", "afid": [{"@_fa": "true", "$": "60008928"}]}], "article-number": "101672", "source-id": "21100389518", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": "all"}, "freetoreadLabel": {"value": "All Open Access"}}, "49": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100605338"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100605338?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85100605338&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85100605338&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85100605338", "dc:identifier": "SCOPUS_ID:85100605338", "eid": "2-s2.0-85100605338", "dc:title": "Bibliometric review of visual computing in the construction industry", "dc:creator": "Wang H.W.", "prism:publicationName": "Visual Computing for Industry, Biomedicine, and Art", "prism:issn": "2096496X", "prism:eIssn": "25244442", "prism:volume": "3", "prism:issueIdentifier": "1", "prism:pageRange": null, "prism:coverDate": "2020-12-01", "prism:coverDisplayDate": "December 2020", "prism:doi": "10.1186/s42492-020-00050-0", "dc:description": "In the construction area, visuals such as drawings, photos, videos, and 3D models, play a significant role in the design, build and maintenance of a facility, bringing efficiency to generate, transfer, and store information. Advanced visual computing techniques facilitate the understanding of design contents, work plans, and other types of information shared in the construction industry. Automatic visual data collection and analysis provide many possibilities to the construction industry and a large number of works have investigated how visual computing can improve construction management processes and other problems in the construction area. However, a comprehensive literature review is needed. This study uses bibliometric approaches to review the works published to date, and analyses the development of knowledge, significant research results, and trends. The purpose of this study is to help newcomers to this research field understand knowledge structure and formulate research directions, thereby enhancing knowledge development. From this study, it can be concluded that computer vision is a key axis of improvement. Moreover, building information modeling, laser scanning, and other visualization-related techniques are also important in advancing the construction area.", "citedby-count": "3", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025278", "afid": "60025278", "affilname": "Tsinghua University", "affiliation-city": "Beijing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/124928942", "afid": "124928942", "affilname": "Tsinghua Technology and Innovation Holdings Co., Ltd.", "affiliation-city": "Beijing", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/56704659200", "authid": "56704659200", "authname": "Wang H.W.", "surname": "Wang", "given-name": "Heng Wei", "initials": "H.W.", "afid": [{"@_fa": "true", "$": "124928942"}, {"@_fa": "true", "$": "60025278"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/36147587900", "authid": "36147587900", "authname": "Hu Z.Z.", "surname": "Hu", "given-name": "Zhen Zhong", "initials": "Z.Z.", "afid": [{"@_fa": "true", "$": "60025278"}, {"@_fa": "true", "$": "60025278"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/56703744700", "authid": "56703744700", "orcid": "0000-0003-2195-8675", "authname": "Lin J.R.", "surname": "Lin", "given-name": "Jia Rui", "initials": "J.R.", "afid": [{"@_fa": "true", "$": "60025278"}]}], "authkeywords": "Augmented reality | Bibliometric analysis | Building information modeling | Construction application | Construction management | Laser scanning | Visual computing", "article-number": "14", "source-id": "21101037157", "fund-acr": "NSFC", "fund-no": "51778336", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "50": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097598301"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097598301?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097598301&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097598301&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85097598301", "dc:identifier": "SCOPUS_ID:85097598301", "eid": "2-s2.0-85097598301", "dc:title": "Visual Analytics for Operation-Level Construction Monitoring and Documentation: State-of-the-Art Technologies, Research Challenges, and Future Directions", "dc:creator": "Kim J.", "prism:publicationName": "Frontiers in Built Environment", "prism:eIssn": "22973362", "prism:volume": "6", "prism:pageRange": null, "prism:coverDate": "2020-11-27", "prism:coverDisplayDate": "27 November 2020", "prism:doi": "10.3389/fbuil.2020.575738", "dc:description": "Operation-level vision-based monitoring and documentation has drawn significant attention from construction practitioners and researchers. To automate the operation-level monitoring of construction and built environments, there have been much effort to develop computer vision technologies. Despite their encouraging findings, it remains a major challenge to exploit technologies in real construction projects, implying that there are knowledge gaps in practice and theory. To fill such knowledge gaps, this study thoroughly reviews 119 papers on operation-level vision-based construction monitoring, published in mainstream construction informatics journals. Existing research papers can be categorized into three sequential technologies: (1) camera placement for operation-level construction monitoring, (2) single-camera-based construction monitoring and documentation, and (3) multi-camera-based onsite information integration and construction monitoring. For each technology, state-of-the-art algorithms, open challenges, and future directions are discussed.", "citedby-count": "14", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025778", "afid": "60025778", "affilname": "University of Michigan, Ann Arbor", "affiliation-city": "Ann Arbor", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60013682", "afid": "60013682", "affilname": "Seoul National University", "affiliation-city": "Seoul", "affiliation-country": "South Korea"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57194707212", "authid": "57194707212", "authname": "Kim J.", "surname": "Kim", "given-name": "Jinwoo", "initials": "J.", "afid": [{"@_fa": "true", "$": "60025778"}, {"@_fa": "true", "$": "60013682"}]}], "authkeywords": "computer vision | construction | deep learning | operation-level | site monitoring | state-of-the-art | vision-based", "article-number": "575738", "source-id": "21100897005", "fund-acr": "MOLIT", "fund-no": "undefined", "fund-sponsor": "Ministry of Land, Infrastructure and Transport", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "51": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079644429"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079644429?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079644429&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85079644429&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0925753520300552"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85079644429", "dc:identifier": "SCOPUS_ID:85079644429", "eid": "2-s2.0-85079644429", "dc:title": "A critical review of vision-based occupational health and safety monitoring of construction site workers", "dc:creator": "Zhang M.", "prism:publicationName": "Safety Science", "prism:issn": "09257535", "prism:eIssn": "18791042", "prism:volume": "126", "prism:pageRange": null, "prism:coverDate": "2020-06-01", "prism:coverDisplayDate": "June 2020", "prism:doi": "10.1016/j.ssci.2020.104658", "pii": "S0925753520300552", "dc:description": "Globally, the occupational health and safety (OHS) of construction workers has long been a serious concern. To address this issue, there is an urgent need for an efficient means to continuously monitor the construction site to eliminate potential hazards in a timely manner. As robust and automated video and image information extraction and processing tools for construction sites, computer vision techniques have been considered to be effective solutions and been applied for the occupational health and safety monitoring of construction site workers. This paper aims to use bibliometric and content-based analysis methods to review the previous attempts in related fields and present the current research status in this field. The results clarify the major limitations and challenges of the current research from both technical and practical perspectives, in turn suggesting the direction of future research.", "citedby-count": "66", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60004538", "afid": "60004538", "affilname": "Dalian University of Technology", "affiliation-city": "Dalian", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55704430600", "authid": "55704430600", "authname": "Zhang M.", "surname": "Zhang", "given-name": "Mingyuan", "initials": "M.", "afid": [{"@_fa": "true", "$": "60004538"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57213266048", "authid": "57213266048", "authname": "Shi R.", "surname": "Shi", "given-name": "Rui", "initials": "R.", "afid": [{"@_fa": "true", "$": "60004538"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/58432270000", "authid": "58432270000", "authname": "Yang Z.", "surname": "Yang", "given-name": "Zhen", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60004538"}]}], "authkeywords": "Computer vision | Construction site | Monitoring | Occupational health and safety", "article-number": "104658", "source-id": "12332", "fund-no": "2019-MS-052", "fund-sponsor": "Natural Science Foundation of Liaoning Province", "openaccess": "0", "openaccessFlag": false}, "52": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079526957"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079526957?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079526957&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85079526957&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580519305679"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85079526957", "dc:identifier": "SCOPUS_ID:85079526957", "eid": "2-s2.0-85079526957", "dc:title": "Sensor-based safety management", "dc:creator": "Asadzadeh A.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "113", "prism:pageRange": null, "prism:coverDate": "2020-05-01", "prism:coverDisplayDate": "May 2020", "prism:doi": "10.1016/j.autcon.2020.103128", "pii": "S0926580519305679", "dc:description": "The construction industry has one of the most hazardous working environments worldwide, which accounts for about 1 in every 5 occupational fatalities. The high rates of workplace injuries, illnesses and fatalities cause irreversible harm to workers and are often the source of delays and additional project costs. Improvements in sensor technologies, wireless communication, the processing power of computers, and advancements in machine learning and computer vision are now enabling the development of sensor-based safety management systems. The rapid growth of Building Information Modelling (BIM) has also created opportunities for improving safety management. While considerable progress has been made to improve construction safety, few studies have focused on the integration of sensor-based systems and BIM. This research, which is motivated by the development of such integrated methods, carries out a systematic review of the relevant literature, summarising recent developments of sensor-based safety management systems and advancements in safety management through BIM. The research gaps are identified and an outline for potential future research is provided. The results of the review reveal the potential of combining sensor-driven systems with BIM for improving safety management in construction.", "citedby-count": "67", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60026553", "afid": "60026553", "affilname": "University of Melbourne", "affiliation-city": "Melbourne", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60019578", "afid": "60019578", "affilname": "Monash University", "affiliation-city": "Melbourne", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60018894", "afid": "60018894", "affilname": "Monash University Malaysia", "affiliation-city": "Bandar Sunway", "affiliation-country": "Malaysia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60011362", "afid": "60011362", "affilname": "RMIT University", "affiliation-city": "Melbourne", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60008928", "afid": "60008928", "affilname": "The Hong Kong Polytechnic University", "affiliation-city": "Hong Kong", "affiliation-country": "Hong Kong"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57214939017", "authid": "57214939017", "authname": "Asadzadeh A.", "surname": "Asadzadeh", "given-name": "Amin", "initials": "A.", "afid": [{"@_fa": "true", "$": "60019578"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55520813200", "authid": "55520813200", "authname": "Arashpour M.", "surname": "Arashpour", "given-name": "Mehrdad", "initials": "M.", "afid": [{"@_fa": "true", "$": "60019578"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8692514900", "authid": "8692514900", "authname": "Li H.", "surname": "Li", "given-name": "Heng", "initials": "H.", "afid": [{"@_fa": "true", "$": "60008928"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57209597335", "authid": "57209597335", "authname": "Ngo T.", "surname": "Ngo", "given-name": "Tuan", "initials": "T.", "afid": [{"@_fa": "true", "$": "60026553"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/6603333330", "authid": "6603333330", "authname": "Bab-Hadiashar A.", "surname": "Bab-Hadiashar", "given-name": "Alireza", "initials": "A.", "afid": [{"@_fa": "true", "$": "60011362"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/56704599800", "authid": "56704599800", "authname": "Rashidi A.", "surname": "Rashidi", "given-name": "Ali", "initials": "A.", "afid": [{"@_fa": "true", "$": "60018894"}]}], "article-number": "103128", "source-id": "24931", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "53": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85076051479"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85076051479?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85076051479&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85076051479&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580519301487"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85076051479", "dc:identifier": "SCOPUS_ID:85076051479", "eid": "2-s2.0-85076051479", "dc:title": "Computer vision applications in construction safety assurance", "dc:creator": "Fang W.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "110", "prism:pageRange": null, "prism:coverDate": "2020-02-01", "prism:coverDisplayDate": "February 2020", "prism:doi": "10.1016/j.autcon.2019.103013", "pii": "S0926580519301487", "dc:description": "Advancements in the development of deep learning and computer vision-based approaches have the potential to provide managers and engineers with the ability to improve the safety performance of their construction operations on-site. In practice, however, the application of deep learning and computer vision has been limited due to an array of technical (e.g., accuracy and reliability) and managerial challenges. These challenges are a product of the dynamic and complex nature of construction and the difficulties associated with acquiring video surveillance data. In this paper, we design and develop a deep learning and computer vision-based framework for safety in construction by integrating an array of digital technologies with multiple aspects of data fusion. Then, we review existing studies that have focused on identifying unsafe behavior and work conditions and develop a computer-vision enabled framework that: (1) considers current progress on computer vision and deep learning for safety; (2) identifies the research challenges that can materialize with using deep learning to identify unsafe behavior and work conditions; and (3) can provide a signpost for future research in the emergent and fertile area of deep-learning within the context of safety.", "citedby-count": "109", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60031226", "afid": "60031226", "affilname": "Curtin University", "affiliation-city": "Perth", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60030162", "afid": "60030162", "affilname": "Columbia University", "affiliation-city": "New York", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025761", "afid": "60025761", "affilname": "Huazhong University of Science and Technology", "affiliation-city": "Wuhan", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60008928", "afid": "60008928", "affilname": "The Hong Kong Polytechnic University", "affiliation-city": "Hong Kong", "affiliation-country": "Hong Kong"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/123534844", "afid": "123534844", "affilname": "430074 China", "affiliation-city": "Wuhan", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "8", "$": "8"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57199951778", "authid": "57199951778", "authname": "Fang W.", "surname": "Fang", "given-name": "Weili", "initials": "W.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "123534844"}, {"@_fa": "true", "$": "60030162"}, {"@_fa": "true", "$": "60031226"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/8909046000", "authid": "8909046000", "authname": "Ding L.", "surname": "Ding", "given-name": "Lieyun", "initials": "L.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "123534844"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57205302607", "authid": "57205302607", "authname": "Love P.E.D.", "surname": "Love", "given-name": "Peter E.D.", "initials": "P.E.D.", "afid": [{"@_fa": "true", "$": "60031226"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/23976309500", "authid": "23976309500", "authname": "Luo H.", "surname": "Luo", "given-name": "Hanbin", "initials": "H.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "123534844"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/8692514900", "authid": "8692514900", "authname": "Li H.", "surname": "Li", "given-name": "Heng", "initials": "H.", "afid": [{"@_fa": "true", "$": "60008928"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/7003601545", "authid": "7003601545", "authname": "Pe\u00f1a-Mora F.", "surname": "Pe\u00f1a-Mora", "given-name": "Feniosky", "initials": "F.", "afid": [{"@_fa": "true", "$": "60030162"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/23975246400", "authid": "23975246400", "authname": "Zhong B.", "surname": "Zhong", "given-name": "Botao", "initials": "B.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "123534844"}]}, {"@_fa": "true", "@seq": "8", "author-url": "https://api.elsevier.com/content/author/author_id/55509744400", "authid": "55509744400", "authname": "Zhou C.", "surname": "Zhou", "given-name": "Cheng", "initials": "C.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "123534844"}]}], "authkeywords": "Computer vision | Deep learning | Digital technology | Safety", "article-number": "103013", "source-id": "24931", "fund-acr": "NSFC", "fund-no": "51678265", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "54": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85074894139"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85074894139?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074894139&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85074894139&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S1474034619305531"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85074894139", "dc:identifier": "SCOPUS_ID:85074894139", "eid": "2-s2.0-85074894139", "dc:title": "Computer vision for behaviour-based safety in construction: A review and future directions", "dc:creator": "Fang W.", "prism:publicationName": "Advanced Engineering Informatics", "prism:issn": "14740346", "prism:volume": "43", "prism:pageRange": null, "prism:coverDate": "2020-01-01", "prism:coverDisplayDate": "January 2020", "prism:doi": "10.1016/j.aei.2019.100980", "pii": "S1474034619305531", "dc:description": "The process of identifying and bringing to the fore people's unsafe behaviour is a core function of implementing a behaviour-based safety (BBS) program in construction. This can be a labour-intensive and challenging process but is needed to enable people to reflect and learn about how their unsafe actions can jeopardise not only their safety but that of their co-workers. With advances being made in computer vision, the capability exists to automatically capture and identify unsafe behaviour and hazards in real-time from two-dimensional (2D) digital images/videos. The corollary developments in computer vision have stimulated a wealth of research in construction to examine its potential application to practice. Hindering the application of computer vision in construction has been its inability to accurately, and generalise the detection of objects. To address this shortcoming, developments in deep learning have provided computer vision with the ability to improve the accuracy, reliability and ability to generalise object detection and therefore its usage in construction. In this paper we review the developments of computer vision studies that have been used to identify unsafe behaviour from 2D images that arises on construction sites. Then, in light of advances made with deep learning, we examine and discuss its integration with computer vision to support BBS. We also suggest that future computer-vision research should aim to support BBS by being able to: (1) observe and record unsafe behaviour; (2) understand why people act unsafe behaviour; (3) learn from unsafe behaviour; and (4) predict unsafe behaviour.", "citedby-count": "137", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60031226", "afid": "60031226", "affilname": "Curtin University", "affiliation-city": "Perth", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60030162", "afid": "60030162", "affilname": "Columbia University", "affiliation-city": "New York", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025761", "afid": "60025761", "affilname": "Huazhong University of Science and Technology", "affiliation-city": "Wuhan", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/118690998", "afid": "118690998", "affilname": "Hubei Engineering Research Center for Virtual, Safe and Automated Construction", "affiliation-city": "Wuhan", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57199951778", "authid": "57199951778", "authname": "Fang W.", "surname": "Fang", "given-name": "Weili", "initials": "W.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "118690998"}, {"@_fa": "true", "$": "60031226"}, {"@_fa": "true", "$": "60030162"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57205302607", "authid": "57205302607", "authname": "Love P.E.D.", "surname": "Love", "given-name": "Peter E.D.", "initials": "P.E.D.", "afid": [{"@_fa": "true", "$": "60031226"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/23976309500", "authid": "23976309500", "authname": "Luo H.", "surname": "Luo", "given-name": "Hanbin", "initials": "H.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "118690998"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/8909046000", "authid": "8909046000", "authname": "Ding L.", "surname": "Ding", "given-name": "Lieyun", "initials": "L.", "afid": [{"@_fa": "true", "$": "60025761"}, {"@_fa": "true", "$": "118690998"}]}], "authkeywords": "Behaviour-based safety | Computer vision | Convolutional neural network | Deep learning | Unsafe behaviour", "article-number": "100980", "source-id": "23640", "fund-acr": "NSFC", "fund-no": "51678265", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "55": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85071757853"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85071757853?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85071757853&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85071757853&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580519305758"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85071757853", "dc:identifier": "SCOPUS_ID:85071757853", "eid": "2-s2.0-85071757853", "dc:title": "A scientometric analysis and critical review of computer vision applications for construction", "dc:creator": "Martinez P.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "107", "prism:pageRange": null, "prism:coverDate": "2019-11-01", "prism:coverDisplayDate": "November 2019", "prism:doi": "10.1016/j.autcon.2019.102947", "pii": "S0926580519305758", "dc:description": "Practical interest in \u2018computer vision\u2019 has risen remarkably over the last 20 years, transforming the current state of construction-related research and attracting the worldwide attention of scholars and practitioners. This study conducts a scientometric review of the global research published between 1999 and 2019 on computer vision applications for construction, through co-author, co-citation, keyword and clustering analysis. A total of 1158 journals and conference proceedings from Scopus database were analyzed. Trends within the field are identified, as are the dominant sub-fields and their interconnections, as well as citation patterns, key publications, key research institutions, key researchers, and key journals, along with the extent to which these interact with each other in research networks. The provided results were analyzed to identify the deficiencies in current research and propose future trends. Among these is a bias in the research literature towards traditional on-site construction and a concerning gap of off-site construction research, as well as a lack of inter-relationships and collaboration between researched areas, the researchers themselves, and/or the research institutions. In the near future, computer vision will play a key role in the future development of smart construction and improvement of quality in construction projects. This study hopes to bring awareness to the industry, the journal editors, and the researchers of the need for a deeper exchange of ideas in any future research efforts.", "citedby-count": "114", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60030835", "afid": "60030835", "affilname": "University of Alberta", "affiliation-city": "Edmonton", "affiliation-country": "Canada"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57206253811", "authid": "57206253811", "authname": "Martinez P.", "surname": "Martinez", "given-name": "Pablo", "initials": "P.", "afid": [{"@_fa": "true", "$": "60030835"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/6603541102", "authid": "6603541102", "authname": "Al-Hussein M.", "surname": "Al-Hussein", "given-name": "Mohamed", "initials": "M.", "afid": [{"@_fa": "true", "$": "60030835"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/57201013693", "authid": "57201013693", "authname": "Ahmad R.", "surname": "Ahmad", "given-name": "Rafiq", "initials": "R.", "afid": [{"@_fa": "true", "$": "60030835"}]}], "authkeywords": "Computer vision | Construction | Critical review | Off-site construction | Scientometric analysis", "article-number": "102947", "source-id": "24931", "fund-acr": "NSERC", "fund-no": "undefined", "fund-sponsor": "Natural Sciences and Engineering Research Council of Canada", "openaccess": "0", "openaccessFlag": false}, "56": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85069863311"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85069863311?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85069863311&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85069863311&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580519303875"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85069863311", "dc:identifier": "SCOPUS_ID:85069863311", "eid": "2-s2.0-85069863311", "dc:title": "Mapping computer vision research in construction: Developments, knowledge gaps and implications for research", "dc:creator": "Zhong B.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "107", "prism:pageRange": null, "prism:coverDate": "2019-11-01", "prism:coverDisplayDate": "November 2019", "prism:doi": "10.1016/j.autcon.2019.102919", "pii": "S0926580519303875", "dc:description": "Computer vision is transforming processes associated with the engineering and management of construction projects. It can enable the acquisition, processing, analysis of digital images, and the extraction of high-dimensional data from the real world to produce information to improve managerial decision-making. To acquire an understanding of the developments and applications of computer vision research within the field of construction, we performed a detailed bibliometric and scientometric analysis of the normative literature from 2000 to 2018. We identified the primary areas where computer vision has been applied, including defect inspection, safety monitoring, and performance analysis. By performing a mapping exercise, a detailed analysis of the computer vision literature enables the identification of gaps in knowledge, which provides a platform to support future research in this fertile area for construction.", "citedby-count": "75", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60031226", "afid": "60031226", "affilname": "Curtin University", "affiliation-city": "Perth", "affiliation-country": "Australia"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025761", "afid": "60025761", "affilname": "Huazhong University of Science and Technology", "affiliation-city": "Wuhan", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60008928", "afid": "60008928", "affilname": "The Hong Kong Polytechnic University", "affiliation-city": "Hong Kong", "affiliation-country": "Hong Kong"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "7", "$": "7"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/23975246400", "authid": "23975246400", "authname": "Zhong B.", "surname": "Zhong", "given-name": "B.", "initials": "B.", "afid": [{"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57205511865", "authid": "57205511865", "authname": "Wu H.", "surname": "Wu", "given-name": "Haitao", "initials": "H.", "afid": [{"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8909046000", "authid": "8909046000", "authname": "Ding L.", "surname": "Ding", "given-name": "Lieyun", "initials": "L.", "afid": [{"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57205302607", "authid": "57205302607", "authname": "Love P.E.D.", "surname": "Love", "given-name": "Peter E.D.", "initials": "P.E.D.", "afid": [{"@_fa": "true", "$": "60031226"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/8692514900", "authid": "8692514900", "authname": "Li H.", "surname": "Li", "given-name": "Heng", "initials": "H.", "afid": [{"@_fa": "true", "$": "60008928"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/23976309500", "authid": "23976309500", "authname": "Luo H.", "surname": "Luo", "given-name": "Hanbin", "initials": "H.", "afid": [{"@_fa": "true", "$": "60025761"}]}, {"@_fa": "true", "@seq": "7", "author-url": "https://api.elsevier.com/content/author/author_id/57210184123", "authid": "57210184123", "authname": "Jiao L.", "surname": "Jiao", "given-name": "Li", "initials": "L.", "afid": [{"@_fa": "true", "$": "60025761"}]}], "authkeywords": "Computer vision | Construction | Review | Science mapping", "article-number": "102919", "source-id": "24931", "fund-acr": "NSFC", "fund-no": "51878311", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "57": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061964552"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061964552?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061964552&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85061964552&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0926580518303777"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85061964552", "dc:identifier": "SCOPUS_ID:85061964552", "eid": "2-s2.0-85061964552", "dc:title": "Adaptive computer vision-based 2D tracking of workers in complex environments", "dc:creator": "Konstantinou E.", "prism:publicationName": "Automation in Construction", "prism:issn": "09265805", "prism:volume": "103", "prism:pageRange": "168-184", "prism:coverDate": "2019-07-01", "prism:coverDisplayDate": "July 2019", "prism:doi": "10.1016/j.autcon.2019.01.018", "pii": "S0926580518303777", "dc:description": "Monitoring of construction workers is important in managing labour productivity. To date, the construction sector relies either on intensive manual observations or intrusive tag-based practices. Visual tracking methods can provide automated and tag-less monitoring. However, no method to date has succeeded in tracking multiple workers, as construction sites are complex environments due to congestion, background clutter and occlusions. In addition, workers have similar appearance and exhibit illumination/scale/posture variations and abrupt changes in movement over the course of their task. To address these shortcomings, we propose a vision-based method that consists of 3 models. Firstly, an adaptive model provides continuous information about the previous position of workers and their appearance features. Secondly, a prediction model is used to calculate the current position of workers, and finally, an appearance model provides accurate localisation. Experimental results show that the proposed method achieves high performance and outperforms the latest relevant state of the art methods.", "citedby-count": "35", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60031101", "afid": "60031101", "affilname": "University of Cambridge", "affiliation-city": "Cambridge", "affiliation-country": "United Kingdom"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57190003646", "authid": "57190003646", "authname": "Konstantinou E.", "surname": "Konstantinou", "given-name": "Eirini", "initials": "E.", "afid": [{"@_fa": "true", "$": "60031101"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/6701831900", "authid": "6701831900", "authname": "Lasenby J.", "surname": "Lasenby", "given-name": "Joan", "initials": "J.", "afid": [{"@_fa": "true", "$": "60031101"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8837673400", "authid": "8837673400", "orcid": "0000-0003-1829-2083", "authname": "Brilakis I.", "surname": "Brilakis", "given-name": "Ioannis", "initials": "I.", "afid": [{"@_fa": "true", "$": "60031101"}]}], "authkeywords": "Computer vision | Construction | Tracking | Workers", "source-id": "24931", "fund-acr": "EPSRC", "fund-no": "13440016", "fund-sponsor": "Engineering and Physical Sciences Research Council", "openaccess": "0", "openaccessFlag": false, "freetoread": {"value": [{"$": "all"}, {"$": "repository"}, {"$": "repositoryam"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Green"}]}}, "58": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85067122075"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85067122075?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067122075&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85067122075&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85067122075", "dc:identifier": "SCOPUS_ID:85067122075", "eid": "2-s2.0-85067122075", "dc:title": "Deconstructing the construction industry-[Opinion]", "prism:publicationName": "IEEE Spectrum", "prism:issn": "00189235", "prism:eIssn": "19399340", "prism:volume": "56", "prism:issueIdentifier": "6", "prism:pageRange": "20", "prism:coverDate": "2019-06-01", "prism:coverDisplayDate": "June 2019", "prism:doi": "10.1109/MSPEC.2019.8727140", "dc:description": "THE CONSTRUCTION INDUSTRY can be a mess. When constructing any building, there are several steps you must take in a specific order, so a snag in one step tends to snowball into more problems down the line. You can't start on drywall until the plumbers and electricians complete their work, for example, and if the drywall folks are behind, the crew working on the interior finish gets delayed even more. \u2022 Developers and general contractors hope that by adopting Internet of Things (IoT) solutions to cut costs, build faster, and use a limited labor pool more efficiently, they can turn the messy, fragmented world of building construction into something more closely resembling what it actually is-A manufacturing process. \u2022 'We're looking at the most fragmented and nonstructured process ever, but it is still a manufacturing process,' says Meirav Oren, the CEO of Versatile Natures, an Israeli company that provides on-site data-collection technology to construction sites. The more you understand the process, says Oren, the better you are at automating it. In other conversations I've had with people in the construction sector, the focus isn't on prefabricated housing or cool bricklaying robots. The focus is on turning construction into a regimented process that can be better understood and optimized. \u2022 Like agriculture-which has undergone its own revolution, thanks to connected tech-construction is labor intensive, dependent on environmental factors, and highly regulated. In farming today, lidar identifies insects while robots pick weeds with the aid of computer vision. The goal in agricultural tech is to make workers more efficient, rather than eliminating them. Construction technology startups, using artificial intelligence and the IoT, have a similar goal.", "citedby-count": "1", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "0"}, "article-number": "8727140", "source-id": "17318", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfree2read"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Bronze"}]}}, "59": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85067605244"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85067605244?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067605244&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85067605244&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85067605244", "dc:identifier": "SCOPUS_ID:85067605244", "eid": "2-s2.0-85067605244", "dc:title": "A review on modeling of flexible deformable object for dexterous robotic manipulation", "dc:creator": "Hou Y.C.", "prism:publicationName": "International Journal of Advanced Robotic Systems", "prism:issn": "17298806", "prism:eIssn": "17298814", "prism:volume": "16", "prism:issueIdentifier": "3", "prism:pageRange": null, "prism:coverDate": "2019-05-01", "prism:coverDisplayDate": "1 May 2019", "prism:doi": "10.1177/1729881419848894", "dc:description": "In this article, we present a review on the recent advancement in flexible deformable object modeling for dexterous manipulation in robotic system. Flexible deformable object is one of the most research topics in computer graphic, computer vision, and robotic literature. The deformable models are known as the construction of object with material parameters in virtual environment to describe the deformation behavior. Existing modeling techniques and different types of deformable model are described. Various approaches of deformable object modeling have been used in robotic recognition and manipulation in order to reduce the time and cost to obtain more accurate result. In robotic manipulation, object detection, classification, and recognition of deformable objects are always a challenging problem and required as a first step to imbue the robot to able handle these deformable objects. Furthermore, the dexterity of robot control is also another essential key in handling of deformable object which its manipulation strategies need to plan intelligently for each sequence process. We also discuss some deserving direction for further research based on most current contribution.", "citedby-count": "19", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60005762", "afid": "60005762", "affilname": "Universiti Tenaga Nasional", "affiliation-city": "Kajang", "affiliation-country": "Malaysia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/37067465000", "authid": "37067465000", "authname": "Hou Y.C.", "surname": "Hou", "given-name": "Yew Cheong", "initials": "Y.C.", "afid": [{"@_fa": "true", "$": "60005762"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57218170038", "authid": "57218170038", "authname": "Sahari K.S.M.", "surname": "Sahari", "given-name": "Khairul Salleh Mohamed", "initials": "K.S.M.", "afid": [{"@_fa": "true", "$": "60005762"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/56942483000", "authid": "56942483000", "authname": "How D.N.T.", "surname": "How", "given-name": "Dickson Neoh Tze", "initials": "D.N.T.", "afid": [{"@_fa": "true", "$": "60005762"}]}], "authkeywords": "deformable modeling | Flexible deformable object | recognition and manipulation | robotic control", "source-id": "144749", "fund-acr": "MOHE", "fund-no": "20140127FRGS", "fund-sponsor": "Ministry of Higher Education, Malaysia", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}]}}, "60": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051123154"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051123154?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85051123154&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85051123154&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0168169918305829"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85051123154", "dc:identifier": "SCOPUS_ID:85051123154", "eid": "2-s2.0-85051123154", "dc:title": "Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review", "dc:creator": "Patr\u00edcio D.I.", "prism:publicationName": "Computers and Electronics in Agriculture", "prism:issn": "01681699", "prism:volume": "153", "prism:pageRange": "69-81", "prism:coverDate": "2018-10-01", "prism:coverDisplayDate": "October 2018", "prism:doi": "10.1016/j.compag.2018.08.001", "pii": "S0168169918305829", "dc:description": "Grain production plays an important role in the global economy. In this sense, the demand for efficient and safe methods of food production is increasing. Information Technology is one of the tools to that end. Among the available tools, we highlight computer vision solutions combined with artificial intelligence algorithms that achieved important results in the detection of patterns in images. In this context, this work presents a systematic review that aims to identify the applicability of computer vision in precision agriculture for the production of the five most produced grains in the world: maize, rice, wheat, soybean, and barley. In this sense, we present 25 papers selected in the last five years with different approaches to treat aspects related to disease detection, grain quality, and phenotyping. From the results of the systematic review, it is possible to identify great opportunities, such as the exploitation of GPU (Graphics Processing Unit) and advanced artificial intelligence techniques, such as DBN (Deep Belief Networks) in the construction of robust methods of computer vision applied to precision agriculture.", "citedby-count": "490", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025701", "afid": "60025701", "affilname": "Universidade de Passo Fundo", "affiliation-city": "Passo Fundo", "affiliation-country": "Brazil"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60009625", "afid": "60009625", "affilname": "Empresa Brasileira de Pesquisa Agropecu\u00e1ria - Embrapa", "affiliation-city": "Brasilia", "affiliation-country": "Brazil"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57203098402", "authid": "57203098402", "authname": "Patr\u00edcio D.I.", "surname": "Patr\u00edcio", "given-name": "Diego In\u00e1cio", "initials": "D.I.", "afid": [{"@_fa": "true", "$": "60009625"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/24597781600", "authid": "24597781600", "orcid": "0000-0002-7933-5115", "authname": "Rieder R.", "surname": "Rieder", "given-name": "Rafael", "initials": "R.", "afid": [{"@_fa": "true", "$": "60025701"}]}], "authkeywords": "Artificial intelligence | Computer vision | Precision agriculture | Systematic review", "source-id": "30441", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false, "freetoread": {"value": [{"$": "all"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Green"}]}}, "61": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85053730999"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85053730999?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85053730999&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85053730999&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85053730999", "dc:identifier": "SCOPUS_ID:85053730999", "eid": "2-s2.0-85053730999", "dc:title": "Research and Prospect of Intellectualized Air Traffic Management Technology", "dc:creator": "Yang H.", "prism:publicationName": "Gongcheng Kexue Yu Jishu/Advanced Engineering Sciences", "prism:issn": "20963246", "prism:volume": "50", "prism:issueIdentifier": "4", "prism:pageRange": "12-21", "prism:coverDate": "2018-07-20", "prism:coverDisplayDate": "20 July 2018", "prism:doi": "10.15961/j.jsuese.201800688", "dc:description": "Air transport plays an important role in promoting the world economy and social development. The statistics of international civil aviation organization show that global air traffic is approximately doubled every fifteen years, and the existing air traffic navigation system is close to saturation. The existing air traffic management (ATM) systems automatically acquire and process air traffic control information for air traffic controller, through surveillance data fusion, flight data processing, meteorology and aeronautical information processing and safety nets processing. However, the limited decision-making support ability leads to the low intelligent degree of ATM system, which can't meet the need of the future development of ATM. In order to adapt to the rapid development of aviation industry in the future, some countries and organizations are committed to carrying out new technologies to solve the problems of air traffic safety, airspace congestion and flight delays. In 2004, the EU proposed the \"Single European Sky ATM Research(SESAR)\" program and proposed tore-plan European airspace to meet air traffic demand and improve the efficiency of ATM system. The key technologies of the program include four key areas of ATM: efficient airport operations, advanced air traffic services, optimized air traffic network services and reliable ATC infrastructure. In 2005, the United States proposed the next generation air transportation system(NEXTGEN), including ADS-B, data communication, en route automation modernization, terminal automation modernization and replacement, NAS voice system and system wide information management. In 2012, ICAO launched the aviation system block upgrade plan (ASBU). The ASBU involved four aviation performance improvement areas, including airport operations, globally interoperable systems and data, optimum capacity and flexible flights and efficient flight path. Each area consists of multiple threads and distributed in four blocks according to the implementation stage. CAAC is also implementing or planning a large number of ASBU modules to cope with the rapid development of Chinese civil aviation. The existing ATM system and its future planning mainly focus on the infrastructure construction, without enough intelligent applications. In recent years, with the support of deep learning, high performance computing and big data, artificial intelligence technology has been rapidly used in various fields. Especially, technologies of computer vision, speech recognition and natural language processing have made breakthrough and rapid industrialization. Artificial intelligence, represented by deep learning, emphasizes that judgment and decision-making based on a large number of prior knowledge, which is consistent with the decision-making process of ATM. Therefore, artificial intelligence technology can promote the development of air traffic control key technologies, improve safety and the efficiency of air traffic control and reduce the workload of air traffic controller. The great benefit of the rapid development of artificial intelligence makes the intellectualized ATM a necessity. In this paper, the concept of intellectualized ATM and the overall framework of intellectualized ATM system were presented. The overall framework of intellectualized ATM includes the perception layer, network layer, platform layer, application layer and visual layer. All kinds of communication, navigation, surveillance, weather, wireless, video capture, radio frequency identification and other facilities of the perception layer offer the infrastructures for ATM. The network layer transmits information by using special line network, satellite communication network, Internet, mobile network and so on. The platform layer achieves information storage, sharing and mining by using of SWIM, cloud computing, intelligent big data mining. Application layer studies the application of artificial intelligence technology in air traffic control, airspace management, air traffic flow management, flight service, general aviation and unmanned aerial vehicle. The visual layer provides efficient and intelligent interaction through the portal, virtual visualization, intelligent UI and mobile applications. The research direction of intellectualized ATM includes intelligent ATM data processing, intelligent decision-making, air traffic control speech recognition and air traffic control robot. The intelligent ATM data processing involves various kinds of ATM data acquisition, processing, transmission, interaction and intelligent mining. Intelligent decision-making focuses on intelligent conflict management, intelligent air traffic flow management, intelligent planning and management, intelligent AMAN and DMAN, intelligent airport operation, etc. In view of the important role of ground-to-air communication in air traffic control, the intelligent simulation pilot and air traffic control safety monitoring based on automatic speech recognition should be studied. The intellectualized ATM system has the capabilities of air traffic control perception, planning, reasoning and action based on artificial intelligence. Thus, the overall framework and key technologies provide the theoretical basis and technical support for the development of intellectualized ATM system.", "citedby-count": "10", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60016521", "afid": "60016521", "affilname": "Sichuan University", "affiliation-city": "Chengdu", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57193828842", "authid": "57193828842", "authname": "Yang H.", "surname": "Yang", "given-name": "Hongyu", "initials": "H.", "afid": [{"@_fa": "true", "$": "60016521"}, {"@_fa": "true", "$": "60016521"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56991744600", "authid": "56991744600", "authname": "Yang B.", "surname": "Yang", "given-name": "Bo", "initials": "B.", "afid": [{"@_fa": "true", "$": "60016521"}, {"@_fa": "true", "$": "60016521"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/56991619500", "authid": "56991619500", "authname": "Wu X.", "surname": "Wu", "given-name": "Xiping", "initials": "X.", "afid": [{"@_fa": "true", "$": "60016521"}, {"@_fa": "true", "$": "60016521"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/57199157025", "authid": "57199157025", "authname": "Yu J.", "surname": "Yu", "given-name": "Jing", "initials": "J.", "afid": [{"@_fa": "true", "$": "60016521"}, {"@_fa": "true", "$": "60016521"}]}], "authkeywords": "Air traffic management | Artificial intelligence | ATM robot | Deep learning | Reinforcement learning", "source-id": "21100805730", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "62": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85037055911"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85037055911?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85037055911&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85037055911&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85037055911", "dc:identifier": "SCOPUS_ID:85037055911", "eid": "2-s2.0-85037055911", "dc:title": "Survey of recent progress in semantic image segmentation with CNNs", "dc:creator": "Geng Q.", "prism:publicationName": "Science China Information Sciences", "prism:issn": "1674733X", "prism:eIssn": "18691919", "prism:volume": "61", "prism:issueIdentifier": "5", "prism:pageRange": null, "prism:coverDate": "2018-05-01", "prism:coverDisplayDate": "1 May 2018", "prism:doi": "10.1007/s11432-017-9189-6", "dc:description": "In recent years, convolutional neural networks (CNNs) are leading the way in many computer vision tasks, such as image classification, object detection, and face recognition. In order to produce more refined semantic image segmentation, we survey the powerful CNNs and novel elaborate layers, structures and strategies, especially including those that have achieved the state-of-the-art results on the Pascal VOC 2012 semantic segmentation challenge. Moreover, we discuss their different working stages and various mechanisms to utilize the structural and contextual information in the image and feature spaces. Finally, combining some popular underlying referential methods in homologous problems, we propose several possible directions and approaches to incorporate existing effective methods as components to enhance CNNs for the segmentation of specific semantic objects.", "citedby-count": "68", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60273040", "afid": "60273040", "affilname": "Institute of Information Engineering", "affiliation-city": "Beijing", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60013789", "afid": "60013789", "affilname": "Beihang University", "affiliation-city": "Beijing", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/49361292200", "authid": "49361292200", "authname": "Geng Q.", "surname": "Geng", "given-name": "Qichuan", "initials": "Q.", "afid": [{"@_fa": "true", "$": "60013789"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/8935295700", "authid": "8935295700", "authname": "Zhou Z.", "surname": "Zhou", "given-name": "Zhong", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60013789"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8920951000", "authid": "8920951000", "authname": "Cao X.", "surname": "Cao", "given-name": "Xiaochun", "initials": "X.", "afid": [{"@_fa": "true", "$": "60273040"}]}], "authkeywords": "CNN | construction of contextual relationships | multi-granularity features | Pascal VOC 2012 challenge | semantic image segmentation", "article-number": "051101", "source-id": "19600161832", "fund-acr": "NSFC", "fund-no": "61472020", "fund-sponsor": "National Natural Science Foundation of China", "openaccess": "0", "openaccessFlag": false}, "63": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85027377841"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85027377841?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85027377841&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85027377841&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85027377841", "dc:identifier": "SCOPUS_ID:85027377841", "eid": "2-s2.0-85027377841", "dc:title": "Applying sensor-based technology to improve construction safety management", "dc:creator": "Zhang M.", "prism:publicationName": "Sensors (Switzerland)", "prism:issn": "14248220", "prism:volume": "17", "prism:issueIdentifier": "8", "prism:pageRange": null, "prism:coverDate": "2017-08-11", "prism:coverDisplayDate": "11 August 2017", "prism:doi": "10.3390/s17081841", "dc:description": "Construction sites are dynamic and complicated systems. The movement and interaction of people, goods and energy make construction safety management extremely difficult. Due to the ever-increasing amount of information, traditional construction safety management has operated under difficult circumstances. As an effective way to collect, identify and process information, sensor-based technology is deemed to provide new generation of methods for advancing construction safety management. It makes the real-time construction safety management with high efficiency and accuracy a reality and provides a solid foundation for facilitating its modernization, and informatization. Nowadays, various sensor-based technologies have been adopted for construction safety management, including locating sensor-based technology, vision-based sensing and wireless sensor networks. This paper provides a systematic and comprehensive review of previous studies in this field to acknowledge useful findings, identify the research gaps and point out future research directions.", "citedby-count": "85", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60004538", "afid": "60004538", "affilname": "Dalian University of Technology", "affiliation-city": "Dalian", "affiliation-country": "China"}], "pubmed-id": "28800061", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "3", "$": "3"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55704430600", "authid": "55704430600", "authname": "Zhang M.", "surname": "Zhang", "given-name": "Mingyuan", "initials": "M.", "afid": [{"@_fa": "true", "$": "60004538"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57195350323", "authid": "57195350323", "authname": "Cao T.", "surname": "Cao", "given-name": "Tianzhuo", "initials": "T.", "afid": [{"@_fa": "true", "$": "60004538"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/8845957900", "authid": "8845957900", "authname": "Zhao X.", "surname": "Zhao", "given-name": "Xuefeng", "initials": "X.", "afid": [{"@_fa": "true", "$": "60004538"}]}], "authkeywords": "Construction | Safety management | Sensor-based technology | Sensors", "article-number": "1841", "source-id": "130124", "fund-no": "undefined", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfullgold"}, {"$": "repository"}, {"$": "repositoryvor"}, {"$": "repositoryam"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Gold"}, {"$": "Green"}]}}, "64": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84979900857"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84979900857?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84979900857&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84979900857&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0003687016301417"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84979900857", "dc:identifier": "SCOPUS_ID:84979900857", "eid": "2-s2.0-84979900857", "dc:title": "Flying solo: A review of the literature on wayfinding for older adults experiencing visual or cognitive decline", "dc:creator": "Bosch S.J.", "prism:publicationName": "Applied Ergonomics", "prism:issn": "00036870", "prism:eIssn": "18729126", "prism:volume": "58", "prism:pageRange": "327-333", "prism:coverDate": "2017-01-01", "prism:coverDisplayDate": "1 January 2017", "prism:doi": "10.1016/j.apergo.2016.07.010", "pii": "S0003687016301417", "dc:description": "Accessible tourism is a growing market within the travel industry, but little research has focused on travel barriers for older adults who may be experiencing visual and cognitive decline as part of the normal aging process, illness, or other disabling conditions. Travel barriers, such as difficulty finding one's way throughout an airport, may adversely affect older adults' travel experience, thereby reducing their desire to travel. This review of the literature investigates wayfinding strategies to ensure that older passengers who have planned to travel independently can do so with dignity. These include facility planning and design strategies (e.g., layout, signage) and technological solutions. Although technological approaches, such as smart phone apps, appear to offer the most promising new solutions for enhancing airport navigation, more traditional approaches, such as designing facilities with an intuitive building layout, are still heavily relied upon in the aviation industry. While there are many design guidelines for enhancing wayfinding for older adults, many are not based on scientific investigation.", "citedby-count": "49", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020547", "afid": "60020547", "affilname": "Texas A&amp;M University", "affiliation-city": "College Station", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60013959", "afid": "60013959", "affilname": "University of Florida", "affiliation-city": "Gainesville", "affiliation-country": "United States"}], "pubmed-id": "27633229", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55505941900", "authid": "55505941900", "authname": "Bosch S.J.", "surname": "Bosch", "given-name": "Sheila J.", "initials": "S.J.", "afid": [{"@_fa": "true", "$": "60013959"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57021980000", "authid": "57021980000", "authname": "Gharaveis A.", "surname": "Gharaveis", "given-name": "Arsalan", "initials": "A.", "afid": [{"@_fa": "true", "$": "60020547"}]}], "authkeywords": "Airport design | Older adults | Wayfinding", "source-id": "13929", "fund-acr": "TRB", "fund-no": "ACRP 07-13", "fund-sponsor": "Transportation Research Board", "openaccess": "0", "openaccessFlag": false}, "65": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84976345341"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84976345341?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84976345341&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84976345341&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84976345341", "dc:identifier": "SCOPUS_ID:84976345341", "eid": "2-s2.0-84976345341", "dc:title": "Visual monitoring of civil infrastructure systems via camera-equipped Unmanned Aerial Vehicles (UAVs): a review of related works", "dc:creator": "Ham Y.", "prism:publicationName": "Visualization in Engineering", "prism:eIssn": "22137459", "prism:volume": "4", "prism:issueIdentifier": "1", "prism:pageRange": null, "prism:coverDate": "2016-12-01", "prism:coverDisplayDate": "1 December 2016", "prism:doi": "10.1186/s40327-015-0029-z", "dc:description": "Over the past few years, the application of camera-equipped Unmanned Aerial Vehicles (UAVs) for visually monitoring construction and operation of buildings, bridges, and other types of civil infrastructure systems has exponentially grown. These platforms can frequently survey construction sites, monitor work-in-progress, create documents for safety, and inspect existing structures, particularly for hard-to-reach areas. The purpose of this paper is to provide a concise review of the most recent methods that streamline collection, analysis, visualization, and communication of the visual data captured from these platforms, with and without using Building Information Models (BIM) as a priori information. Specifically, the most relevant works from Civil Engineering, Computer Vision, and Robotics communities are presented and compared in terms of their potential to lead to automatic construction monitoring and civil infrastructure condition assessment.", "citedby-count": "370", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60015206", "afid": "60015206", "affilname": "Florida International University", "affiliation-city": "Miami", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60000745", "afid": "60000745", "affilname": "University of Illinois Urbana-Champaign", "affiliation-city": "Urbana", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55651299500", "authid": "55651299500", "authname": "Ham Y.", "surname": "Ham", "given-name": "Youngjib", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60015206"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56287693000", "authid": "56287693000", "authname": "Han K.K.", "surname": "Han", "given-name": "Kevin K.", "initials": "K.K.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/56716901300", "authid": "56716901300", "authname": "Lin J.J.", "surname": "Lin", "given-name": "Jacob J.", "initials": "J.J.", "afid": [{"@_fa": "true", "$": "60000745"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/34868104300", "authid": "34868104300", "authname": "Golparvar-Fard M.", "surname": "Golparvar-Fard", "given-name": "Mani", "initials": "M.", "afid": [{"@_fa": "true", "$": "60000745"}]}], "authkeywords": "Civil infrastructure condition assessment | Construction monitoring | Unmanned Aerial Vehicles (UAVs)", "article-number": "1", "source-id": "21100856541", "fund-acr": "NSF", "fund-no": "1427111", "fund-sponsor": "National Science Foundation", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherhybridgold"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Hybrid Gold"}]}}, "66": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84975886000"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84975886000?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84975886000&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84975886000&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84975886000", "dc:identifier": "SCOPUS_ID:84975886000", "eid": "2-s2.0-84975886000", "dc:title": "Infrastructure sensing", "dc:creator": "Soga K.", "prism:publicationName": "Interface Focus", "prism:issn": "20428898", "prism:eIssn": "20428901", "prism:volume": "6", "prism:issueIdentifier": "4", "prism:pageRange": null, "prism:coverDate": "2016-08-06", "prism:coverDisplayDate": "6 August 2016", "prism:doi": "10.1098/rsfs.2016.0023", "dc:description": "Design, construction, maintenance and upgrading of civil engineering infrastructure requires fresh thinking to minimize use of materials, energy and labour. This can only be achieved by understanding the performance of the infrastructure, both during its construction and throughout its design life, through innovative monitoring. Advances in sensor systems offer intriguing possibilities to radically alter methods of condition assessment and monitoring of infrastructure. In this paper, it is hypothesized that the future of infrastructure relies on smarter information; the rich information obtained from embedded sensors within infrastructure will act as a catalyst for new design, construction, operation and maintenance processes for integrated infrastructure systems linked directly with user behaviour patterns. Some examples of emerging sensor technologies for infrastructure sensing are given. They include distributed fibre-optics sensors, computer vision, wireless sensor networks, low-power micro-electromechanical systems, energy harvesting and citizens as sensors.", "citedby-count": "25", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60031101", "afid": "60031101", "affilname": "University of Cambridge", "affiliation-city": "Cambridge", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60025038", "afid": "60025038", "affilname": "University of California, Berkeley", "affiliation-city": "Berkeley", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/7102442890", "authid": "7102442890", "authname": "Soga K.", "surname": "Soga", "given-name": "Kenichi", "initials": "K.", "afid": [{"@_fa": "true", "$": "60025038"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57189900369", "authid": "57189900369", "authname": "Schooling J.", "surname": "Schooling", "given-name": "Jennifer", "initials": "J.", "afid": [{"@_fa": "true", "$": "60031101"}]}], "authkeywords": "Behaviour patterns | Civil engineering infrastructure | Sensor technologies", "article-number": "20160023", "source-id": "21100201986", "fund-acr": "EPSRC", "fund-no": "EP/L010917/1", "fund-sponsor": "Engineering and Physical Sciences Research Council", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfree2read"}, {"$": "repository"}, {"$": "repositoryvor"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Bronze"}, {"$": "Green"}]}}, "67": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84952030966"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84952030966?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84952030966&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84952030966&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84952030966", "dc:identifier": "SCOPUS_ID:84952030966", "eid": "2-s2.0-84952030966", "dc:title": "A review of web image mining", "dc:creator": "Yanai K.", "prism:publicationName": "ITE Transactions on Media Technology and Applications", "prism:eIssn": "21867364", "prism:volume": "3", "prism:issueIdentifier": "3", "prism:pageRange": "156-169", "prism:coverDate": "2015-01-01", "prism:coverDisplayDate": "2015", "prism:doi": "10.3169/mta.3.156", "dc:description": "In this paper, we review works related to big visual data on the Web in the literature of computer vision and multimedia research regarding the following points: (1) Web image acquisition for construction of visual concept database for image/video recognition, (2) Web image application for visual concept analysis and data-driven computer graphics, and (3) real-world sensing through Web images to detect location-dependent and event-related visual information.", "citedby-count": "7", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60032315", "afid": "60032315", "affilname": "The University of Electro-Communications", "affiliation-city": "Chofu", "affiliation-country": "Japan"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/7103290726", "authid": "7103290726", "authname": "Yanai K.", "surname": "Yanai", "given-name": "Keiji", "initials": "K.", "afid": [{"@_fa": "true", "$": "60032315"}]}], "authkeywords": "Social media mining | Visual concepts | Visual event detection | Web image mining", "source-id": "21100432483", "fund-acr": "JSPS", "fund-no": "24300036", "fund-sponsor": "Japan Society for the Promotion of Science", "openaccess": "1", "openaccessFlag": true, "freetoread": {"value": [{"$": "all"}, {"$": "publisherfree2read"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Bronze"}]}}, "68": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84885606175"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84885606175?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84885606175&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84885606175&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84885606175", "dc:identifier": "SCOPUS_ID:84885606175", "eid": "2-s2.0-84885606175", "dc:title": "A survey of appearance models in visual object tracking", "dc:creator": "Li X.", "prism:publicationName": "ACM Transactions on Intelligent Systems and Technology", "prism:issn": "21576904", "prism:eIssn": "21576912", "prism:volume": "4", "prism:issueIdentifier": "4", "prism:pageRange": null, "prism:coverDate": "2013-10-21", "prism:coverDisplayDate": "2013", "prism:doi": "10.1145/2508037.2508039", "dc:description": "Visual object tracking is a significant computer vision task which can be applied to many domains, such as visual surveillance, human computer interaction, and video compression. Despite extensive research on this topic, it still suffers from difficulties in handling complex object appearance changes caused by factors such as illumination variation, partial occlusion, shape deformation, and camera motion. Therefore, effective modeling of the 2D appearance of tracked objects is a key issue for the success of a visual tracker. In the literature, researchers have proposed a variety of 2D appearance models. To help readers swiftly learn the recent advances in 2D appearance models for visual object tracking, we contribute this survey, which provides a detailed review of the existing 2D appearance models. In particular, this survey takes a module-based architecture that enables readers to easily grasp the key points of visual object tracking. In this survey, we first decompose the problem of appearance modeling into two different processing stages: visual representation and statistical modeling. Then, different 2D appearance models are categorized and discussed with respect to their composition modules. Finally, we address several issues of interest as well as the remaining challenges for future research on this topic. The contributions of this survey are fourfold. First, we review the literature of visual representations according to their feature-construction mechanisms (i.e., local and global). Second, the existing statistical modeling schemes for tracking-by-detection are reviewed according to their model-constructionmechanisms: generative, discriminative, and hybrid generative-discriminative. Third, each type of visual representations or statisticalmodeling techniques is analyzed and discussed from a theoretical or practical viewpoint. Fourth, the existing benchmark resources (e.g., source codes and video datasets) are examined in this survey. \u00a9 2013 ACM.", "citedby-count": "654", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60020273", "afid": "60020273", "affilname": "Binghamton University State University of New York", "affiliation-city": "Binghamton", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60009512", "afid": "60009512", "affilname": "The University of Adelaide", "affiliation-city": "Adelaide", "affiliation-country": "Australia"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "6", "$": "6"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55718109600", "authid": "55718109600", "authname": "Li X.", "surname": "Li", "given-name": "Xi", "initials": "X.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56703992500", "authid": "56703992500", "authname": "Hu W.", "surname": "Hu", "given-name": "Weiming", "initials": "W.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/7402859952", "authid": "7402859952", "authname": "Shen C.", "surname": "Shen", "given-name": "Chunhua", "initials": "C.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/35214034700", "authid": "35214034700", "authname": "Zhang Z.", "surname": "Zhang", "given-name": "Zhongfei", "initials": "Z.", "afid": [{"@_fa": "true", "$": "60020273"}]}, {"@_fa": "true", "@seq": "5", "author-url": "https://api.elsevier.com/content/author/author_id/7103296948", "authid": "7103296948", "authname": "Dick A.", "surname": "Dick", "given-name": "Anthony", "initials": "A.", "afid": [{"@_fa": "true", "$": "60009512"}]}, {"@_fa": "true", "@seq": "6", "author-url": "https://api.elsevier.com/content/author/author_id/35587677100", "authid": "35587677100", "authname": "Van Den Hengel A.", "surname": "Van Den Hengel", "given-name": "Anton", "initials": "A.", "afid": [{"@_fa": "true", "$": "60009512"}]}], "authkeywords": "Appearance model | Features | Statistical modeling | Visual object tracking", "article-number": "58", "source-id": "19700190323", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false, "freetoread": {"value": [{"$": "all"}, {"$": "repository"}, {"$": "repositoryam"}]}, "freetoreadLabel": {"value": [{"$": "All Open Access"}, {"$": "Green"}]}}, "69": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84868358465"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84868358465?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84868358465&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84868358465&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84868358465", "dc:identifier": "SCOPUS_ID:84868358465", "eid": "2-s2.0-84868358465", "dc:title": "Review for team's behavior recognition", "dc:creator": "Yu F.", "prism:publicationName": "Advances in Information Sciences and Service Sciences", "prism:issn": "19763700", "prism:eIssn": "22339345", "prism:volume": "4", "prism:issueIdentifier": "19", "prism:pageRange": "471-480", "prism:coverDate": "2012-10-01", "prism:coverDisplayDate": "October 2012", "prism:doi": "10.4156/AISS.vol4.issue19.59", "dc:description": "Recognition and understanding of team's behavior which is planned and high-cooperative and multi-player (agent) participate is an important field of computer vision research. In this paper, we in detail analyze and summarize the existing research achievements in the area of the team's behavior recognition from four aspects of target tracking and detection, representation of behavior, construction of classification and behavior recognition. The problems waiting to be solved and some research trends in the field of team's behavior recognition in the future are also analyzed in this paper. It may provide some novel insights and literature references for the researcher of recognition of multi-objective behavior in the future.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60088965", "afid": "60088965", "affilname": "Guangxi University of Science and Technology", "affiliation-city": "Liuzhou", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60014070", "afid": "60014070", "affilname": "Hunan Normal University", "affiliation-city": "Changsha", "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55712868100", "authid": "55712868100", "authname": "Yu F.", "surname": "Yu", "given-name": "Fu", "initials": "F.", "afid": [{"@_fa": "true", "$": "60014070"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/44462255600", "authid": "44462255600", "authname": "Zhiwen W.", "surname": "Zhiwen", "given-name": "Wang", "initials": "W.", "afid": [{"@_fa": "true", "$": "60088965"}]}], "authkeywords": "Behavior recognition strategy | Construction of classification | Occlusion | Representation of behavior | Role identification | Target tracking and detection | Team's behavior recognition", "source-id": "19700200842", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "70": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84861996029"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84861996029?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84861996029&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84861996029&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84861996029", "dc:identifier": "SCOPUS_ID:84861996029", "eid": "2-s2.0-84861996029", "dc:title": "Rugged computers for tough environments", "dc:creator": "L\u00f6fblad S.", "prism:publicationName": "GIM International", "prism:issn": "15669076", "prism:volume": "26", "prism:issueIdentifier": "5", "prism:pageRange": null, "prism:coverDate": "2012-05-01", "prism:coverDisplayDate": "May 2012", "dc:description": "The Handheld Group, with headquarters in Lidk\u00f6ping in southwestern Sweden, is a manufacturer and worldwide supplier of rugged mobile computers and PDAs, and the fastest growing company in its sector. Over the past eight years, Handheld has experienced tremendous growth and has been able to meet the demands of some of the most demanding verticals on the market, the true outdoor users in the geotech market. Handheld's vision is to become one of the leading companies in the world in ruggedized mobile computing. The company's main business is to supply ruggedized mobile computers to end users together with its business partners in a global perspective. Handheld's line-up of rugged PDAs and mobile computers is specifically developed for use in all kinds of tough environments where the user is working outside a protected office environment, such as the geomatics industry, logistics, forestry, public transportation, construction, mining, field service, utilities, maintenance, public safety, military and security.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/112866915", "afid": "112866915", "affilname": "Handheld Group", "affiliation-city": null, "affiliation-country": null}], "prism:aggregationType": "Trade Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/54881856100", "authid": "54881856100", "authname": "L\u00f6fblad S.", "surname": "L\u00f6fblad", "given-name": "Sofia", "initials": "S.", "afid": [{"@_fa": "true", "$": "112866915"}]}], "source-id": "28195", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "71": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/79960832338"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/79960832338?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=79960832338&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=79960832338&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/79960832338", "dc:identifier": "SCOPUS_ID:79960832338", "eid": "2-s2.0-79960832338", "dc:title": "Geometric invariants construction from multiple views", "dc:creator": "Jin C.", "prism:publicationName": "International Journal of Modeling, Simulation, and Scientific Computing", "prism:issn": "17939623", "prism:eIssn": "17939615", "prism:volume": "2", "prism:issueIdentifier": "2", "prism:pageRange": "195-206", "prism:coverDate": "2011-01-01", "prism:coverDisplayDate": "June 2011", "prism:doi": "10.1142/S1793962311000402", "pii": "S1793962311000402", "dc:description": "Geometric invariants have wide applications in computer vision and their precision has long been a hot topic. In most of the existing methods, three-dimensional (3D) invariants have been obtained by reconstruction of the object structure, where fundamental matrices between image pairs should be first established. Consequently, there are additional errors introduced during invariants construction and could be very time consuming. In this paper, a novel algorithm to calculate 3D projective invariants from multiple images has been proposed, without reconstructing the object structures explicitly. We have employed the geometric configuration of points and lines in general position to deduce the formulation of 3D invariants. It has been verified in our experiments that our proposed method is considerably accurate when compared with the ground truth, and more efficient when compared with reconstruction based methods. \u00a9 2011 World Scientific Publishing Company.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/110031850", "afid": "110031850", "affilname": "China Mobile Group Zhejiang Co., Ltd.", "affiliation-city": null, "affiliation-country": "China"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/56325434700", "authid": "56325434700", "authname": "Jin C.", "surname": "Jin", "given-name": "Cheng", "initials": "C.", "afid": [{"@_fa": "true", "$": "110031850"}]}], "authkeywords": "3D reconstruction | Geometric invariants | multi-view geometry | projective invariants", "source-id": "19900192598", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "72": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/34247261632"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/34247261632?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=34247261632&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=34247261632&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/34247261632", "dc:identifier": "SCOPUS_ID:34247261632", "eid": "2-s2.0-34247261632", "dc:title": "Prosthetic interfaces with the visual system: Biological issues", "dc:creator": "Cohen E.", "prism:publicationName": "Journal of Neural Engineering", "prism:issn": "17412560", "prism:eIssn": "17412552", "prism:volume": "4", "prism:issueIdentifier": "2", "prism:pageRange": null, "prism:coverDate": "2007-06-01", "prism:coverDisplayDate": "1 June 2007", "prism:doi": "10.1088/1741-2560/4/2/R02", "pii": "S1741256007880098", "dc:description": "The design of effective visual prostheses for the blind represents a challenge for biomedical engineers and neuroscientists. Significant progress has been made in the miniaturization and processing power of prosthesis electronics; however development lags in the design and construction of effective machine-brain interfaces with visual system neurons. This review summarizes what has been learned about stimulating neurons in the human and primate retina, lateral geniculate nucleus and visual cortex. Each level of the visual system presents unique challenges for neural interface design. Blind patients with the retinal degenerative disease retinitis pigmentosa (RP) are a common population in clinical trials of visual prostheses. The visual performance abilities of normals and RP patients are compared. To generate pattern vision in blind patients, the visual prosthetic interface must effectively stimulate the retinotopically organized neurons in the central visual field to elicit patterned visual percepts. The development of more biologically compatible methods of stimulating visual system neurons is critical to the development of finer spatial percepts. Prosthesis electrode arrays need to adapt to different optimal stimulus locations, stimulus patterns, and patient disease states. \u00a9 2007 IOP Publishing Ltd.", "citedby-count": "61", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60101765", "afid": "60101765", "affilname": "Food and Drug Administration, Center for Devices and Radiological Health", "affiliation-city": "Rockville", "affiliation-country": "United States"}], "pubmed-id": "17409473", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57200427436", "authid": "57200427436", "authname": "Cohen E.", "surname": "Cohen", "given-name": "Ethan D.", "initials": "E.D.", "afid": [{"@_fa": "true", "$": "60101765"}]}], "article-number": "R02", "source-id": "130164", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "73": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33745466671"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33745466671?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=33745466671&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=33745466671&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/33745466671", "dc:identifier": "SCOPUS_ID:33745466671", "eid": "2-s2.0-33745466671", "dc:title": "Software package for the precast concrete industry knowledge - Data - Visions", "prism:publicationName": "Betonwerk und Fertigteil-Technik/Concrete Precasting Plant and Technology", "prism:issn": "03734331", "prism:volume": "72", "prism:issueIdentifier": "6", "prism:pageRange": "58-60", "prism:coverDate": "2006-07-03", "prism:coverDisplayDate": "2006", "dc:description": "PRAXIS AG has developed innovative and efficient client-oriented software products such as WDV 32 and AuGe to help in the growth of the precast concrete industry. The WDV 32 trade solution is used in trade and production companies in the stock and bulk commodity sectors such as gravel and sand companies, ready-mix concrete, concrete products and precast concrete industry. The software can be used in big companies, distribution companies, and in small companies with simple production sites due to its significant scope for adaptability. It can also be used with software modules in office settings and its working processes including document management, archiving, appointment management, and management of technical instructions. AuGe is a company-wide platform that displays continuous tracking on a hosted Intranet site of the progress and company-specific assessments and statistics. AuGe was designed for construction and bulk commodity companies and developed by firms in this sector.", "citedby-count": "0", "prism:aggregationType": "Trade Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "0"}, "source-id": "26458", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "74": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33745013669"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33745013669?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=33745013669&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=33745013669&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/33745013669", "dc:identifier": "SCOPUS_ID:33745013669", "eid": "2-s2.0-33745013669", "dc:title": "Flexible by design", "dc:creator": "Michiels E.", "prism:publicationName": "DB2 Magazine", "prism:volume": "11", "prism:issueIdentifier": "2", "prism:pageRange": "58-60", "prism:coverDate": "2006-06-01", "prism:coverDisplayDate": "June 2006", "dc:description": "On March 16, 2006, IBM has announced Rational Data Architecture (RDA), a new eclipsed based tool that lets users discover, model, visualize, relate, and develop distributed data assets in different formats. RDA is part of the WebSphere Information Integration platform and is the concrete realization of the information integration services layer of the IBM Information On Demand vision. RDA, which runs on windows, uses the same platform as other Rational design and construction tools, which enables extensibility and a familiar user experience. Design and modeling capabilities of RDA include logical data modeling, physical data modeling, and the ability to map different data sources to each other and integrate them into a federation schema. RDA can generate syntax-specific DDL or XML Schema from the model based on a code generation dialog that allows the DBA to select which elements to include in the code generation.", "citedby-count": "0", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60021293", "afid": "60021293", "affilname": "International Business Machines", "affiliation-city": "Armonk", "affiliation-country": "United States"}], "prism:aggregationType": "Trade Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/36895744900", "authid": "36895744900", "authname": "Michiels E.", "surname": "Michiels", "given-name": "Eric", "initials": "E.", "afid": [{"@_fa": "true", "$": "60021293"}]}], "source-id": "52779", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "75": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33645668469"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33645668469?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=33645668469&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=33645668469&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/33645668469", "dc:identifier": "SCOPUS_ID:33645668469", "eid": "2-s2.0-33645668469", "dc:title": "Automated radioscopic testing of aluminum die castings", "dc:creator": "Mery D.", "prism:publicationName": "Materials Evaluation", "prism:issn": "00255327", "prism:volume": "64", "prism:issueIdentifier": "2", "prism:pageRange": "135-143", "prism:coverDate": "2006-02-01", "prism:coverDisplayDate": "February 2006", "dc:description": "Castings produced for the automotive industry are considered important components for overall roadworthiness. To ensure the safety of construction, it is necessary to check every part thoroughly using nondestructive testing (NDT). Radioscopy rapidly became the accepted way for controlling the quality of die cast pieces. In this paper, the fundamental principles of the automated detection of casting discontinuities are explained. A general automated testing schema is presented and several techniques that have appeared in the literature in the past 20 years are explained, showing the development of this sector in the areas of industry and academia. Finally, advances in the simulation of discontinuities, used for assessing the performance of a test technique, are outlined.", "citedby-count": "24", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60029681", "afid": "60029681", "affilname": "Pontificia Universidad Cat\u00f3lica de Chile", "affiliation-city": "Santiago", "affiliation-country": "Chile"}], "prism:aggregationType": "Trade Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/7004430596", "authid": "7004430596", "authname": "Mery D.", "surname": "Mery", "given-name": "Domingo", "initials": "D.", "afid": [{"@_fa": "true", "$": "60029681"}]}], "authkeywords": "Aluminum castings | Automated testing | Computer vision | Discontinuity detection | Discontinuity simulation | X-ray testing", "source-id": "17801", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "76": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33749567885"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/33749567885?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=33749567885&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=33749567885&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/33749567885", "dc:identifier": "SCOPUS_ID:33749567885", "eid": "2-s2.0-33749567885", "dc:title": "Special issue: Collaboration in e-Research", "dc:creator": "Jirotka M.", "prism:publicationName": "Computer Supported Cooperative Work", "prism:issn": "09259724", "prism:eIssn": "15737551", "prism:volume": "15", "prism:issueIdentifier": "4", "prism:pageRange": "251-255", "prism:coverDate": "2006-01-01", "prism:coverDisplayDate": "August 2006", "prism:doi": "10.1007/s10606-006-9028-x", "dc:description": "The e-Science program has suggested a way to address new scientific challenges through the development of global, collaborative multi-disciplinary research communities. These research communities rely upon the construction of more powerful computational, data, and communication infrastructures. The e-Science vision is concerned with changing with dynamics of science with e-Research and with providing technologies that will facilitate the emergence of these new forms of scientific practice. e-Research raises significant concerns about trust in technology as the management of infrastructure and resources is increasingly delegated to automated systems. It raises many challenging issues for the design of representations of information, knowledge, and expertise interdisciplinary and distributed research teams. CSCW has a rich tradition sensitive to issues raised in the development of robust e-Research, which describes the framework of its contribution.", "citedby-count": "45", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60026851", "afid": "60026851", "affilname": "University of Oxford", "affiliation-city": "Oxford", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60015138", "afid": "60015138", "affilname": "University of Nottingham", "affiliation-city": "Nottingham", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60010451", "afid": "60010451", "affilname": "Santa Clara University", "affiliation-city": "Santa Clara", "affiliation-country": "United States"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60003771", "afid": "60003771", "affilname": "The University of Manchester", "affiliation-city": "Manchester", "affiliation-country": "United Kingdom"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/8850301900", "authid": "8850301900", "authname": "Jirotka M.", "surname": "Jirotka", "given-name": "Marina", "initials": "M.", "afid": [{"@_fa": "true", "$": "60026851"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/7005500459", "authid": "7005500459", "authname": "Procter R.", "surname": "Procter", "given-name": "Rob", "initials": "R.", "afid": [{"@_fa": "true", "$": "60003771"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/7003488009", "authid": "7003488009", "authname": "Rodden T.", "surname": "Rodden", "given-name": "Tom", "initials": "T.", "afid": [{"@_fa": "true", "$": "60015138"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/6701464335", "authid": "6701464335", "authname": "Bowker G.", "surname": "Bowker", "given-name": "Geoffrey C.", "initials": "G.C.", "afid": [{"@_fa": "true", "$": "60010451"}]}], "source-id": "24304", "fund-no": "undefined", "fund-sponsor": "Spectrum Pharmaceuticals", "openaccess": "0", "openaccessFlag": false}, "77": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/28744450006"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/28744450006?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=28744450006&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=28744450006&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/28744450006", "dc:identifier": "SCOPUS_ID:28744450006", "eid": "2-s2.0-28744450006", "dc:title": "Magnetic attraction", "dc:creator": "Jeffery H.", "prism:publicationName": "Engineering", "prism:issn": "00137782", "prism:volume": "246", "prism:issueIdentifier": "9", "prism:pageRange": "27-28", "prism:coverDate": "2005-10-01", "prism:coverDisplayDate": "October 2005", "dc:description": "The extensive and reliable applications provided by computer vision technology, which aspires to make machines that are capable of handling useful information from single images or a sequence of images, are described. Machine vision is used in many industrial applications, such as in the inspection of parts during a manufacturing process, and it is faster and more accurate than traditional manual inspection methods. An interested application of this technology is in the production of machines parts for a construction game called Geomag. In the Geomag quality control process, a coaxial light is used to provide constant illumination for the pieces. The use of machine vision systems allows the manufacturing industry to produce high speed.", "citedby-count": "0", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57196972235", "authid": "57196972235", "authname": "Jeffery H.", "surname": "Jeffery", "given-name": "Hannah", "initials": "H."}], "source-id": "29049", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "78": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/19944370094"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/19944370094?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=19944370094&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=19944370094&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/19944370094", "dc:identifier": "SCOPUS_ID:19944370094", "eid": "2-s2.0-19944370094", "dc:title": "Real-time natural hand gestures", "dc:creator": "Yi B.", "prism:publicationName": "Computing in Science and Engineering", "prism:issn": "15219615", "prism:volume": "7", "prism:issueIdentifier": "3", "prism:pageRange": "92-97", "prism:coverDate": "2005-05-01", "prism:coverDisplayDate": "May 2005", "prism:doi": "10.1109/MCSE.2005.58", "dc:description": "The extension of hand gesture model to create an human computer interaction (HCI) system that includes the whole body, will provide a platform to create virtual human gestures. Vision-based HCI hand-gesture-analysis and recognition studies require large numbers of variety of gestures as input and virtual hand as output. Human hand is highly articulated with many joints and organic in nature. Virtual hand construction fully consider the human hand's biomechnaical features.", "citedby-count": "31", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60014556", "afid": "60014556", "affilname": "Sichuan Normal University", "affiliation-city": "Chengdu", "affiliation-country": "China"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60001769", "afid": "60001769", "affilname": "University of Nevada, Reno", "affiliation-city": "Reno", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "4", "$": "4"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/35946448700", "authid": "35946448700", "authname": "Yi B.", "surname": "Yi", "given-name": "Beifang", "initials": "B.", "afid": [{"@_fa": "true", "$": "60001769"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/57213805178", "authid": "57213805178", "authname": "Harris F.C.", "surname": "Harris", "given-name": "Frederick C.", "initials": "F.C.", "afid": [{"@_fa": "true", "$": "60001769"}]}, {"@_fa": "true", "@seq": "3", "author-url": "https://api.elsevier.com/content/author/author_id/55856586500", "authid": "55856586500", "authname": "Wang L.", "surname": "Wang", "given-name": "Ling", "initials": "L.", "afid": [{"@_fa": "true", "$": "60014556"}]}, {"@_fa": "true", "@seq": "4", "author-url": "https://api.elsevier.com/content/author/author_id/8607117600", "authid": "8607117600", "authname": "Yan Y.", "surname": "Yan", "given-name": "Yusong", "initials": "Y.", "afid": [{"@_fa": "true", "$": "60014556"}]}], "source-id": "13185", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "79": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/1842429632"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/1842429632?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=1842429632&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=1842429632&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/1842429632", "dc:identifier": "SCOPUS_ID:1842429632", "eid": "2-s2.0-1842429632", "dc:title": "The Architect's Answer: Sketchup 3 - An Elegant AEC and multimedia solution", "dc:creator": "Goldberg H.", "prism:publicationName": "Cadalyst", "prism:issn": "08205450", "prism:volume": "21", "prism:issueIdentifier": "1", "prism:pageRange": "34-36", "prism:coverDate": "2004-01-01", "prism:coverDisplayDate": "January 2004", "dc:description": "An elegant AEC and multimedia software program called SketchUp 3.0 was designed as a more intuitive and accessible 3D design tool. SketchUP is a shared vision of @Last Software's founders, a small group of AEC industry veterans for designing of the three dimensional (3D) design tool. Features in v3 give it broader applicability throughout the entire design, presentation, and construction document phase. SketchUp provides a free reader to enable interactive walk through a design on their computers.", "citedby-count": "0", "prism:aggregationType": "Trade Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55666300800", "authid": "55666300800", "authname": "Goldberg H.", "surname": "Goldberg", "given-name": "H. Edward", "initials": "H.E."}], "source-id": "18139", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "80": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0742285899"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0742285899?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0742285899&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0742285899&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/0742285899", "dc:identifier": "SCOPUS_ID:0742285899", "eid": "2-s2.0-0742285899", "dc:title": "Virtual Building for Construction Projects", "dc:creator": "Sheppard L.M.", "prism:publicationName": "IEEE Computer Graphics and Applications", "prism:issn": "02721716", "prism:volume": "24", "prism:issueIdentifier": "1", "prism:pageRange": "6-12", "prism:coverDate": "2004-01-01", "prism:coverDisplayDate": "January 2004", "prism:doi": "10.1109/MCG.2004.1255800", "dc:description": "The use of 4DCAD technology in construction projects of the architecture-engineering-construction (AEC) industry is discussed. The 4DCAD technology links three-dimensional design models with a cost database, schedules and other data. Using the technology, user can visualize the construction sequence as a movie or animation, which aids in avoiding conflict in scheduling, resolving safety issues and cost estimation before the actual construction begins. The PM-Vision from Construction Systems associates (CSA) and ConstructSim from Reality Capture are two of the latest software developed based on the 4DCAD technology. The shortcomings of applying the technology are also presented.", "citedby-count": "18", "pubmed-id": "15384661", "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/7103363903", "authid": "7103363903", "authname": "Sheppard L.M.", "surname": "Sheppard", "given-name": "Laurel M.", "initials": "L.M."}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/56410597700", "authid": "56410597700", "authname": "Potel M.", "surname": "Potel", "given-name": "Mike", "initials": "M."}], "source-id": "25518", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "81": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/9144227083"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/9144227083?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=9144227083&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=9144227083&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/9144227083", "dc:identifier": "SCOPUS_ID:9144227083", "eid": "2-s2.0-9144227083", "dc:title": "IT strategy for construction companies: A pragmatism's vision", "dc:creator": "Macomber J.", "prism:publicationName": "Leadership and Management in Engineering", "prism:issn": "15326748", "prism:volume": "3", "prism:issueIdentifier": "2", "prism:pageRange": "94-99", "prism:coverDate": "2003-04-01", "prism:coverDisplayDate": "April 2003", "prism:doi": "10.1061/(ASCE)1532-6748(2003)3:2(94)", "dc:description": "It is contended that leading constructors will alter the economic model in order to take advantage of information technology (IT) opportunities in the coming years. Strategic business leaders, it is noted, aren't interested in playing with computer tools that nibble at the margins of individual productivity; they seek the substantial savings in costs and improvements in service that have been achieved in other industries. The construction industry, however, is currently organized on an \"every man for himself\" basis, each firm holding its information within its walls. Therefore, the compelling IT strategies in construction and engineering will incorporate economic incentives that overcome this barrier and make it worthwhile for individual actors to aid the whole supply chain. Attention is given to the way in which such incentives might be structured. The marriage of technology tools and business incentives is seen as forming the core of a strategic vision for IT in construction during the next decade.", "citedby-count": "2", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/100802750", "afid": "100802750", "affilname": "George B.H. Macomber Company", "affiliation-city": null, "affiliation-country": null}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/6701566373", "authid": "6701566373", "authname": "Macomber J.", "surname": "Macomber", "given-name": "John D.", "initials": "J.D.", "afid": [{"@_fa": "true", "$": "100802750"}]}], "source-id": "16776", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "82": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/27644574395"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/27644574395?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=27644574395&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=27644574395&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/27644574395", "dc:identifier": "SCOPUS_ID:27644574395", "eid": "2-s2.0-27644574395", "dc:title": "A full visual A-SMGCS simulation platform", "dc:creator": "Hesselink H.H.", "prism:publicationName": "REE, Revue de L'Electricite et de L'Electronique", "prism:issn": "12656534", "prism:volume": "2002", "prism:issueIdentifier": "4", "prism:pageRange": "57-62", "prism:coverDate": "2002-01-01", "prism:coverDisplayDate": "2002", "prism:doi": "10.3845/ree.2002.044", "dc:description": "In this paper, we present the construction and evaluation of a real-time full vision Advanced Surface Movement Guidance and Control System (A-SMGCS) simulation platform for controllers and pilots, including several advanced sensor simulators and a surveillance function. The project was the first to demonstrate and use a full A-SMGCS platform for evaluation of A-SMGCS operational concepts and procedures. Essential bases for the simulator were the sensor simulation and surveillance functions. Simulated ASDE, a Mode-S multi-lateration system, and a D-GPS formed the sensors that provided input for the surveillance function, which had the possibility to specify a track-loss and track-swap ratio. Output of the surveillance function was used by several A-SMGCS processes and displayed at the controller working position on a plan view display and electronic strip panel. The project demonstrated that improved situational awareness through the use of advanced sensor and surveillance technology aided the controllers in carrying out their task. We conducted several tests where different sensor qualities were available to the controller and where labelled surveillance was made available for the full 100% accuracy or with a predefined track-loss rate. Several weeks of trials with operational controllers and pilots were carried out. We showed the benefit of improved technology for ground sensors to aid the controller and to provide the necessary information to other A-SMGCS processes, like runway incursion alert and planning.", "citedby-count": "1", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60003494", "afid": "60003494", "affilname": "Netherlands Aerospace Centre NLR", "affiliation-city": "Amsterdam", "affiliation-country": "Netherlands"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60002731", "afid": "60002731", "affilname": "QinetiQ", "affiliation-city": "Farnborough", "affiliation-country": "United Kingdom"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/101801692", "afid": "101801692", "affilname": "NLR Special Interest Group", "affiliation-city": null, "affiliation-country": "Netherlands"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/101759528", "afid": "101759528", "affilname": "Triple-I Project", "affiliation-city": null, "affiliation-country": "Netherlands"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/8348880700", "authid": "8348880700", "authname": "Hesselink H.H.", "surname": "Hesselink", "given-name": "H. H.", "initials": "H.H.", "afid": [{"@_fa": "true", "$": "60003494"}, {"@_fa": "true", "$": "101759528"}, {"@_fa": "true", "$": "101801692"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/9037444000", "authid": "9037444000", "authname": "Maycroft H.", "surname": "Maycroft", "given-name": "H.", "initials": "H.", "afid": [{"@_fa": "true", "$": "60002731"}]}], "authkeywords": "A-SMGCS | Man-in-the-loop | Simulation | Surveillance", "source-id": "19149", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "83": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0041303657"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0041303657?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0041303657&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0041303657&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/0041303657", "dc:identifier": "SCOPUS_ID:0041303657", "eid": "2-s2.0-0041303657", "dc:title": "CAD-layered record drawings for facility management", "dc:creator": "Wilkins D.", "prism:publicationName": "Engineered Systems", "prism:issn": "08919976", "prism:volume": "19", "prism:issueIdentifier": "12", "prism:pageRange": "70-76", "prism:coverDate": "2002-01-01", "prism:coverDisplayDate": "December 2002", "dc:description": "The issues related to the CAD-layered record drawings for facility management are discussed in the article. Through vision and time management skills, CAD record drawings can be layered to meet the needs of facility management over the life of a building occupancy. There are several ways in which to translate between layer schemes. Script files, Auto LISP, and AutoCAD's 'Layer Translate' are ways in which to automate the process.", "citedby-count": "0", "prism:aggregationType": "Trade Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/57213627416", "authid": "57213627416", "authname": "Wilkins D.", "surname": "Wilkins", "given-name": "David A.", "initials": "D.A."}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/7003707737", "authid": "7003707737", "authname": "Mckew H.", "surname": "Mckew", "given-name": "Howard J.", "initials": "H.J."}], "source-id": "16011", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "84": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0034289078"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0034289078?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0034289078&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0034289078&origin=inward"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/0034289078", "dc:identifier": "SCOPUS_ID:0034289078", "eid": "2-s2.0-0034289078", "dc:title": "Implementing a management system architecture framework", "dc:creator": "Goers W.", "prism:publicationName": "Bell Labs Technical Journal", "prism:issn": "10897089", "prism:volume": "5", "prism:issueIdentifier": "4", "prism:pageRange": "31-43", "prism:coverDate": "2000-01-01", "prism:coverDisplayDate": "October-December 2000", "prism:doi": "10.1002/bltj.2249", "dc:description": "Any practical vision for the evolution of communications services must include a strategy for how networking vendors make it possible for service providers to manage their networks. While the Telecommunications Management Network (TMN) framework has proponents, the IP services community has shown little interest. Furthermore, operations systems developers have long attempted to produce the best framework, but the technology is outdated before it exists. This paper addresses both issues by presenting an application-driven model for integrated management. This model can be applied to either a \"classic\" framework orientation or a management application view. What is common between these two views are a management portal, common data models, multiple interface technologies, open and simple network element interfaces, and common operations, administration, and administration (OA&M) tools. These are the elements for which there needs to be a consistent set of interface definitions. They form the basis for the construction of next-generation management applications.", "citedby-count": "6", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60026638", "afid": "60026638", "affilname": "Nokia Corporation", "affiliation-city": "Espoo", "affiliation-country": "Finland"}, {"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60000251", "afid": "60000251", "affilname": "IEEE", "affiliation-city": "New York", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/6506832628", "authid": "6506832628", "authname": "Goers W.", "surname": "Goers", "given-name": "William C.", "initials": "W.C.", "afid": [{"@_fa": "true", "$": "60026638"}, {"@_fa": "true", "$": "60000251"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/55439444300", "authid": "55439444300", "authname": "Brenner M.", "surname": "Brenner", "given-name": "Michael R.", "initials": "M.R.", "afid": [{"@_fa": "true", "$": "60026638"}]}], "source-id": "20786", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}, "85": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0032210240"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0032210240?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0032210240&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0032210240&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0031320398000478"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/0032210240", "dc:identifier": "SCOPUS_ID:0032210240", "eid": "2-s2.0-0032210240", "dc:title": "Three-dimensional model construction from multiview range images: Survey with new results", "dc:creator": "Goshtasby A.A.", "prism:publicationName": "Pattern Recognition", "prism:issn": "00313203", "prism:volume": "31", "prism:issueIdentifier": "11", "prism:pageRange": "1705-1714", "prism:coverDate": "1998-01-01", "prism:coverDisplayDate": "November 1998", "prism:doi": "10.1016/s0031-3203(98)00047-8", "pii": "S0031320398000478", "dc:description": "Construction of three-dimensional (3-D) models from multiview range images involves three general steps: (1) image integration, (2) recovery of missing data, and (3) model representation and editing. Literature related to these three steps are reviewed and new results in data recovery and model editing are presented. Examples demonstrating different steps of the model construction process are also given using range images from a variety applications. \u00a9 1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.", "citedby-count": "16", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/60018306", "afid": "60018306", "affilname": "Wright State University", "affiliation-city": "Dayton", "affiliation-country": "United States"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "1", "$": "1"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/7003767990", "authid": "7003767990", "authname": "Goshtasby A.A.", "surname": "Goshtasby", "given-name": "A. Ardeshir", "initials": "A.A.", "afid": [{"@_fa": "true", "$": "60018306"}]}], "authkeywords": "Image integration | Image registration | Model editing | Model representation | Range image | Recovery of missing data", "source-id": "24823", "fund-no": "1R03DE11162", "openaccess": "0", "openaccessFlag": false}, "86": {"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/38149146470"}, {"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/38149146470?field=author,affiliation"}, {"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=38149146470&origin=inward"}, {"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=38149146470&origin=inward"}, {"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S1049966084710394"}], "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/38149146470", "dc:identifier": "SCOPUS_ID:38149146470", "eid": "2-s2.0-38149146470", "dc:title": "Purposive Reconstruction: A Reply to \"A Computational and Evolutionary Perspective on the Role of Representation in Vision\" by M. J. Tarr and M. J. Black", "dc:creator": "Christensen H.", "prism:publicationName": "CVGIP: Image Understanding", "prism:issn": "10499660", "prism:volume": "60", "prism:issueIdentifier": "1", "prism:pageRange": "103-108", "prism:coverDate": "1994-07-01", "prism:coverDisplayDate": "July 1994", "prism:doi": "10.1006/ciun.1994.1039", "pii": "S1049966084710394", "dc:description": "In Tarr and Black\u2032s paper it is stated that computer vision research should be based on reconstruction, as it offers the most promising framework for achieving insight into human visual cognition. It is further stated that it is in agreement with evolution. The competing school, the purposive, is considered too specific and relevant mainly for construction of robotic related systems with a limited functionality. In this paper it is argued that the two schools should not be viewed as competing, but rather as complementary. The reconstruction approach is used for research in vision functionalities, which may be combined into operational systems through a purposive analysis from a global point of view. Such a combined approach to vision is necessary for addressing critical issues such as continuous operation and achievement of specific visual tasks, while maintaining the generality needed to obtain insight into visual cognition. \u00a9 1994 Academic Press. All rights reserved.", "citedby-count": "2", "affiliation": [{"@_fa": "true", "affiliation-url": "https://api.elsevier.com/content/affiliation/affiliation_id/105327844", "afid": "105327844", "affilname": "Ies", "affiliation-city": "Aalborg", "affiliation-country": "Denmark"}], "prism:aggregationType": "Journal", "subtype": "re", "subtypeDescription": "Review", "author-count": {"@limit": "100", "@total": "2", "$": "2"}, "author": [{"@_fa": "true", "@seq": "1", "author-url": "https://api.elsevier.com/content/author/author_id/55567693000", "authid": "55567693000", "authname": "Christensen H.", "surname": "Christensen", "given-name": "H. I.", "initials": "H.I.", "afid": [{"@_fa": "true", "$": "105327844"}]}, {"@_fa": "true", "@seq": "2", "author-url": "https://api.elsevier.com/content/author/author_id/7103067957", "authid": "7103067957", "authname": "Madsen C.", "surname": "Madsen", "given-name": "C. B.", "initials": "C.B.", "afid": [{"@_fa": "true", "$": "105327844"}]}], "source-id": "34484", "fund-no": "undefined", "openaccess": "0", "openaccessFlag": false}}